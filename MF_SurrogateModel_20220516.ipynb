{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5ce59619-8858-4d7b-927e-8f6235eddec7",
      "metadata": {
        "id": "5ce59619-8858-4d7b-927e-8f6235eddec7"
      },
      "source": [
        "# Multi-Fidelity Surrogate Modeling Techniques For Prediction of Hypersonic Flows\n",
        "This code seeks to compare the data compression, accuracy, portability, and evaluation time for two different types of surrogate modeling techniques: Kriging and Deep Neural Nets (DNN). First, we will build single fidelity models based on the RANS data (our high fidelity data set), then we will build single fidelity models based on local methods (low fidelity data set). Finally, we will build multi-fidelity models combining the data from both models. \n",
        "\n",
        "Our goal is to beat the performance of the single fidelity model, and also potentially explore how much of the high fidelity data is needed--maybe we can match the performace of the single fidelity model, but with significantly less data. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cbda0d4",
      "metadata": {},
      "source": [
        "## Future Work\n",
        "<!-- * Use [these guys](https://seaborn.pydata.org/examples/scatterplot_matrix.html) instead of what you wrote  -->\n",
        "\n",
        "* Make this a true AutoML program. It's close, but needs some love. For the purposes of this group, and for any other folks that use this code, it doesn't need to be the most efficient thing in the world, it just needs to work. \n",
        "* Scikit-learn speed up through [scikiit-learn-intelex](https://pypi.org/project/scikit-learn-intelex/).\n",
        "* Consider 3D plots for the input space analysis. May be interesting to see how the different operating conditions contribute to error in the 3D domain (you could see correlations across three variables instead of just 2)\n",
        "<!-- * Separate function block into sections --> model functions, plotting functions, etc. Now that it's a monstrous block of code, it's annoying to parse through  -->\n",
        "* Remove all hardcoding. Most of it is removed, but there are still some \"magic numbers\" floating around, specific to the dataset this framework was first trained on. \n",
        "* Make the load/train/save/optimize decision block a bit cleaner. it's ugly\n",
        "* Allow this program to handle any number of fidelity levels -- currently it's written for two levels of fidelity, high and low. \n",
        "* Implement a proper hyperparameter tuning algorithm for the GPR models. Currently, the author of this notebook is leveraging the in-built kernel optimizer and is conducting this optimization in FOR loop. not very efficient or elegant. scikit-optimize would be a more elegant choice, but I found it to not be very user friendly or easy to apply to this particular problem. To get really fancy.... you could try to optimize in parallel, capitalizing on our access to GPUs on DoD HPC or OSC. \n",
        "  * You could also write a FOR loop that adds and multiplies all combinations of the \"standard\" kernels using some combinatorial code. \n",
        "* The \"optimizeKrig\" and \"neuralNetworkConvergence\" codes can be combined/added to the \"modelConvergence\" code. They more or less do the same thing, and you could automate feeding the best results from the first two codes to the input of the \"modelConvergence\" code. Eliminate redundancy\n",
        "  \n",
        "* try different NN architectures (CNNs, GAN, etc.) [keras layers docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers) [keras tuner docs](https://keras.io/api/keras_tuner/hyperparameters/)\n",
        "* Kriging comes with built-in confidence intervals, which I have not integrated. Could be nice to visualize:\n",
        "    plt.fill_between(\n",
        "        X.ravel(),\n",
        "        mean_prediction - 1.96 * std_prediction,\n",
        "        mean_prediction + 1.96 * std_prediction,\n",
        "        alpha=0.5,\n",
        "        label=r\"95% confidence interval\",\n",
        "    )\n",
        "    [sklearn docs for plotting confidence intervals](https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html#sphx-glr-auto-examples-gaussian-process-plot-gpr-noisy-targets-py)\n",
        "\n",
        "* Implement big data GPR techniques [outlined here](https://stats.stackexchange.com/questions/326446/gaussian-process-regression-for-large-datasets) and [here](https://towardsdatascience.com/sparse-and-variational-gaussian-process-what-to-do-when-data-is-large-2d3959f430e7)\n",
        "<!-- * Re-run the RANS CFD at flight operating conditions vice wind tunnel conditions. For example, the range of freestream temperatures don't match up with what a hypersonic vehicle would notionally see in flight. See [here](https://www.digitaldutch.com/atmoscalc/graphs.htm) , derived from [this](https://en.wikipedia.org/wiki/U.S._Standard_Atmosphere#1976_version) -->\n",
        "\n",
        "Other resources \n",
        "https://drive.google.com/drive/u/1/folders/1DxMJgs76tUpL9fw219C9X2atQRkCmmYi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942d7131",
      "metadata": {},
      "source": [
        "# Make Decisions About What You'd Like To Do\n",
        "In the below cell, make some choices about where you're executing this program. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf1cce9",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Surrogate model script started')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "U9Chi2IxxvVd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9Chi2IxxvVd",
        "outputId": "15b622a3-9e57-4eb3-881d-d55bf33342d7"
      },
      "outputs": [],
      "source": [
        "## Are you shipping this code to OSC or DoDHPC? \n",
        "\n",
        "superComputerTrain = False\n",
        "PrintGPUInfo = True\n",
        "\n",
        "## Are you running a quick test of the code, and thus desire short NN train times? \n",
        "\n",
        "quickTestRun = False\n",
        "\n",
        "## What would you like to do?\n",
        "setAll = False\n",
        "\n",
        "loadAll = False\n",
        "trainAll = True\n",
        "saveAll = True\n",
        "optimizeAll = False\n",
        "\n",
        "# Which KerasTuner algorithm would you like to use? \n",
        "# Hyperband or RandomSearch recommended, don't use BayesianOptimization for this problem\n",
        "tunerChoice = 'Hyperband' #or 'RandomSearch' \n",
        "\n",
        "# Would you like to use the original operating conditions (400 case) for the LF models? Or use the LHS populated larger input space (~4000 cases?)\n",
        "# bigInputSpace = 1 for larger input space, = 0 for original operating conditions\n",
        "\n",
        "bigInputSpace = True \n",
        "\n",
        "outlierRemoval = True\n",
        "\n",
        "downsample = True\n",
        "downsampleLF = True\n",
        "visualizeDownsample = True\n",
        "\n",
        "random_state = 30 # used for reproducibility of data splits\n",
        "\n",
        "####################################################################################\n",
        "\n",
        "\n",
        "if setAll:\n",
        "    LFKrigLoad = loadAll\n",
        "    HFKrigLoad = loadAll\n",
        "    MFKrigLoad = loadAll\n",
        "    LFNNLoad = loadAll\n",
        "    HFNNLoad = loadAll\n",
        "    MFNNLoad = loadAll\n",
        "\n",
        "    LFKrigTrain = trainAll\n",
        "    HFKrigTrain = trainAll\n",
        "    MFKrigTrain = trainAll\n",
        "    LFNNTrain = trainAll\n",
        "    HFNNTrain = trainAll\n",
        "    MFNNTrain = trainAll\n",
        "\n",
        "    LFKrigSave = saveAll\n",
        "    HFKrigSave = saveAll\n",
        "    MFKrigSave = saveAll\n",
        "    LFNNSave = saveAll\n",
        "    HFNNSave = saveAll\n",
        "    MFNNSave = saveAll\n",
        "\n",
        "    LFKrigOptimize = optimizeAll\n",
        "    HFKrigOptimize = optimizeAll\n",
        "    MFKrigOptimize = optimizeAll\n",
        "    LFNNOptimize = optimizeAll\n",
        "    HFNNOptimize = optimizeAll\n",
        "    MFNNOptimize = optimizeAll\n",
        "\n",
        "else:\n",
        "    # Low Fidelity Models \n",
        "    LFKrigLoad = 0\n",
        "    LFKrigTrain = 1\n",
        "    LFKrigSave = 1\n",
        "    LFKrigOptimize = 1\n",
        "\n",
        "    LFNNLoad = False\n",
        "    LFNNTrain = 1\n",
        "    LFNNSave = 1\n",
        "    LFNNOptimize = 0\n",
        "    LFNNConvergence = True\n",
        "\n",
        "    # High Fidelity Models \n",
        "    HFKrigLoad = True\n",
        "    HFKrigTrain = 1\n",
        "    HFKrigSave = 1\n",
        "    HFKrigOptimize = 1\n",
        "\n",
        "    HFNNLoad = 0\n",
        "    HFNNTrain = 1\n",
        "    HFNNSave = 1\n",
        "    HFNNOptimize = 1\n",
        "    HFNNConvergence = 1\n",
        "\n",
        "    # Multi Fidelity Models \n",
        "    MFKrigLoad = 0\n",
        "    MFKrigTrain = 1\n",
        "    MFKrigSave = 1\n",
        "    MFKrigOptimize = 1\n",
        "\n",
        "    MFNNLoad = 0\n",
        "    MFNNTrain = 1\n",
        "    MFNNSave = 1\n",
        "    MFNNOptimize = 1\n",
        "    MFNNConvergence = True\n",
        "\n",
        "\n",
        "if LFNNTrain or LFNNLoad or LFNNOptimize:\n",
        "    NN = True\n",
        "else: \n",
        "    NN = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65cc0eb7-c89f-449c-9217-2322a907c606",
      "metadata": {
        "id": "65cc0eb7-c89f-449c-9217-2322a907c606"
      },
      "source": [
        "# Progress Notes\n",
        "\n",
        "To do: \n",
        "- remove all of the x_cc_windowed "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vlOfWOJK9puA",
      "metadata": {
        "id": "vlOfWOJK9puA"
      },
      "source": [
        "# Import Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d51799a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports successful\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'# if you wish to supress TensorFlow debug info, set to 3\n",
        "# import code\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import warnings; warnings.simplefilter('ignore', np.RankWarning)\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 300; plt.rcParams['axes.labelsize'] = 'xx-large';\n",
        "%matplotlib ipympl\n",
        "if not superComputerTrain:\n",
        "    %matplotlib inline\n",
        "    import tqdm\n",
        "    from tqdm.keras import TqdmCallback\n",
        "    from tensorflow.keras import layers\n",
        "# %config InlineBackend.figure_format = 'svg'\n",
        "if NN:\n",
        "    import tensorflow as tf\n",
        "# import warnings\n",
        "# import sklearn\n",
        "import math\n",
        "import datetime\n",
        "# import copy\n",
        "import time\n",
        "import random\n",
        "# import scipy\n",
        "import GPUtil\n",
        "# import skopt\n",
        "import keras_tuner as kt\n",
        "import itertools\n",
        "# import seaborn as sns\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "from matplotlib.widgets import Slider, Button\n",
        "from matplotlib.patches import Rectangle\n",
        "from sklearn import preprocessing\n",
        "from sklearn import gaussian_process\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel, RBF, RationalQuadratic, ExpSineSquared, DotProduct \n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split#, GridSearchCV, RepeatedStratifiedKFold\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras import mixed_precision\n",
        "from scipy.stats import qmc\n",
        "from tabulate import tabulate\n",
        "from string import digits\n",
        "\n",
        "print('Imports successful')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "df40061b",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = os.getcwd() #Set path relative to the open notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "806f923a",
      "metadata": {},
      "source": [
        "# GPU Details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b94ba37a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================== Mixed Precision Policy ========================================\n",
            "======================================== GPU Details ========================================\n",
            "  id  name                  load    free memory    used memory    total memory    temperature    uuid\n",
            "----  --------------------  ------  -------------  -------------  --------------  -------------  ----------------------------------------\n",
            "   0  NVIDIA GeForce MX150  0.0%    1983.0MB       0.0MB          2048.0MB        41.0 °C        GPU-9323180e-3e94-198a-6e30-95e041864620\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17005826932677159015\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 1401808078\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 13271268590297321140\n",
            "physical_device_desc: \"device: 0, name: NVIDIA GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "if PrintGPUInfo:\n",
        "    print(\"=\"*40, \"Mixed Precision Policy\", \"=\"*40)\n",
        "    if superComputerTrain:\n",
        "        policy = mixed_precision.Policy('mixed_float16')\n",
        "        mixed_precision.set_global_policy(policy)\n",
        "    print(\"=\"*40, \"GPU Details\", \"=\"*40)\n",
        "    gpus = GPUtil.getGPUs()\n",
        "    list_gpus = []\n",
        "    for gpu in gpus:\n",
        "        # get the GPU id\n",
        "        gpu_id = gpu.id\n",
        "        # name of GPU\n",
        "        gpu_name = gpu.name\n",
        "        # get % percentage of GPU usage of that GPU\n",
        "        gpu_load = f\"{gpu.load*100}%\"\n",
        "        # get free memory in MB format\n",
        "        gpu_free_memory = f\"{gpu.memoryFree}MB\"\n",
        "        # get used memory\n",
        "        gpu_used_memory = f\"{gpu.memoryUsed}MB\"\n",
        "        # get total memory\n",
        "        gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
        "        # get GPU temperature in Celsius\n",
        "        gpu_temperature = f\"{gpu.temperature} °C\"\n",
        "        gpu_uuid = gpu.uuid\n",
        "        list_gpus.append((\n",
        "            gpu_id, gpu_name, gpu_load, gpu_free_memory, gpu_used_memory,\n",
        "            gpu_total_memory, gpu_temperature, gpu_uuid\n",
        "        ))\n",
        "\n",
        "    print(tabulate(list_gpus, headers=(\"id\", \"name\", \"load\", \"free memory\", \"used memory\", \"total memory\", \"temperature\", \"uuid\")))\n",
        "\n",
        "    print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "47f46bd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "programStart = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8f6df808",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "modelConvergence folder already exists\n",
            "figures folder already exists\n",
            "models folder already exists\n",
            "NN folder already exists\n",
            "NN_convergence folder already exists\n",
            "NN_sizeAndSpeed folder already exists\n",
            "Kriging folder already exists\n",
            "Current location:  c:\\Users\\tyler\\Desktop\\oscDataPackage\n"
          ]
        }
      ],
      "source": [
        "figureDir = \"figures\"\n",
        "modelDir = \"models\"\n",
        "NNDir = \"NN\"\n",
        "krigDir = \"Kriging\"\n",
        "modelConvStudyDir = \"modelConvergence\"\n",
        "convStudyDir = \"NN_convergence\"\n",
        "sizeAndSpeedDir = \"NN_sizeAndSpeed\"\n",
        "\n",
        "path_parent = os.path.dirname(os.getcwd())\n",
        "os.chdir(path_parent)\n",
        "\n",
        "tunerDirName = 'tuner' + str(datetime.date.today())\n",
        "tunerDir = os.path.join(os.getcwd(), tunerDirName)\n",
        "try: \n",
        "    os.mkdir(tunerDirName)\n",
        "except: \n",
        "    pass \n",
        "\n",
        "os.chdir(path)\n",
        "\n",
        "try: \n",
        "    os.chdir(path)\n",
        "    os.mkdir(modelConvStudyDir)\n",
        "    os.chdir(path)\n",
        "    print(modelConvStudyDir+ ' folder created') \n",
        "except:\n",
        "    print(modelConvStudyDir+ ' folder already exists') \n",
        "    pass \n",
        "\n",
        "try: \n",
        "    os.chdir(path)\n",
        "    os.mkdir(figureDir)\n",
        "    os.chdir(path)\n",
        "    print(figureDir+ ' folder created') \n",
        "except:\n",
        "    print(figureDir+ ' folder already exists') \n",
        "    pass \n",
        "\n",
        "try:\n",
        "    os.chdir(path)\n",
        "    os.mkdir(modelDir)\n",
        "    os.chdir(path)\n",
        "    print(modelDir+ ' folder created') \n",
        "except:\n",
        "    print(modelDir +' folder already exists') \n",
        "    pass \n",
        "\n",
        "try:\n",
        "    os.chdir(path) \n",
        "    os.chdir(modelDir)\n",
        "    os.mkdir(NNDir)\n",
        "    os.chdir(path)\n",
        "    print(NNDir+ ' folder created') \n",
        "except:\n",
        "    print(NNDir +' folder already exists') \n",
        "    pass \n",
        "\n",
        "try: \n",
        "    os.chdir(os.path.join(path,modelDir,NNDir))\n",
        "    os.mkdir(convStudyDir)\n",
        "    os.chdir(path)\n",
        "    print(convStudyDir+ ' folder created') \n",
        "except:\n",
        "    print(convStudyDir +' folder already exists') \n",
        "    pass \n",
        "\n",
        "try: \n",
        "    os.chdir(os.path.join(path,modelDir,NNDir))\n",
        "    os.mkdir(sizeAndSpeedDir)\n",
        "    os.chdir(path)\n",
        "    print(sizeAndSpeedDir+ ' folder created') \n",
        "except:\n",
        "    print(sizeAndSpeedDir +' folder already exists') \n",
        "    pass \n",
        "\n",
        "try: \n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir)\n",
        "    os.mkdir(krigDir)\n",
        "    os.chdir(path)\n",
        "    print(krigDir+ ' folder created') \n",
        "except:\n",
        "    print(krigDir +' folder already exists') \n",
        "    pass \n",
        "\n",
        "\n",
        "os.chdir(path)\n",
        "print('Current location: ', os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "535685f3",
      "metadata": {},
      "source": [
        "# General Information "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca5975f0",
      "metadata": {},
      "source": [
        "## Neural Network Choices\n",
        "[Choice in optimizer](https://keras.io/api/optimizers/adamax/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f933d9",
      "metadata": {},
      "source": [
        "### Visualization things\n",
        "\n",
        "https://github.com/3b1b/manim\n",
        "https://github.com/ManimCommunity/manim/blob/main/README.md#documentation\n",
        "https://www.youtube.com/watch?v=HnIeAP--vWc&t=8s\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c9ad765-1da2-4d52-a655-3be2cdb9c36e",
      "metadata": {
        "id": "9c9ad765-1da2-4d52-a655-3be2cdb9c36e"
      },
      "source": [
        "# Functions and Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d703a4",
      "metadata": {},
      "source": [
        "## I/O Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a5f3ba02",
      "metadata": {},
      "outputs": [],
      "source": [
        "def saveVersionedPickle(filename, objectToSave, path):\n",
        "    baseName = filename\n",
        "    counter = 2\n",
        "    ext = '.pkl'\n",
        "    dt = str(datetime.date.today())\n",
        "    while os.path.exists('./' + filename + '_' + dt + ext):\n",
        "        filename = baseName + '_v' + str(counter)\n",
        "        counter += 1\n",
        "\n",
        "    filename += '_' + dt + ext\n",
        "    os.chdir(path)\n",
        "    pickle.dump(objectToSave, open(filename, 'wb'))\n",
        "    os.chdir(path)\n",
        "\n",
        "def get_dir_size(path='.'):\n",
        "    total = 0\n",
        "    with os.scandir(path) as it:\n",
        "        for entry in it:\n",
        "            if entry.is_file():\n",
        "                total += entry.stat().st_size\n",
        "            elif entry.is_dir():\n",
        "                total += get_dir_size(entry.path)\n",
        "    return total\n",
        "\n",
        "def variableChecker(stringToTest):\n",
        "    if stringToTest in globals():\n",
        "        print('Global variable')\n",
        "    else: \n",
        "        print('Not global variable')\n",
        "\n",
        "    if stringToTest in locals():\n",
        "        print('Local variable')\n",
        "    else: \n",
        "        print('Not local variable')\n",
        "\n",
        "def saveNN(fidelityLevel):\n",
        "\n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir + '/' + NNDir)\n",
        "    kerasFolderName = fidelityLevel + '_NN_'\n",
        "    dt = str(datetime.date.today())\n",
        "    kerasFolderName += dt\n",
        "\n",
        "    kerasPath = makeNewUniqueDir(baseName = kerasFolderName)\n",
        "\n",
        "\n",
        "    modelName = fidelityLevel + '_NN'\n",
        "    model = globals()[modelName]\n",
        "    tf.get_logger().setLevel('WARNING')\n",
        "    model.save(kerasPath)\n",
        "    \n",
        "    os.chdir(kerasPath)\n",
        "    epochsName = modelName + '_epochs'\n",
        "    historyName = modelName + '_history'\n",
        "    epochsDict = globals()[epochsName]\n",
        "    historyDict = globals()[historyName]\n",
        "\n",
        "    epochsFilename = epochsName\n",
        "    historyFilename = historyName\n",
        "    dt = str(datetime.date.today())\n",
        "    ext = '.pkl'\n",
        "    epochsFilename += '_' + dt + ext\n",
        "    historyFilename += '_' + dt + ext\n",
        "    pickle.dump(epochsDict, open(epochsFilename, 'wb'))\n",
        "    pickle.dump(historyDict, open(historyFilename, 'wb'))\n",
        "\n",
        "    os.chdir(path)\n",
        "\n",
        "def loadNN(neuralNetFolderName):\n",
        "    # Loading the NN is a bit easier-- but you'll need to specify the path. An example path is included already, \n",
        "    # which will need to be edited if you wish to load a different model. \n",
        "    os.chdir(path)\n",
        "    loadFolderPath = path + '\\\\\\\\' + modelDir + '\\\\\\\\' + NNDir + '\\\\\\\\' + neuralNetFolderName\n",
        "    os.chdir(loadFolderPath)\n",
        "    loadedModelName = neuralNetFolderName[0:2] + '_NN'\n",
        "\n",
        "    globals()[loadedModelName] = keras.models.load_model(loadFolderPath)\n",
        "\n",
        "    ### Load History and Epochs\n",
        "\n",
        "    desiredLoadedEpochsName = loadedModelName + '_epochs'\n",
        "    desiredLoadedHistoryName = loadedModelName + '_history'\n",
        "\n",
        "    epochsFileName = desiredLoadedEpochsName + neuralNetFolderName[5:] + '.pkl'\n",
        "    historyFileName =  desiredLoadedHistoryName + neuralNetFolderName[5:] + '.pkl'\n",
        "\n",
        "    globals()[desiredLoadedEpochsName] = pickle.load(open(epochsFileName, 'rb'))\n",
        "    globals()[desiredLoadedHistoryName] = pickle.load(open(historyFileName, 'rb'))\n",
        "\n",
        "    print(loadedModelName + ' loaded!!!!')\n",
        "    os.chdir(path)\n",
        "\n",
        "def loadConvStudyNN(convStudyFolderName, fidelityLevel, layerConfiguration):\n",
        " \n",
        "    os.chdir(path)\n",
        "\n",
        "    #generate layer config string for directory search \n",
        "    s = str(layerConfiguration)\n",
        "    originalLayerConfigString = s\n",
        "    disallowed_characters = '[] '\n",
        "\n",
        "    for char in disallowed_characters:\n",
        "        s = s.replace(char, '')\n",
        "    s = s.replace(',','_')\n",
        "    layerConfigString = s\n",
        "\n",
        "    loadFolderPath = path + '\\\\\\\\' + modelDir + '\\\\\\\\' + NNDir + '\\\\\\\\' + convStudyDir + '\\\\\\\\' + convStudyFolderName\n",
        "    os.chdir(loadFolderPath)\n",
        "    loadedModelName = fidelityLevel + '_NN'\n",
        "    loadedDictName = fidelityLevel + 'convStudyDict'\n",
        "    pklName = glob.glob('*.pkl')\n",
        "    if len(pklName) > 1:\n",
        "        raise Exception('ERROR: More than one .pkl file in current directory. Remove extra .pkl or load all files manually')\n",
        "    pklName = pklName[0]\n",
        "\n",
        "    globals()[loadedDictName] = pickle.load(open(pklName, 'rb'))\n",
        "\n",
        "    modelDirKeywords = layerConfigString + fidelityLevel + \"*\"\n",
        "    modelDirName = glob.glob(modelDirKeywords)\n",
        "    if len(modelDirName) > 1:\n",
        "        raise Exception('ERROR: More than one directory with ' + str(layerConfiguration) + 'configuration. Remove extra directory or load manually')\n",
        "    modelDirName = modelDirName[0]\n",
        "\n",
        "    loadFolderPath = os.path.join(loadFolderPath, modelDirName)\n",
        "\n",
        "    globals()[loadedModelName] = keras.models.load_model(loadFolderPath)\n",
        "\n",
        "    ### Load History and Epochs\n",
        "\n",
        "    loadedEpochsName = loadedModelName + '_epochs'\n",
        "    loadedHistoryName = loadedModelName + '_history'\n",
        "\n",
        "    globals()[loadedEpochsName] = globals()[loadedDictName][originalLayerConfigString]['epochs']\n",
        "    globals()[loadedHistoryName] = globals()[loadedDictName][originalLayerConfigString]['history']\n",
        "\n",
        "    print(loadedModelName + ' loaded!!!!')\n",
        "    print(loadedEpochsName + ' loaded!!!!')\n",
        "    print(loadedHistoryName + ' loaded!!!!')\n",
        "    os.chdir(path)\n",
        "\n",
        "def saveKrig(fidelityLevel):\n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir + '/' + krigDir)\n",
        "    modelName = fidelityLevel + '_krig'\n",
        "    model = globals()[modelName]\n",
        "    filename = modelName + '_'\n",
        "    dt = str(datetime.date.today())\n",
        "    ext = '.sav'\n",
        "    filename += dt + ext\n",
        "    pickle.dump(model, open(filename, 'wb'))\n",
        "    os.chdir(path)\n",
        "\n",
        "def loadBatchTest(filename,DFname,printDF):\n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir + '/' + NNDir)\n",
        "    globals()[DFname] = pd.read_pickle(\"./\"+filename)  \n",
        "    print('Loaded: ' ,DFname)\n",
        "    if printDF:\n",
        "        print(globals()[DFname])\n",
        "    os.chdir(path)\n",
        "\n",
        "def loadTunerPKL(filename):\n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir + '/' + NNDir)\n",
        "    globals()['tuner'] = pd.read_pickle(\"./\"+filename)  \n",
        "    print('Loaded: ' ,filename)\n",
        "    os.chdir(path)\n",
        "\n",
        "def requiredMemoryCalculator(sizeData):\n",
        "    requiredMem = sizeData*8 * 9.31e-10\n",
        "    print('Memory required for Kriging: ', round(requiredMem,4), 'Gigabytes')\n",
        "\n",
        "def loadKrigOpt(filename,dictName,printKeys):\n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir + '/' + krigDir)\n",
        "    globals()[dictName] = pd.read_pickle(\"./\"+filename)  \n",
        "    print('Loaded: ' ,dictName)\n",
        "    if printKeys:\n",
        "        print(globals()[dictName].keys())\n",
        "    os.chdir(path)\n",
        "\n",
        "def saveTuner(tuner, fidelityLevel):\n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir + '/' + NNDir)\n",
        "    filename = 'tunerPickle_' + fidelityLevel + '_'\n",
        "    dt = str(datetime.date.today())\n",
        "    ext = '.pkl'\n",
        "    filename += dt + ext\n",
        "    f = open(filename, 'wb')\n",
        "    pickle.dump(tuner, f)\n",
        "    f.close()\n",
        "    print(filename, 'saved at location: ',path, modelDir ,'\\\\' ,NNDir)\n",
        "    os.chdir(path)\n",
        "\n",
        "\n",
        "def makeNewUniqueDir(baseName):\n",
        "    counter = 2\n",
        "    newDir = baseName\n",
        "\n",
        "    while os.path.exists(newDir):\n",
        "\n",
        "        newDir = baseName + '_v' + str(counter)\n",
        "        counter += 1\n",
        "\n",
        "    os.mkdir(newDir)\n",
        "    return newDir\n",
        "\n",
        "#I wrote this function like a moron. There is a nice way to make this recursive, take a look at the function measures the memory of a directory. This works for what I wanted it to do though. :-) \n",
        "def twoLevelDictStructurePrint(userDict):\n",
        "    for key in userDict.keys():\n",
        "        print(key)\n",
        "        try:\n",
        "            keyList = [item for item in userDict[key].keys()]\n",
        "            print(\"    \", keyList)\n",
        "            for item in keyList:\n",
        "                nestedList = [item for item in userDict[key][item]]\n",
        "                print(\"        \",nestedList)\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a804c7b",
      "metadata": {},
      "source": [
        "## Plotting Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "4062d441",
      "metadata": {},
      "outputs": [],
      "source": [
        "def oneToOneVisualizationPlotAllData(\n",
        "    case, qw_test_predict,p_test_predict, qw_test_truth, p_test_truth, M_inf_test, method\n",
        "    ):\n",
        "\n",
        "    plt.rcParams[\"figure.figsize\"] = (15,10)\n",
        "    fig, axs = plt.subplots(2, 2)\n",
        "    fig.tight_layout(pad=1.08, w_pad=1.5, h_pad=4)\n",
        "    fig.patch.set_facecolor('white')\n",
        "\n",
        "    dt = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    figName = 'colorMap' + '_' + method + '_' + dt\n",
        "\n",
        "    elbowLocation = 2.35\n",
        "    case = case\n",
        "    cm = plt.cm.get_cmap('cool')\n",
        "    zmax = 2.5\n",
        "    z = np.arange(0,zmax, zmax/qw_test_predict[case,:].shape[0])\n",
        "    #plot one case only\n",
        "    labelstr = 'Mach inf: ' + str(M_inf_test[case]) + ',case:' + str(case)\n",
        "    maxHeatTransfer = qw_test_predict[case,:].max()\n",
        "    maxPressure = p_test_predict[case,:].max()\n",
        "\n",
        "    ################### HEAT TRANSFER ########################\n",
        "    x = qw_test_predict[case,:]/maxHeatTransfer\n",
        "    y = qw_test_truth[case,:]/maxHeatTransfer\n",
        "    sc = axs[0,0].scatter(x, y ,c = z, s=80, label = labelstr, \n",
        "                     cmap=cm,edgecolors='none',vmin=0,vmax=2.5 )\n",
        "    cbar = fig.colorbar(sc,ax = axs[0,0])\n",
        "    cbar.ax.set_title(\"x-location (meters)\")\n",
        "    cbar.ax.plot([0, zmax], [elbowLocation]*2, 'w')\n",
        "    axs[0,0].plot([0, 1], [0, 1], color = 'k')\n",
        "\n",
        "    caseNRMSE = str(round(100*normalizedRootMeanSquaredError(qw_test_truth[case,:],qw_test_predict[case,:]),4))\n",
        "    caseR2 =  str(round(r2_score(qw_test_truth[case,:], qw_test_predict[case,:]),4))\n",
        "    plotTextBox = 'R2: ' + caseR2 + '\\n' + 'NRMSE: ' + caseNRMSE + '%'\n",
        "\n",
        "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "    axs[0,0].text(0.05, 0.85, plotTextBox, transform=axs[0,0].transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
        "    # axs[0,0].set_title(\"Heat Transfer Predicitions vs Actual\")\n",
        "    axs[0,0].grid()\n",
        "    axs[0,0].set_ylabel(\"True Value\")\n",
        "    axs[0,0].set_xlabel(\"Predicted Heat Transfer\")\n",
        "\n",
        "    #############################################\n",
        "\n",
        "    axs1label = method + ' Prediction'\n",
        "    sliceVal = 20 # this is the \"ol' fashioned way\" for the plt.plot argument \"markevery=sliceVal.\" The command doesn't work in plt.scatter\n",
        "\n",
        "    # plt.plot(theta_rbf, Tw_rbf, color='black', linestyle='solid', linewidth=2, marker='D', markersize=6,     mfc='white', markevery=5, label='RBF')\n",
        "    axs[0,1].plot(x_cc_sorted[0,idxWindowStart:], qw_test_truth[case,:]/maxHeatTransfer, color='firebrick', \n",
        "                linestyle='solid', linewidth=4, label='Truth Data')\n",
        "\n",
        "    axs[0,1].plot(x_cc_sorted[0,idxWindowStart:], qw_test_predict[case,:]/maxHeatTransfer, \n",
        "                color='black', linestyle='-.', linewidth=2, label=axs1label)\n",
        "    # axs[0,1].set_title(\"Predicted Heat Transfer\",fontsize='x-large')\n",
        "    axs[0,1].set_ylabel(\"qw / qw_max\", fontsize='x-large')\n",
        "    axs[0,1].set_xlabel('x (meters)')\n",
        "\n",
        "    axs[0,1].legend(fontsize='x-large')\n",
        "\n",
        "    ############### PRESSURE ##################\n",
        "    # \n",
        "    x = p_test_predict[case,:]/maxPressure\n",
        "    y = p_test_truth[case,:]/maxPressure\n",
        "    sc = axs[1,0].scatter(x, y ,c = z, s=80, label = labelstr, \n",
        "                     cmap=cm,edgecolors='none',vmin=0,vmax=2.5 )\n",
        "    cbar = fig.colorbar(sc,ax = axs[1,0])\n",
        "    cbar.ax.set_title(\"x-location (meters)\")\n",
        "    cbar.ax.plot([0, zmax], [elbowLocation]*2, 'w')\n",
        "    axs[1,0].plot([0, 1], [0, 1], color = 'k')\n",
        "\n",
        "    caseNRMSE = str(round(100*normalizedRootMeanSquaredError(p_test_truth[case,:],p_test_predict[case,:]),4))\n",
        "    caseR2 =  str(round(r2_score(p_test_truth[case,:], p_test_predict[case,:]),4))\n",
        "    plotTextBox = 'R2: ' + caseR2 + '\\n' + 'NRMSE: ' + caseNRMSE + '%'\n",
        "\n",
        "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "    axs[1,0].text(0.05, 0.85, plotTextBox, transform=axs[1,0].transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
        "    # axs[1,0].set_title(\"Pressure Predicitions vs Actual\")\n",
        "    axs[1,0].grid()\n",
        "    axs[1,0].set_ylabel(\"True Value\")\n",
        "    axs[1,0].set_xlabel(\"Predicted Pressure\")\n",
        "\n",
        "    #############################################\n",
        "\n",
        "    axs1label = method + ' Prediction'\n",
        "    sliceVal = 20 # this is the \"ol' fashioned way\" for the plt.plot argument \"markevery=sliceVal.\" The command doesn't work in plt.scatter\n",
        "\n",
        "    # plt.plot(theta_rbf, Tw_rbf, color='black', linestyle='solid', linewidth=2, marker='D', markersize=6,     mfc='white', markevery=5, label='RBF')\n",
        "    axs[1,1].plot(x_cc_sorted[0,idxWindowStart:], p_test_truth[case,:]/maxPressure, color='firebrick', \n",
        "                linestyle='solid', linewidth=4, label='Truth Data')\n",
        "\n",
        "    axs[1,1].plot(x_cc_sorted[0,idxWindowStart:], p_test_predict[case,:]/maxPressure, \n",
        "                color='black', linestyle='-.', linewidth=2, label=axs1label)\n",
        "    # axs[1,1].set_title(\"Predicted Pressure\",fontsize='x-large')\n",
        "    axs[1,1].set_ylabel(\"p / p_max\", fontsize='x-large')\n",
        "    axs[1,1].set_xlabel('x (meters)')\n",
        "\n",
        "    axs[1,1].legend(fontsize='x-large')\n",
        "\n",
        "\n",
        "    os.chdir(figureDir)\n",
        "    plt.savefig(figName)\n",
        "    os.chdir(path)\n",
        "\n",
        "def oneToOnePlotTool(method, desiredNumCasesForPlot, X_test, qw_prediction, qw_truth, p_prediction, p_truth):\n",
        "\n",
        "    totalCases = X_test.shape[0]\n",
        "    casePlotRange= np.arange(0,totalCases,int((totalCases/desiredNumCasesForPlot)))\n",
        "\n",
        "    plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=.5)\n",
        "    fig.patch.set_facecolor('white')\n",
        "\n",
        "    dt = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    figName = 'oneToOneForManyCases' + '_' + method + '_' + dt\n",
        "\n",
        "    for case in casePlotRange:\n",
        "        labelstr = 'Case: ' + str(case)\n",
        "        maxHeatTransfer = max(qw_prediction[case,:].max(),qw_truth[case,:].max())\n",
        "        maxPressure = max(p_prediction[case,:].max(),p_truth[case,:].max())\n",
        "        axs[0].scatter(qw_prediction[case,:]/maxHeatTransfer,qw_truth[case,:]/maxHeatTransfer, s=1, label = labelstr )\n",
        "        axs[1].scatter(p_prediction[case,:]/maxPressure,p_truth[case,:]/maxPressure, s=1, label = labelstr)\n",
        "\n",
        "    qwCaseNRMSE = str(round(100*normalizedRootMeanSquaredError(qw_truth,qw_prediction),4))\n",
        "    pCaseNRMSE = str(round(100*normalizedRootMeanSquaredError(p_truth,p_prediction),4))\n",
        "    qwCaseR2 =  str(round(r2_score(qw_truth, qw_prediction),4))\n",
        "    pCaseR2 =  str(round(r2_score(p_truth, p_prediction),4))\n",
        "    qwPlotTextBox = 'R2: ' + qwCaseR2 + '\\n' + 'NRMSE: ' + qwCaseNRMSE + '%'\n",
        "    pPlotTextBox = 'R2: ' + pCaseR2 + '\\n' + 'NRMSE: ' + pCaseNRMSE + '%'\n",
        "\n",
        "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "    axs[0].text(0.05, 0.85, qwPlotTextBox, transform=axs[0].transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
        "    axs[1].text(0.05, 0.85, pPlotTextBox, transform=axs[1].transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
        "    \n",
        "    axs[0].plot([0, 1], [0, 1], color = 'grey', zorder = 0)\n",
        "    axs[1].plot([0, 1], [0, 1], color = 'grey', zorder = 0)\n",
        "\n",
        "    axs0title = method + \" Heat Transfer Predicitions vs Actual\"\n",
        "    axs1title = method + \" Pressure Predictions vs. Actual\"\n",
        "    axs[0].set_title(axs0title)\n",
        "    axs[1].set_title(axs1title)\n",
        "    axs[0].grid()\n",
        "    axs[1].grid()\n",
        "    axs[0].set_ylabel(\"True Value\")\n",
        "    axs[0].set_xlabel(\"Predicted Heat Transfer\")\n",
        "    axs[1].set_xlabel(\"Predicted Pressure\")\n",
        "    os.chdir(path)\n",
        "    os.chdir(figureDir)\n",
        "    plt.savefig(figName)\n",
        "    os.chdir(path)\n",
        "\n",
        "def plotPressureHeatTransferSideBySide(case, qw_test_predict,p_test_predict, qw_test_truth, p_test_truth, method):\n",
        "    sliceVal = 20 # this is the \"ol' fashioned way\" for the plt.plot argument \"markevery=sliceVal.\" The command doesn't work in plt.scatter\n",
        "\n",
        "    plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    fig.tight_layout(pad=0.4, w_pad=2.0, h_pad=1.5)\n",
        "    fig.patch.set_facecolor('white')\n",
        "\n",
        "    maxHeatTransfer = max(qw_test_predict[case,:].max(),qw_test_truth[case,:].max())\n",
        "    maxPressure = max(p_test_predict[case,:].max(),p_test_truth[case,:].max())\n",
        "\n",
        "    # plt.plot(theta_rbf, Tw_rbf, color='black', linestyle='solid', linewidth=2, marker='D', markersize=6,     mfc='white', markevery=5, label='RBF')\n",
        "    axs[0].plot(x_cc_sorted[0,idxWindowStart:], qw_test_truth[case,:]/maxHeatTransfer, color='firebrick', linestyle='solid', linewidth=4, label='Truth Data')\n",
        "    axs[0].scatter(x_cc_sorted[0,idxWindowStart::sliceVal], qw_test_predict[case,::sliceVal]/maxHeatTransfer, c='white',\n",
        "                zorder=3,edgecolors='black', marker='D', s=70, label=method + ' Prediction')\n",
        "    axs[0].set_title(\"Predicted Heat Transfer\",fontsize='x-large')\n",
        "    axs[0].set_ylabel(\"qw / qw_max\", fontsize='x-large')\n",
        "\n",
        "    # plt.plot(theta_rbf, Tw_rbf, color='black', linestyle='solid', linewidth=2, marker='D', markersize=6,     mfc='white', markevery=5, label='RBF')\n",
        "    axs[1].plot(x_cc_sorted[0,idxWindowStart:], p_test_truth[case,:]/maxPressure, color='black', linestyle='solid', linewidth=4, label='Truth Data')\n",
        "    axs[1].scatter(x_cc_sorted[0,idxWindowStart::sliceVal], p_test_predict[case,::sliceVal]/maxPressure, c='white',\n",
        "                zorder=3,edgecolors='black', marker='D', s=70, label=method + ' Prediction')\n",
        "    axs[1].set_title(\"Predicted Pressure\", fontsize='x-large')\n",
        "    axs[1].set_ylabel(\"P/P_max\", fontsize='x-large')\n",
        "\n",
        "    for i in np.arange(0,len(axs)):\n",
        "        # axs[i].grid()\n",
        "        axs[i].legend(fontsize='x-large')\n",
        "        axs[i].set_xlabel('x (meters)',fontsize='x-large')\n",
        "        # axs[i].text(0.05, 0.55, textstr, transform=axs[i].transAxes, fontsize=14,\n",
        "        #     verticalalignment='top', bbox=props)\n",
        "\n",
        "    dt = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    figName = 'pressureHeatTransferSideBySide' + '_' + method + '_' + dt\n",
        "    os.chdir(path)\n",
        "    os.chdir(figureDir)\n",
        "    plt.savefig(figName)\n",
        "    os.chdir(path)\n",
        "        \n",
        "def plotTrainAndTestLoss(historyDict,mseNames, colorList, fidelityLevel, epochRangeBegin=0,epochRangeEnd=None,):\n",
        "    if epochRangeEnd == None:\n",
        "        epochRangeEnd = len(historyDict['loss'])\n",
        "    numValMSECount = sum(1 for string in mseNames if string.find('val') != -1)\n",
        "    valMSEArray = np.zeros(((numValMSECount,epochRangeEnd)))\n",
        "    minMSEArray = np.empty((numValMSECount,1))\n",
        "    count = 0\n",
        "\n",
        "    for color,mse in enumerate(mseNames): \n",
        "        plt.semilogy(range(1,len(historyDict[mse][epochRangeBegin:epochRangeEnd]) + 1),\n",
        "         historyDict[mse][epochRangeBegin:epochRangeEnd],\n",
        "         label=mse,linestyle=\"-\", color=colorList[color])\n",
        "        if mse.find('val') != -1: \n",
        "            minMSEEpochNum = np.argmin(historyDict[mse])\n",
        "            plt.axvline(x = minMSEEpochNum, linestyle='dashdot', label=mse + ' minimum', color=colorList[color])\n",
        "            minMSEArray[count] = minMSEEpochNum\n",
        "            valMSEArray[count,:] = historyDict[mse]\n",
        "            print('Minimum validation MSE for ' + mse + ' is at epoch number ' + str(minMSEEpochNum) )\n",
        "            count += 1\n",
        "    \n",
        "    # summedValMSEArray = valMSEArray.sum(axis=0)\n",
        "\n",
        "    plt.title(fidelityLevel + \" Neural Network Loss\")\n",
        "    plt.legend(loc=0)\n",
        "    plt.grid()\n",
        "    # print('Average min epoch number: ' + str(np.mean(minMSEArray)))\n",
        "    # print('Epoch number, minimum, all val error added: ' + str(np.argmin(summedValMSEArray)))\n",
        "    dt = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    figName = 'trainAndTestLoss' + '_' + fidelityLevel + '_' + dt\n",
        "    os.chdir(path)\n",
        "    os.chdir(figureDir)\n",
        "    plt.savefig(figName)\n",
        "    os.chdir(path)\n",
        "\n",
        "def plotAverageDistributions(qw_test_predict,p_test_predict, qw_test_truth, p_test_truth, method, fidelityLevel):\n",
        "    totalCases = len(qw_test_truth[:,0])\n",
        "    sliceVal = 20 # this is the \"ol' fashioned way\" for the plt.plot argument \"markevery=sliceVal.\" The command doesn't work in plt.scatter\n",
        "\n",
        "    plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    fig.tight_layout(pad=0.4, w_pad=2.0, h_pad=1.5)\n",
        "    fig.patch.set_facecolor('white')\n",
        "\n",
        "    mean_qw_test_predict = np.mean(qw_test_predict, axis=0)\n",
        "    mean_p_test_predict = np.mean(p_test_predict, axis=0)\n",
        "\n",
        "    mean_qw_test_truth = np.mean(qw_test_truth, axis=0)\n",
        "    mean_p_test_truth = np.mean(p_test_truth, axis=0)\n",
        "\n",
        "    maxHeatTransfer = max(mean_qw_test_predict.max(), mean_qw_test_truth.max())\n",
        "    maxPressure = max(mean_p_test_predict.max(),mean_p_test_truth.max())\n",
        "\n",
        "    # plt.plot(theta_rbf, Tw_rbf, color='black', linestyle='solid', linewidth=2, marker='D', markersize=6,     mfc='white', markevery=5, label='RBF')\n",
        "    axs[0].plot(x_cc_sorted[0,idxWindowStart:], mean_qw_test_truth/maxHeatTransfer, color='firebrick', linestyle='solid', linewidth=4, label='Average Truth Data Distribution')\n",
        "    axs[0].scatter(x_cc_sorted[0,idxWindowStart::sliceVal], mean_qw_test_predict[::sliceVal]/maxHeatTransfer, c='white',\n",
        "                zorder=3,edgecolors='black', marker='D', s=70, label='Average '+ method + ' Prediction')\n",
        "    axs[0].set_title(\"Predicted Heat Transfer\",fontsize='x-large')\n",
        "    axs[0].set_ylabel(\"qw / qw_max\", fontsize='x-large')\n",
        "\n",
        "    # plt.plot(theta_rbf, Tw_rbf, color='black', linestyle='solid', linewidth=2, marker='D', markersize=6,     mfc='white', markevery=5, label='RBF')\n",
        "    axs[1].plot(x_cc_sorted[0,idxWindowStart:], mean_p_test_truth/maxPressure, color='black', linestyle='solid', linewidth=4, label='Average Truth Data Distribution')\n",
        "    axs[1].scatter(x_cc_sorted[0,idxWindowStart::sliceVal], mean_p_test_predict[::sliceVal]/maxPressure, c='white',\n",
        "                zorder=3,edgecolors='black', marker='D', s=70, label='Average '+ method + ' Prediction')\n",
        "    axs[1].set_title(\"Predicted Pressure\", fontsize='x-large')\n",
        "    axs[1].set_ylabel(\"P/P_max\", fontsize='x-large')\n",
        "\n",
        "    for i in np.arange(0,len(axs)):\n",
        "        # axs[i].grid()\n",
        "        axs[i].legend(fontsize='x-large')\n",
        "        axs[i].set_xlabel('x (meters)',fontsize='x-large')\n",
        "        # axs[i].text(0.05, 0.55, textstr, transform=axs[i].transAxes, fontsize=14,\n",
        "        #     verticalalignment='top', bbox=props)\n",
        "    dt = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    figName = 'averageDistribution' + '_' + fidelityLevel + '_' + method + '_' + dt\n",
        "    os.chdir(path)\n",
        "    os.chdir(figureDir)\n",
        "    plt.savefig(figName)\n",
        "    os.chdir(path)\n",
        "\n",
        "def kerasPlotModel(model,fidelityLevel):\n",
        "    os.chdir(path)\n",
        "    os.chdir(figureDir)\n",
        "    dt = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    figName = 'modelGraph' + '_' + fidelityLevel + '_' + dt\n",
        "    try:\n",
        "        tf.keras.utils.plot_model(\n",
        "            model = model,\n",
        "            to_file = figName,\n",
        "            show_shapes=True,\n",
        "            show_dtype=True,\n",
        "            show_layer_activations=True\n",
        "            )\n",
        "        print('Successfully saved model graph via plot_model')\n",
        "    except:\n",
        "        print('Can\\'t use \\'plot model\\', probably missing graphviz')\n",
        "\n",
        "    os.chdir(path)\n",
        "\n",
        "def plotPressureHeatTransferSideBySideTruthData(caseIndexArray, qw_truth, p_truth):\n",
        "    plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    fig.patch.set_facecolor('white')\n",
        "    xStart = 0\n",
        "    for case in caseIndexArray:\n",
        "        # axs[0].plot(x_cc_sorted[0,idxWindowStart:], qw_truth[case,:], linewidth=2, label='Case: ' + str(case))\n",
        "        axs[0].semilogy(x_cc_windowed[0,xStart:], qw_truth[case,xStart:].reshape(-1,),label='Case: ' + str(case),linewidth=1)\n",
        "        axs[0].set_title(\"Truth Heat Transfer\",fontsize='x-large')\n",
        "        axs[0].set_ylabel(\"qw\", fontsize='x-large')\n",
        "\n",
        "        # axs[1].plot(x_cc_sorted[0,idxWindowStart:], p_truth[case,:], linewidth=2, label='Case: ' + str(case))\n",
        "        axs[1].semilogy(x_cc_windowed[0,xStart:], p_truth[case,xStart:].reshape(-1,),label='Case: ' + str(case),linewidth=1)\n",
        "        axs[1].set_title(\"Truth Pressure\",fontsize='x-large')\n",
        "        axs[1].set_ylabel(\"p\", fontsize='x-large')\n",
        "\n",
        "    for i in np.arange(0,len(axs)):\n",
        "        axs[i].legend(fontsize='x-large')\n",
        "        axs[i].set_xlabel('x (meters)',fontsize='x-large')\n",
        "\n",
        "    dt = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    figName = 'plotPressureHeatTransferSideBySideTruthData_' + dt\n",
        "    os.chdir(path)\n",
        "    os.chdir(figureDir)\n",
        "    plt.savefig(figName)\n",
        "    os.chdir(path)\n",
        "\n",
        "def plotNNConvergence(fidelityLevel, numParamsList, MSElist, convStudyLayerList, savePlot):\n",
        "    plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "    figName = 'NNconvergence' + fidelityLevel + '_'\n",
        "    dt = str(datetime.date.today())\n",
        "    figName += dt\n",
        "    fig, ax = plt.subplots(constrained_layout=True)\n",
        "    ax.scatter(numParamsList, MSElist, label = 'data')\n",
        "    if fidelityLevel == 'LF':\n",
        "        outputVarNames_local = LFoutputVarNames\n",
        "    else: \n",
        "        outputVarNames_local = outputVarNames\n",
        "\n",
        "    totalParamsTrainData_local = 0\n",
        "    for var in outputVarNames_local:\n",
        "        totalParamsTrainData_local += globals()[var].shape[0] * globals()[var].shape[1]\n",
        "\n",
        "    annotations = [str(item) for item in convStudyLayerList]\n",
        "\n",
        "    for i, label in enumerate(annotations):\n",
        "        ax.annotate(label, (numParamsList[i], MSElist[i]))\n",
        "\n",
        "    ax.set_xlabel('Number of Neural Network Parameters')\n",
        "    ax.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
        "    ax.set_ylabel('Validation MSE')\n",
        "    ax.set_title(fidelityLevel + ' Neural Network Convergence')\n",
        "\n",
        "    def num2percentage(x):\n",
        "        return (x / totalParamsTrainData_local)*100\n",
        "\n",
        "    def percentage2num(x):\n",
        "        return (x * totalParamsTrainData_local)/100\n",
        "\n",
        "    secax = ax.secondary_xaxis('top', functions=(num2percentage, percentage2num))\n",
        "    secax.set_xlabel('Train Data Params/Neural Network Params $(\\%)$')\n",
        "\n",
        "    # plt.show()\n",
        "    if savePlot: \n",
        "        os.chdir(path)\n",
        "        os.chdir(figureDir)\n",
        "        baseName = figName\n",
        "        counter = 2\n",
        "        while os.path.exists('./' + figName + '.png'):\n",
        "            figName = baseName + '_v' + str(counter)\n",
        "            counter += 1\n",
        "        plt.savefig(figName)\n",
        "        os.chdir(path)\n",
        "    plt.rcParams[\"figure.figsize\"] = (6.4,4.8)\n",
        "\n",
        "def plotInputSpace(caseList, inputVarNameList): #inputT, inputTw, inputU, inputRho):\n",
        "# to use this function, the names in the inputVarNameList must already exist as a global variable\n",
        "# this is sometimes called an All-against-all scatter plot\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.suptitle(\"Parameter Space Search\", fontsize=18, y=0.95)\n",
        "\n",
        "    colorList = ['red', 'grey']\n",
        "    labelList = ['outliers', 'not outliers']\n",
        "    zOrderList = [3,0 ]\n",
        "        \n",
        "    combinations = [list(item) for item in itertools.combinations(inputVarNameList, 2)]\n",
        "    matches=[]\n",
        "    for match in combinations:\n",
        "        if not (\"inputMach\" in match and \"inputTemperature\" in match):\n",
        "            if not (\"inputMach\" in match and \"inputVelocity\" in match):\n",
        "                matches.append(match)\n",
        "    combinations=matches\n",
        "\n",
        "    for i, combo in enumerate(combinations):\n",
        "        for j, caseArray in enumerate(caseList):\n",
        "            ax = plt.subplot(len(combinations)//2,2, i+1)\n",
        "            ax.scatter(globals()[combo[0]][caseArray], globals()[combo[1]][caseArray], c=colorList[j],label=labelList[j],zorder=zOrderList[j])\n",
        "            if j == 0:\n",
        "                ax.scatter(globals()[combo[0]][389], globals()[combo[1]][389], c='purple',label='case 389', zorder=zOrderList[j])\n",
        "            ax.set_title(combo[0] + ' vs. ' + combo[1])\n",
        "            ax.legend()\n",
        "            ax.set_xlabel(combo[0])\n",
        "            ax.set_ylabel(combo[1])\n",
        "\n",
        "    # dt = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    # figName = 'plotPressureHeatTransferSideBySideTruthData_' + dt\n",
        "    # os.chdir(path)\n",
        "    # os.chdir(figureDir)\n",
        "    # plt.savefig(figName)\n",
        "    # os.chdir(path)\n",
        "\n",
        "def plotInputSpaceErrorColorMap(testIdxArray, trainIdxArray, inputVarNameList, topErrorValuesToPlot, errorList, logPlot): #inputT, inputTw, inputU, inputRho):\n",
        "# to use this function, the names in the inputVarNameList must already exist as a global variable\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.suptitle(\"Parameter Space Search\", fontsize=18, y=0.95)\n",
        "\n",
        "    halfwayPoint = int(qw.shape[1]/2)\n",
        "    qwChopped = qw[:,:halfwayPoint]\n",
        "    qwMin = np.amin(qwChopped, axis=1)\n",
        "    negativeQwMin = np.nonzero(qwMin<0)\n",
        "    # weirdoCase = [196, 389]\n",
        "\n",
        "    n = topErrorValuesToPlot\n",
        "    topErrorListSortedIndex = np.argsort(-1*np.asarray(errorList))[:n]\n",
        "    m = 10\n",
        "    sortedList = np.sort(errorList)[::-1][:m]\n",
        "    print('Top ', str(m), ' Error Values: ', sortedList)\n",
        "\n",
        "    edgeColors = ['blue', 'purple', 'green', 'indigo']\n",
        "    # colorList = ['red', 'grey']\n",
        "    # labelList = ['outliers', 'not outliers']\n",
        "    # zOrderList = [3,0 ]\n",
        "    cm = plt.cm.get_cmap('autumn')\n",
        "    cm = cm.reversed()\n",
        "    combinations = [list(item) for item in itertools.combinations(inputVarNameList, 2)]\n",
        "    matches=[]\n",
        "    for match in combinations:\n",
        "        if not (\"inputMach\" in match and \"inputTemperature\" in match):\n",
        "            if not (\"inputMach\" in match and \"inputVelocity\" in match):\n",
        "                matches.append(match)\n",
        "    combinations=matches\n",
        "\n",
        "\n",
        "    for i, combo in enumerate(combinations):\n",
        "        # for j, caseArray in enumerate(caseList): #test, then train\n",
        "        ax = plt.subplot(len(combinations)//2,2, i+1)\n",
        "        z = errorList\n",
        "        if logPlot: \n",
        "            norm = matplotlib.colors.LogNorm()\n",
        "        else: \n",
        "            norm = matplotlib.colors.Normalize()\n",
        "\n",
        "        ax.scatter(globals()[combo[0]][trainIdxArray], globals()[combo[1]][trainIdxArray], c='lightgrey',label='Train Data',zorder=1, s=5)\n",
        "\n",
        "        left = np.percentile(globals()[combo[0]],10)\n",
        "        right = np.percentile(globals()[combo[0]],90)\n",
        "        bottom = np.percentile(globals()[combo[1]],10)\n",
        "        top = np.percentile(globals()[combo[1]],90)\n",
        "\n",
        "        width = right-left\n",
        "        height = top-bottom\n",
        "\n",
        "        ax.add_patch(Rectangle((left, bottom), width, height, zorder=0,alpha=0.2))\n",
        "\n",
        "        x = globals()[combo[0]][testIdxArray]\n",
        "        y = globals()[combo[1]][testIdxArray]\n",
        "        sc = ax.scatter( x, y ,c = z, cmap=cm,edgecolors='none', zorder = 3, s=60,marker='d',label='Test Data', norm=norm)\n",
        "        if 'weirdoCase' in locals():\n",
        "            for j, case in enumerate(weirdoCase):\n",
        "                ax.scatter(globals()[combo[0]][case], globals()[combo[1]][case],s=90, edgecolors= edgeColors[j], facecolors='none',label='Case: ' + str(case), zorder=3)\n",
        "        if 'topErrorListSortedIndex' in locals():\n",
        "            # for j, case in enumerate(topErrorListSortedIndex):\n",
        "            ax.scatter(globals()[combo[0]][testIdxArray][topErrorListSortedIndex], globals()[combo[1]][testIdxArray][topErrorListSortedIndex],s=80, edgecolors= 'black', facecolors='none',label='Top '+ str(n) + ' error, Cases: ' + str(topErrorListSortedIndex), zorder=3)\n",
        "        # ax.scatter(globals()[combo[0]][negativeQwMin], globals()[combo[1]][negativeQwMin],s=80, edgecolors = 'black', facecolors='none',label='negative q_w', zorder=1)\n",
        "        ax.set_title(combo[0] + ' vs. ' + combo[1])\n",
        "        if i == 0:\n",
        "            ax.legend(bbox_to_anchor=(-0.1, 1.7), loc='upper left', borderaxespad=0, facecolor='lightgrey')\n",
        "        # ax.legend()\n",
        "        ax.set_xlabel(combo[0])\n",
        "        ax.set_ylabel(combo[1])\n",
        "        cbar = plt.colorbar(sc,ax = ax)\n",
        "        cbar.ax.set_title(\"$NRMSE$\")\n",
        "        ### PLot the mean R2 on the colorbar    # cbar.ax.plot([0, zmax], [elbowLocation]*2, 'w'\n",
        "\n",
        "def plotInputSpaceErrorColorMapLF(badBoysArray, LFinputVarNames): #inputT, inputTw, inputU, inputRho):\n",
        "# to use this function, the names in the inputVarNameList must already exist as a global variable\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.suptitle(\"Parameter Space Search\", fontsize=18, y=0.95)\n",
        "\n",
        "    edgeColors = ['blue', 'purple', 'green', 'indigo', 'salmon']\n",
        "\n",
        "    combinations = [list(item) for item in itertools.combinations(LFinputVarNames, 2)]\n",
        "    # matches=[]\n",
        "    # for match in combinations:\n",
        "    #     if not (\"inputMach\" in match and \"inputTemperature\" in match):\n",
        "    #         if not (\"inputMach\" in match and \"inputVelocity\" in match):\n",
        "    #             matches.append(match)\n",
        "    # combinations=matches\n",
        "    print(combinations)\n",
        "\n",
        "    for i, combo in enumerate(combinations):\n",
        "        # for j, caseArray in enumerate(caseList): #test, then train\n",
        "        ax = plt.subplot(len(combinations)//2,2, i+1)\n",
        "        # z = errorList\n",
        "\n",
        "        ax.scatter(globals()[combo[0]][:], globals()[combo[1]][:], c='lightgrey',label='Train Data',zorder=1, s=3)\n",
        "\n",
        "        left = np.percentile(globals()[combo[0]],10)\n",
        "        right = np.percentile(globals()[combo[0]],90)\n",
        "        bottom = np.percentile(globals()[combo[1]],10)\n",
        "        top = np.percentile(globals()[combo[1]],90)\n",
        "\n",
        "        width = right-left\n",
        "        height = top-bottom\n",
        "\n",
        "        ax.add_patch(Rectangle((left, bottom), width, height, zorder=0,alpha=0.2))\n",
        "\n",
        "        # x = globals()[combo[0]][testIdxArray]\n",
        "        # y = globals()[combo[1]][testIdxArray]\n",
        "        # sc = ax.scatter( x, y ,c = z, s=80, cmap=cm,edgecolors='none', zorder = 3, marker='d',label='Test Data')\n",
        "        for j, case in enumerate(badBoysArray):\n",
        "            ax.scatter(globals()[combo[0]][case], globals()[combo[1]][case],s=80, edgecolors= edgeColors[j], facecolors='none',label='Case: ' + str(case), zorder=3)\n",
        "        # ax.scatter(globals()[combo[0]][negativeQwMin], globals()[combo[1]][negativeQwMin],s=80, edgecolors = 'black', facecolors='none',label='negative q_w', zorder=1)\n",
        "        ax.set_title(combo[0] + ' vs. ' + combo[1])\n",
        "        if i == 0:\n",
        "            ax.legend(bbox_to_anchor=(-0.1, 1.5), loc='upper left', borderaxespad=0)\n",
        "        # ax.legend()\n",
        "        ax.set_xlabel(combo[0])\n",
        "        ax.set_ylabel(combo[1])\n",
        "        # cbar = plt.colorbar(sc,ax = ax)\n",
        "        # cbar.ax.set_title(\"$RMSE$\")\n",
        "        ### PLot the mean R2 on the colorbar    # cbar.ax.plot([0, zmax], [elbowLocation]*2, 'w'\n",
        "\n",
        "def plotInputSpaceMissedPeakColorMap(testIdxArray, trainIdxArray, inputVarNameList, topErrorValuesToPlot, errorList, logPlot): #inputT, inputTw, inputU, inputRho):\n",
        "# to use this function, the names in the inputVarNameList must already exist as a global variable\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.suptitle(\"Parameter Space Search\", fontsize=18, y=0.95)\n",
        "\n",
        "    halfwayPoint = int(qw.shape[1]/2)\n",
        "    qwChopped = qw[:,:halfwayPoint]\n",
        "    qwMin = np.amin(qwChopped, axis=1)\n",
        "    negativeQwMin = np.nonzero(qwMin<0)\n",
        "    # weirdoCase = [196, 389]\n",
        "\n",
        "    n = topErrorValuesToPlot\n",
        "    topErrorListSortedIndex = np.argsort(-1*np.asarray(errorList))[:n]\n",
        "    m = 10\n",
        "    sortedList = np.sort(errorList)[::-1][:m]\n",
        "    print('Top ', str(m), ' Error Values: ', sortedList)\n",
        "\n",
        "    edgeColors = ['blue', 'purple', 'green', 'indigo']\n",
        "    # colorList = ['red', 'grey']\n",
        "    # labelList = ['outliers', 'not outliers']\n",
        "    # zOrderList = [3,0 ]\n",
        "    cm = plt.cm.get_cmap('autumn')\n",
        "    cm = cm.reversed()\n",
        "    combinations = [list(item) for item in itertools.combinations(inputVarNameList, 2)]\n",
        "    matches=[]\n",
        "    for match in combinations:\n",
        "        if not (\"inputMach\" in match and \"inputTemperature\" in match):\n",
        "            if not (\"inputMach\" in match and \"inputVelocity\" in match):\n",
        "                matches.append(match)\n",
        "    combinations=matches\n",
        "\n",
        "\n",
        "    for i, combo in enumerate(combinations):\n",
        "        # for j, caseArray in enumerate(caseList): #test, then train\n",
        "        ax = plt.subplot(len(combinations)//2,2, i+1)\n",
        "        z = errorList\n",
        "        if logPlot: \n",
        "            norm = matplotlib.colors.LogNorm()\n",
        "        else: \n",
        "            norm = matplotlib.colors.Normalize()\n",
        "\n",
        "        ax.scatter(globals()[combo[0]][trainIdxArray], globals()[combo[1]][trainIdxArray], c='lightgrey',label='Train Data',zorder=1, s=5)\n",
        "\n",
        "        left = np.percentile(globals()[combo[0]],10)\n",
        "        right = np.percentile(globals()[combo[0]],90)\n",
        "        bottom = np.percentile(globals()[combo[1]],10)\n",
        "        top = np.percentile(globals()[combo[1]],90)\n",
        "\n",
        "        width = right-left\n",
        "        height = top-bottom\n",
        "\n",
        "        ax.add_patch(Rectangle((left, bottom), width, height, zorder=0,alpha=0.2))\n",
        "\n",
        "        x = globals()[combo[0]][testIdxArray]\n",
        "        y = globals()[combo[1]][testIdxArray]\n",
        "        sc = ax.scatter( x, y ,c = z, cmap=cm,edgecolors='none', zorder = 3, s=60,marker='d',label='Test Data', norm=norm)\n",
        "        if 'weirdoCase' in locals():\n",
        "            for j, case in enumerate(weirdoCase):\n",
        "                ax.scatter(globals()[combo[0]][case], globals()[combo[1]][case],s=90, edgecolors= edgeColors[j], facecolors='none',label='Case: ' + str(case), zorder=3)\n",
        "        if 'topErrorListSortedIndex' in locals():\n",
        "            # for j, case in enumerate(topErrorListSortedIndex):\n",
        "            ax.scatter(globals()[combo[0]][testIdxArray][topErrorListSortedIndex], globals()[combo[1]][testIdxArray][topErrorListSortedIndex],s=80, edgecolors= 'black', facecolors='none',label='Top '+ str(n) + ' error, Cases: ' + str(topErrorListSortedIndex), zorder=3)\n",
        "        # ax.scatter(globals()[combo[0]][negativeQwMin], globals()[combo[1]][negativeQwMin],s=80, edgecolors = 'black', facecolors='none',label='negative q_w', zorder=1)\n",
        "        ax.set_title(combo[0] + ' vs. ' + combo[1])\n",
        "        if i == 0:\n",
        "            ax.legend(bbox_to_anchor=(-0.1, 1.7), loc='upper left', borderaxespad=0, facecolor='lightgrey')\n",
        "        # ax.legend()\n",
        "        ax.set_xlabel(combo[0])\n",
        "        ax.set_ylabel(combo[1])\n",
        "        cbar = plt.colorbar(sc,ax = ax)\n",
        "        cbar.ax.set_title(\"$Peak Abs Err$\")\n",
        "        ### PLot the mean R2 on the colorbar    # cbar.ax.plot([0, zmax], [elbowLocation]*2, 'w'\n",
        "\n",
        "def plotModelConvergenceStudy(top_n_modelChoices,splitList,convDict, fidelityLevel, modelChoice, peakMiss):\n",
        "    markerList = [\n",
        "        'o',\n",
        "        'v',\n",
        "        's',\n",
        "        \"*\",\n",
        "        'X',\n",
        "        'p',\n",
        "        '1',\n",
        "        '>',\n",
        "        'H',\n",
        "        '4',\n",
        "        'P'\n",
        "    ]\n",
        "\n",
        "    inputDict = {\n",
        "        'R^2' : 'R2_list',\n",
        "        'NRMSE' : 'nrmse_list', \n",
        "    }\n",
        "\n",
        "    peakMissErrorDict = {\n",
        "        'median': 'single_medianPeakMissList',\n",
        "        'mean' : 'single_meanPeakMissList',\n",
        "    }\n",
        "    errorMetric = peakMissErrorDict[peakMiss]\n",
        "\n",
        "    for key in inputDict.keys():\n",
        "        yAxis = inputDict[key]\n",
        "        nModels = len(top_n_modelChoices)\n",
        "        numColors = nModels\n",
        "        colors = plt.cm.jet(np.linspace(0,1,numColors))\n",
        "        if modelChoice == 'krig':\n",
        "            modelArchitectureList = cleanKernelList(kernelList = convDict['top_n_modelChoices'])\n",
        "        if modelChoice == 'NN':\n",
        "            modelArchitectureList = [str(item) for item in convDict['top_n_modelChoices']]\n",
        "\n",
        "        plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "        figName = f'modelConvergence_{fidelityLevel}_{modelChoice}_'\n",
        "        dt = str(datetime.date.today())\n",
        "        figName += dt\n",
        "        fig, ax = plt.subplots(constrained_layout=True)\n",
        "\n",
        "        xList = [split*100 for split in splitList]\n",
        "        yList = []\n",
        "        labels = []\n",
        "        for j, modelChoice in enumerate(np.arange(0,nModels)):\n",
        "            labels.append(f'Model: {modelArchitectureList[modelChoice]}')\n",
        "            for split in splitList:\n",
        "                yList.append((convDict[split][yAxis][j]))\n",
        "\n",
        "        iterator = int(len(xList))\n",
        "        start = 0\n",
        "        end = iterator\n",
        "        for i in np.arange(0,nModels):\n",
        "            ax.plot(xList,yList[start:end], linestyle='--',c=colors[i],marker=markerList[i], linewidth=0.75,zorder=0, label = labels[i])\n",
        "            start += iterator\n",
        "            end += iterator\n",
        "\n",
        "        ax.set_xlabel('Training Data Split (%)')\n",
        "        ax.set_ylabel(f'${key}$')\n",
        "        ax.legend()\n",
        "    \n",
        "    peakMissList = []\n",
        "    for split in splitList:\n",
        "        peakMissList.append(convDict[split][errorMetric])\n",
        "    peakMissArray = np.asarray(peakMissList)\n",
        "\n",
        "    varDict = {\n",
        "        'qw' : 'Heat Flux',\n",
        "        'qw_LF' : 'Heat Flux',\n",
        "        'p' : 'Pressure',\n",
        "        'p_LF': 'Pressure'\n",
        "    }\n",
        "\n",
        "    for j, var in enumerate(outputVarNames):\n",
        "        fig, ax = plt.subplots(constrained_layout=True)\n",
        "        yList = peakMissArray[:,:,j]\n",
        "        for i in np.arange(0,nModels):\n",
        "            ax.plot(xList, yList[:,i], linestyle='--',c=colors[i],marker=markerList[i], linewidth=0.75,zorder=0, label = labels[i])\n",
        "        ax.set_xlabel('Training Data Split (%)')\n",
        "        ax.set_ylabel(f'{peakMiss.capitalize()} {varDict[var]} \\n Peak To Peak Percent Difference (%)', wrap=True)\n",
        "        ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ab93056",
      "metadata": {},
      "source": [
        "## Scientific / Statistics / ML Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5a361bb0-ff10-4df0-ab87-c968b606624c",
      "metadata": {
        "id": "5a361bb0-ff10-4df0-ab87-c968b606624c"
      },
      "outputs": [],
      "source": [
        "def percentdifferencecalc(x1,x2):\n",
        "    mean = np.mean((x1,x2),axis=0)\n",
        "    percentDifference = abs(((x1-x2)/mean)*100)\n",
        "    return percentDifference\n",
        "\n",
        "def latinHypercubeSample(dimensionParameterSpace, numPointsToSample,l_bounds,u_bounds,seed):\n",
        "    \"\"\"\n",
        "\n",
        "    :param dimensionParameterSpace: \n",
        "    :param numPointsToSample: \n",
        "    :param l_bounds: \n",
        "    :param u_bounds: \n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sampler = qmc.LatinHypercube(d=dimensionParameterSpace, seed=seed)\n",
        "    sample = sampler.random(n=numPointsToSample)\n",
        "    sample.shape\n",
        "    # Wall Temp, rho, free stream temp, free stream velocity\n",
        "    lowFidelityInputPoints = qmc.scale(sample, l_bounds, u_bounds)\n",
        "    return lowFidelityInputPoints\n",
        "\n",
        "\n",
        "#Oblique Perfect Gas Function \n",
        "def perfgas_oblique(M,V1,T1,P1,rho_1,a1,theta):\n",
        "    \n",
        "    gamma = 1.4 # perfect gas\n",
        "    R_specific = 287.058\n",
        "    cp1 = 1.005 #KJ/Kg*K, air at 251K\n",
        "    #For our initial guess at beta, let's use the M>>1 approximation. Although\n",
        "    #our flow M>>1, this code will calculate a more accurate turn angle than the approximation. \n",
        "    b_init = ((gamma + 1) / 2)*theta\n",
        "\n",
        "    #We'll use Newton's method, which requires the function and the function's \n",
        "    #derivative, included below as \"f\" and \"fp\"\n",
        "    #  tan(theta) = 2cot(beta)*(M^2sin^2(beta) - 1)/(M^2(gamma + cos(2beta) + 1)\n",
        "\n",
        "    b = np.zeros((11,1))\n",
        "    i = 1\n",
        "    b[i] = b_init\n",
        "    \n",
        "    for i in range(1,10):\n",
        "        b[i+1] = b[i] - ((2*(1/np.tan(b[i]))*(M**2*(np.sin(b[i]))**2-1))/(M**2*(gamma + np.cos(2*b[i]))+2)-np.tan(theta)) \\\n",
        "        / ((4*M**2*np.sin(2*b[i])*(1/np.tan(b[i]))*(M**2*np.sin(b[i])**2-1))/((M**2*(np.cos(2*b[i])+gamma)+2)**2)\n",
        "           + (4*M**2*np.cos(b[i])**2 - 2*(1/np.cos(b[i]))**2*(M**2*(np.sin(b[i]))**2-1))/(M**2*(np.cos(2*b[i])+gamma)+2))\n",
        "\n",
        "            \n",
        "    beta = b[10]\n",
        "    # beta_deg = np.rad2deg(b[10])\n",
        "\n",
        "    M1 = M\n",
        "    M2 = np.sqrt(((1+((gamma-1)/2)*(M1**2)*(np.sin(beta)**2)) / (gamma*(M1**2)*(np.sin(beta)**2)-((gamma-1)/2)))\n",
        "        * (1/(np.sin(beta-theta)**2)))\n",
        "    m_ratio = M2/M1\n",
        "\n",
        "    temp_ratio = 1 + ((2*(gamma-1))/((gamma+1)**2))*(((M1**2)*(np.sin(beta)**2) - 1)/((M1**2)*(np.sin(beta)**2)))*(gamma*(M1**2)*(np.sin(beta)**2)+1)\n",
        "    T2 = temp_ratio*T1\n",
        "\n",
        "    H2 = cp1*T2*1000\n",
        "\n",
        "    #Using the relation T2/T1 = (a2/a1)^2, we can also solve for the ratio of\n",
        "    #a2/a1 \n",
        "    a_ratio = np.sqrt(temp_ratio)\n",
        "    a2 = a_ratio*a1\n",
        "\n",
        "    rho_ratio = ((gamma+1)*(M1**2)*(np.sin(beta)**2))/((gamma-1)*(M1**2)*(np.sin(beta)**2)+2)\n",
        "    rho2 = rho_ratio*rho_1\n",
        "\n",
        "    v_ratio = m_ratio* a_ratio\n",
        "    V2 = v_ratio*V1\n",
        "\n",
        "    p_ratio = rho_ratio*temp_ratio\n",
        "    P2 = p_ratio*P1\n",
        "\n",
        "    T01 = T1*(1+ ((gamma-1)/2)*(M1**2))\n",
        "    T02 = T2*(1+ ((gamma-1)/2)*(M2**2))\n",
        "\n",
        "    total_p_ratio = p_ratio * ((1+((gamma-1)/2)*(M2**2))**(gamma/(gamma-1)))/((1+((gamma-1)/2)*(M1**2))**(gamma/(gamma-1)))\n",
        "    P01 = P1* ((1 +((gamma-1)/2)*(M1**2))**((gamma)/(gamma-1)))\n",
        "    P02 = P01*total_p_ratio\n",
        "    \n",
        "    return H2, V2, T2, P2, rho2, beta, M2,a2, T01, T02, P01, P02\n",
        "\n",
        "def mu_suth(T):\n",
        "    mu_ref = 1.8e-5\n",
        "    T_ref = 300\n",
        "    mu = mu_ref*((T/T_ref)**0.7)\n",
        "    return mu\n",
        "\n",
        "# Neural Network Functions\n",
        "\n",
        "#Building the model\n",
        "\n",
        "def build_model_parameterized(\n",
        "    input_data, output_data, layerSizeList, rate, regType, regValue,\n",
        "    hiddenLayerActivation, outputLayerActivation, outputLayerDataType, kernelInitializer,\n",
        "    optimizer, loss):\n",
        "    \"\"\"\n",
        "\n",
        "    :param input_data: input parameters/features\n",
        "    :param output_data: outputs the NN is fitting\n",
        "    :param layerSizeList: list of all the layer sizes. Number of values indicates number of layers\n",
        "    :param rate: learning rate\n",
        "    :param reg: L2 regularization value to drop weights\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    inputlayershape = int(len(input_data[0,:]))\n",
        "    outputlayershape = int(len(output_data[0,:]))\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(inputlayershape,))\n",
        "    \n",
        "    x = tf.keras.layers.Dense(\n",
        "        layerSizeList[0],\n",
        "        activation=hiddenLayerActivation,\n",
        "        kernel_regularizer=regType(regValue),\n",
        "        kernel_initializer = kernelInitializer\n",
        "        )(inputs)\n",
        "\n",
        "    for layerSize in layerSizeList[1:]:\n",
        "        x = tf.keras.layers.Dense(\n",
        "            layerSize,activation=hiddenLayerActivation,\n",
        "            kernel_regularizer=regType(regValue),\n",
        "            kernel_initializer = kernelInitializer\n",
        "            )(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(\n",
        "        outputlayershape,\n",
        "        activation = outputLayerActivation,\n",
        "        kernel_regularizer = regType(regValue),\n",
        "        kernel_initializer = kernelInitializer,\n",
        "        name = 'outputlayer',\n",
        "        dtype=outputLayerDataType\n",
        "        )(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "    \n",
        "    model.compile(optimizer=optimizer(learning_rate=rate),\n",
        "             loss = loss,\n",
        "             metrics = [tf.keras.metrics.MeanSquaredError(),\n",
        "                       tf.keras.metrics.RootMeanSquaredError(),])\n",
        "                       # \"mae\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model_all_fidelity(model, input_data, output_data, numEpochs, myBatchSize, validData, callbacks_list):\n",
        "    \n",
        "    history = model.fit(x=input_data,\n",
        "                       y=output_data,\n",
        "                       batch_size=myBatchSize,\n",
        "                       epochs=numEpochs,\n",
        "                       callbacks = callbacks_list,\n",
        "                       verbose=False,\n",
        "                       shuffle=False,\n",
        "                       validation_data=validData,\n",
        "                       use_multiprocessing=True)\n",
        "    epochs = history.epoch\n",
        "    return epochs, history.history\n",
        "    \n",
        "def normalizedRootMeanSquaredError(truth,prediction):\n",
        "    rmse = mean_squared_error(truth, prediction, squared=False)\n",
        "    ybar = truth.max()-truth.min()\n",
        "    nrmse = rmse/ybar\n",
        "    return nrmse\n",
        "\n",
        "def errorMetrics(truth,prediction,fidelity,model, variable, verbose):\n",
        "    rmse = mean_squared_error(truth, prediction, squared=False)\n",
        "    ybar = truth.max()-truth.min()\n",
        "    nrmse = round(rmse/ybar,5)\n",
        "    R2 = round(r2_score(truth, prediction),4)\n",
        "    if verbose: \n",
        "        print(fidelity + ' ' + model + ' ' + variable + ' ' + 'R2: ' + str(R2) )\n",
        "        print(fidelity + ' ' + model + ' ' + variable + ' ' + 'NRMSE: ' + str(nrmse * 100) + '%\\n' )\n",
        "    return nrmse, R2\n",
        "\n",
        "def krigTrain(X_train,y_train, fidelityLevel, kernel, n_restarts,verbose):\n",
        "    \n",
        "    modelName = fidelityLevel + '_krig'\n",
        "    \n",
        "    globals()[modelName] = None\n",
        "    globals()[modelName] = gaussian_process.GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=n_restarts)\n",
        "    if verbose:\n",
        "        print(modelName + ' training begin')\n",
        "    start = time.time()\n",
        "    globals()[modelName].fit(X_train, y_train)\n",
        "\n",
        "    end = time.time()\n",
        "    if verbose:\n",
        "        print(modelName + ' training end')\n",
        "        print(fidelityLevel + ' Kriging train time: %0.7f seconds' % (end-start) )\n",
        "        print('Model name: ', modelName)\n",
        "    print('Original kernel:' , kernel)\n",
        "    print('Optimized kernel:' , globals()[modelName].kernel_ )\n",
        "    print('_'*25)\n",
        "\n",
        "def generateInverseTransformedPredictions(X_train,X_test,y_train,y_test,method,fidelityLevel,truncate,verbose):\n",
        "    # Need to add validation data eventually\n",
        "    if verbose:\n",
        "        print('Method: ' + method + ', Fidelity Level: ' + fidelityLevel)\n",
        "        print('_'*25)\n",
        "    \n",
        "    #shorten variable names a bit\n",
        "    if method == 'kriging':\n",
        "        method = 'krig'\n",
        "    \n",
        "    modelName = fidelityLevel + '_' + method\n",
        "\n",
        "    dataSplitNames = [\n",
        "        '_' + modelName + '_test_predict',\n",
        "        '_' + modelName + '_train_predict',\n",
        "        '_' + fidelityLevel + '_test_truth',\n",
        "        '_' + fidelityLevel + '_train_truth'\n",
        "        ]\n",
        "    numDataSplit = int(len(dataSplitNames)/2) # are we splitting into train/test (numDataSplit = 2) or train/test/validation (numDataSplit =3) ? \n",
        "\n",
        "    #######################################\n",
        "\n",
        "    globals()[dataSplitNames[0][1:]] = globals()[modelName].predict(X_test)\n",
        "    globals()[dataSplitNames[1][1:]] = globals()[modelName].predict(X_train)\n",
        "\n",
        "\n",
        "    globals()[dataSplitNames[2][1:]] = y_test\n",
        "    globals()[dataSplitNames[3][1:]] = y_train\n",
        "    #######################################\n",
        "\n",
        "    variableNameList =[] #to be used for the \"un-truncating\"\n",
        "\n",
        "    for i in np.arange(len(outputVarNames)):\n",
        "        for j in np.arange(numDataSplit):\n",
        "            #Input Data Split\n",
        "            globals()[outputVarNames[j] + dataSplitNames[i]] = np.hsplit(globals()[dataSplitNames[i][1:]],numDataSplit)[j]\n",
        "            variableNameList.append(outputVarNames[j] + dataSplitNames[i])\n",
        "            if verbose:\n",
        "                print(dataSplitNames[i][1:] + ' part ' + str(j+1) + '--> ' + outputVarNames[j] + dataSplitNames[i])\n",
        "            globals()[outputVarNames[j] + dataSplitNames[i+2]] = np.hsplit(globals()[dataSplitNames[i+2][1:]],numDataSplit)[j]\n",
        "            variableNameList.append(outputVarNames[j] + dataSplitNames[i+2]) \n",
        "            if verbose:\n",
        "                print(dataSplitNames[i+2][1:] + ' part ' + str(j+1) + '--> ' + outputVarNames[j] + dataSplitNames[i+2])\n",
        "    \n",
        "    if verbose:\n",
        "        print(variableNameList)\n",
        "        X_predictionSpeed = np.tile(X_train,(2,1))\n",
        "        frequencyTempList = []\n",
        "        predictionTimeTempList = []\n",
        "        numTestCases = X_predictionSpeed.shape[0]\n",
        "        for _ in np.arange(0,200):\n",
        "            predictionStart = time.time()\n",
        "            globals()[modelName].predict(X_predictionSpeed)\n",
        "            predictionEnd = time.time()\n",
        "            predictionTime = predictionEnd-predictionStart\n",
        "            predictionTimePerCase = predictionTime/numTestCases\n",
        "            predictionTimeTempList.append(predictionTimePerCase)\n",
        "            frequency = 1/((predictionTime)/numTestCases)\n",
        "            frequencyTempList.append(frequency)\n",
        "        frequencyTestAverage = np.mean(frequencyTempList)\n",
        "        predictionTimeAverage = np.mean(predictionTimeTempList)\n",
        "        print('_'*15)\n",
        "        print('Prediction frequency: %0.5f Hz. Prediction time per case: %0.7f seconds' \\\n",
        "            % (frequencyTestAverage, predictionTimeAverage) )\n",
        "        print('_'*15)\n",
        "        \n",
        "\n",
        "    if truncate: \n",
        "        leftFluidScalarDistributionLength = globals()[outputVarNames[0]][0,:xSpotLeft].shape[0]\n",
        "        rightFluidScalarDistributionLength =  globals()[outputVarNames[0]][0,xSpotLeft:].shape[0]\n",
        "        if verbose:\n",
        "            print(\"leftFluidScalarDistributionLength:\", leftFluidScalarDistributionLength)\n",
        "            print(\"rightFluidScalarDistributionLength:\", rightFluidScalarDistributionLength)\n",
        "\n",
        "        for var in variableNameList:\n",
        "            temp_left = [np.tile(entry, leftFluidScalarDistributionLength) for entry in globals()[var][:,0] ]\n",
        "            temp_right = [np.tile(entry,rightFluidScalarDistributionLength) for entry in globals()[var][:,1] ]\n",
        "            temp_stacked = np.hstack((temp_left,temp_right))\n",
        "            globals()[var] = temp_stacked\n",
        "            if verbose:\n",
        "                print(var, \" shape: \", globals()[var].shape)\n",
        "########### Inverse Scale ###########\n",
        "\n",
        "    if fidelityLevel == 'LF':\n",
        "\n",
        "        for name in LFoutputVarNames:\n",
        "            ScalerName = name + '_OutputScaler'\n",
        "            for tail in dataSplitNames:\n",
        "                fullName = name[0:-3] + tail\n",
        "                globals()[fullName] = globals()[ScalerName].inverse_transform(globals()[fullName])\n",
        "                if verbose:\n",
        "                    print(fullName + ' = ' + ScalerName + '.inverse_transform(' +  fullName + ')')\n",
        "                \n",
        "    else:\n",
        "        \n",
        "        for name in outputVarNames:\n",
        "            ScalerName = name + '_OutputScaler'\n",
        "            for tail in dataSplitNames:\n",
        "                fullName = name + tail\n",
        "                globals()[fullName] = globals()[ScalerName].inverse_transform(globals()[fullName])\n",
        "                if verbose:\n",
        "                    print( fullName + ' has been inverse transformed using ' + ScalerName + '! It is called ' + fullName)\n",
        "\n",
        "def optimizeKrig(kernelList, X_train, y_train, X_test, y_test, fidelityLevel, method, n_restarts, verbose):\n",
        "    startOpt = time.time()\n",
        "    if method == 'kriging' or 'Kriging':\n",
        "        methodShortName = 'krig'\n",
        "    modelName = fidelityLevel + '_' + methodShortName\n",
        "    errorDict = {'Original Kernel':[],'Optimized Kernel':[],'NRMSE (Pressure)':[], 'NRMSE (Heat Transfer)':[],'R^2 (Pressure)':[], 'R^2 (Heat Transfer)':[]}\n",
        "    ############################### BOOKMARK\n",
        "    modelDict = {}\n",
        "    completionTime = []\n",
        "    numIters = len(kernelList)\n",
        "\n",
        "    dataSplitNames = [\n",
        "    '_' + modelName + '_test_predict',\n",
        "    '_' + modelName + '_train_predict',\n",
        "    '_' + fidelityLevel + '_test_truth',\n",
        "    '_' + fidelityLevel + '_train_truth'\n",
        "    ]\n",
        "    \n",
        "    variableNameList = []\n",
        "    for name in outputVarNames:\n",
        "        for entry in dataSplitNames:\n",
        "            variableNameList.append(name + entry)\n",
        "\n",
        "    for i, kernel in enumerate(kernelList):\n",
        "        print('_'*25)\n",
        "        print('Optimization begin for kernel: ' + str(kernel))\n",
        "        loopStart = time.time()\n",
        "        currentIter = i+1\n",
        "        krigTrain(\n",
        "        X_train=X_train,\n",
        "        y_train=y_train, \n",
        "        fidelityLevel= fidelityLevel,\n",
        "        kernel=kernel, \n",
        "        n_restarts = n_restarts,\n",
        "        verbose = False\n",
        "        )\n",
        "\n",
        "        generateInverseTransformedPredictions(\n",
        "        X_train = X_train,\n",
        "        X_test = X_test,\n",
        "        y_train = y_train,\n",
        "        y_test = y_test,\n",
        "        method = methodShortName,\n",
        "        fidelityLevel = fidelityLevel,\n",
        "        verbose = False,\n",
        "        truncate=downsampleLF\n",
        "        )\n",
        "\n",
        "        chosenVar = 'p'\n",
        "        chosenSet = 'test'\n",
        "        matches = [match for match in variableNameList if (chosenSet in match) and (chosenVar+'_' in match)]\n",
        "\n",
        "        [NRMSE_pressure, R2_pressure] = errorMetrics(\n",
        "        truth = globals()[matches[1]],\n",
        "        prediction = globals()[matches[0]],\n",
        "        fidelity = fidelityLevel,\n",
        "        model = methodShortName,\n",
        "        variable = 'Pressure',\n",
        "        verbose = False)\n",
        "\n",
        "        chosenVar = 'qw'\n",
        "        chosenSet = 'test'\n",
        "        matches = [match for match in variableNameList if (chosenSet in match) and (chosenVar+'_' in match)]\n",
        "\n",
        "        [NRMSE_heatTransfer, R2_heatTransfer] = errorMetrics( \n",
        "        truth = globals()[matches[1]],\n",
        "        prediction = globals()[matches[0]],\n",
        "        fidelity = fidelityLevel,\n",
        "        model = methodShortName,\n",
        "        variable = 'Heat Transfer',\n",
        "        verbose = False)\n",
        "        \n",
        "        errorDict['Original Kernel'].append(kernel)\n",
        "        errorDict['Optimized Kernel'].append(globals()[modelName].kernel_)\n",
        "        errorDict['NRMSE (Pressure)'].append(NRMSE_pressure)\n",
        "        errorDict['NRMSE (Heat Transfer)'].append(NRMSE_heatTransfer)\n",
        "        errorDict['R^2 (Pressure)'].append(R2_pressure)\n",
        "        errorDict['R^2 (Heat Transfer)'].append(R2_heatTransfer)\n",
        "        modelDict[str(kernel)] = (globals()[modelName].kernel_, globals()[modelName])\n",
        "        print('Optimization complete for kernel: ' + str(kernel) + '-->' + str(globals()[modelName].kernel_) + '\\n')\n",
        "        print('Trained model stored in modelDict, key: ' + str(kernel))\n",
        "        print('_'*25)\n",
        "\n",
        "        loopEnd = time.time()\n",
        "        currentIterTime = round((loopEnd-loopStart),4)\n",
        "        completionTime.append(currentIterTime)\n",
        "        estimatedRemainingTime = (numIters - currentIter)*np.mean(completionTime)\n",
        "        if verbose:\n",
        "            print('Iteration ', str(i+1), ' of ',str(numIters) ,' training complete, time elapsed: ', str(round(currentIterTime/60,4)), ' minutes ', )\n",
        "            print('Estimated time to completion: ', str(round(estimatedRemainingTime/60,4)), ' minutes')\n",
        "\n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir + '/' + krigDir)\n",
        "\n",
        "    errorCompDataFrame = pd.DataFrame.from_dict(errorDict)\n",
        "    dt = str(datetime.date.today())\n",
        "    dfName = fidelityLevel + '_errorCompDataFrame_' + dt + '.csv'\n",
        "    errorCompDataFrame.to_csv(\n",
        "        dfName,\n",
        "        index = False\n",
        "        )\n",
        "        \n",
        "    filename = 'optimizerPickle_' + fidelityLevel + '_'\n",
        "    dt = str(datetime.date.today())\n",
        "    ext = '.pkl'\n",
        "    filename += dt + ext\n",
        "    f = open(filename, 'wb')\n",
        "    pickle.dump(errorCompDataFrame, f)\n",
        "    f.close()\n",
        "    print(filename, 'saved at location: ',path, modelDir ,'/' ,krigDir)\n",
        "    os.chdir(path)\n",
        "    endOpt = time.time()\n",
        "    totalOptTime = round((endOpt - startOpt),4)/60\n",
        "    print('Convergence study complete. Time elapsed: ' , str(totalOptTime), ' minutes.')\n",
        "\n",
        "# throw in a little search algorithm that picks the best one and retrains based on that kernel. Maybe keeps the trained models in a dict, picks the good one, deletes the rest. \n",
        "    return errorCompDataFrame, errorDict, modelDict\n",
        "\n",
        "def operatingConditions(case):\n",
        "    gamma = 1.4 # perfect gas\n",
        "    R_specific = 287.058\n",
        "    T_inf = inputTemperature[case]\n",
        "    u_inf = inputVelocity[case]\n",
        "    a_inf = np.sqrt(gamma*R_specific*T_inf)\n",
        "    M_inf = u_inf/a_inf\n",
        "\n",
        "    print('Case number: ' + str(case))\n",
        "\n",
        "    print(\n",
        "        'Wall Temp: ' + str(round(inputWallTemp[case].item(), 2)) + ' K\\n' + \\\n",
        "            'Freestream Temp: ' + str(round(inputTemperature[case].item(), 2)) + ' K\\n' + \\\n",
        "                'Freestream Density: ' + str(round(inputDensity[case].item(), 2)) + ' kg/m3\\n' + \\\n",
        "                    'Freestream Velocity: ' + str(round(inputVelocity[case].item(), 2)) + ' m/s\\n' + \\\n",
        "                        'Mach Number: ' + str(M_inf)\n",
        "        )\n",
        "\n",
        "def batchTest(model,fidelityLevel, batchSizeMultiples, input_data, output_data,validData,numEpochs):\n",
        "    batchSizeList = []\n",
        "    for multiple in np.arange(start=1,stop = batchSizeMultiples):\n",
        "        batchSizeList.append(32*multiple)\n",
        "\n",
        "    batchNumberList = []\n",
        "    timeList = []\n",
        "    timeDict = dict()\n",
        "\n",
        "    for batch in batchSizeList:\n",
        "        # LF_NN_epochs = None\n",
        "        # LF_NN_history = None\n",
        "        print('Batch size: ',str(batch), ' training start')\n",
        "        start = time.time()\n",
        "        train_model_all_fidelity(\n",
        "            model = model, \n",
        "            input_data = input_data, \n",
        "            output_data = output_data,\n",
        "            numEpochs = numEpochs, \n",
        "            myBatchSize = batch,\n",
        "            validData = validData,\n",
        "            callbacks_list= callbacks_list)\n",
        "        end = time.time()\n",
        "        batchNumberList.append(batch)\n",
        "        timeList.append(round((end-start),4))\n",
        "        print('Batch size: ',str(batch), ' training end. Time elapsed: ',str(round((end-start),4)) )\n",
        "\n",
        "    timeDict[\"Batch\"] = batchNumberList\n",
        "    timeDict[\"Time\"] = timeList\n",
        "    timeDF = pd.DataFrame(data=timeDict)\n",
        "\n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir + '/' + NNDir)\n",
        "    filename = 'timePickle_' + fidelityLevel + '_'\n",
        "    dt = str(datetime.date.today())\n",
        "    ext = '.pkl'\n",
        "    filename += dt + ext\n",
        "    f = open(filename, 'wb')\n",
        "    pickle.dump(timeDF, f)\n",
        "    f.close()\n",
        "    print(filename, 'saved at location: ',path, modelDir ,'/' ,NNDir)\n",
        "    os.chdir(path)\n",
        "\n",
        "def neuralNetworkConvergence(\n",
        "    fidelityLevel,convStudyLayerList, hyperparamDict,X_train,y_train, validData, callbacks_list, verbose, showConvPlot, saveConvPlot, showMSEplot, saveMSEplot, showSpeedPlot, saveSpeedPlot\n",
        "    ):\n",
        "\n",
        "    convStudyTimeStart = time.time()\n",
        "    numParamsList = []\n",
        "    NNminMSElist = []\n",
        "    completionTime = []\n",
        "    predictionTimeList = []\n",
        "    predictionTimePerCaseList = []\n",
        "    frequencyList = []\n",
        "    # fileSizeList = []\n",
        "    dictName = fidelityLevel + 'convStudyDict'\n",
        "    globals()[dictName] = dict()\n",
        "\n",
        "    annotations = [str(item) for item in convStudyLayerList]\n",
        "    depthList = [len(item) for item in convStudyLayerList]\n",
        "    disallowed_characters = '[] '\n",
        "    dirAnnotations = []\n",
        "    for s in annotations:\n",
        "        for char in disallowed_characters:\n",
        "            s = s.replace(char, '')\n",
        "        s = s.replace(',','_')\n",
        "        dirAnnotations.append(s)\n",
        "\n",
        "    numEpochs = hyperparamDict[\"numEpochs\"]\n",
        "    if quickTestRun:\n",
        "        numEpochs = 3\n",
        "    validData = validData\n",
        "    X_predictionSpeed = np.tile(X_train,(2,1))\n",
        "    callbacks_list = callbacks_list\n",
        "\n",
        "    NN = None #sometimes remnants of previously trained models can hang around, it's best \n",
        "                #to clear the variable first \n",
        "    numIters = len(convStudyLayerList)\n",
        "    currentConvStudyTopDir = fidelityLevel + time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    convStudyPath = os.path.join(path,modelDir,NNDir,convStudyDir)\n",
        "    os.chdir(convStudyPath)\n",
        "    os.mkdir(currentConvStudyTopDir)\n",
        "    os.chdir(currentConvStudyTopDir)\n",
        "\n",
        "    for i, layerSizeList in enumerate(convStudyLayerList):\n",
        "        currentIter = i+1\n",
        "        NN = build_model_parameterized(\n",
        "            input_data = X_train, \n",
        "            output_data = y_train,\n",
        "            layerSizeList = layerSizeList, \n",
        "            rate = hyperparamDict[\"learningRate\"], \n",
        "            regType = hyperparamDict[\"regType\"], \n",
        "            regValue = hyperparamDict[\"regValue\"],\n",
        "            hiddenLayerActivation = hyperparamDict[\"hiddenLayerActivation\"],\n",
        "            outputLayerActivation = hyperparamDict[\"outputLayerActivation\"],\n",
        "            outputLayerDataType= 'float32',\n",
        "            kernelInitializer = hyperparamDict[\"kernelInitializer\"],\n",
        "            optimizer = hyperparamDict[\"optimizer\"],\n",
        "            loss = hyperparamDict[\"loss\"])\n",
        "\n",
        "        NN_epochs = None\n",
        "        NN_history = None\n",
        "        print('Iteration ', str(currentIter), ' training start')\n",
        "        start = time.time()\n",
        "        NN_epochs, NN_history = train_model_all_fidelity(\n",
        "            model = NN, \n",
        "            input_data = X_train, \n",
        "            output_data = y_train,\n",
        "            numEpochs = numEpochs, \n",
        "            myBatchSize = hyperparamDict[\"myBatchSize\"],\n",
        "            validData = validData,\n",
        "            callbacks_list= callbacks_list)\n",
        "\n",
        "        minMSE = np.min(NN_history[\"val_mean_squared_error\"])\n",
        "        numParams = NN.count_params()\n",
        "\n",
        "        frequencyTempList = []\n",
        "        predictionTimeTempList = []\n",
        "        numTestCases = X_predictionSpeed.shape[0]\n",
        "        for _ in np.arange(0,200):\n",
        "            predictionStart = time.time()\n",
        "            NN.predict(X_predictionSpeed)\n",
        "            predictionEnd = time.time()\n",
        "            predictionTime = predictionEnd-predictionStart\n",
        "            predictionTimeTempList.append(predictionTime)\n",
        "            frequency = 1/((predictionTime)/numTestCases)\n",
        "            frequencyTempList.append(frequency)\n",
        "        frequencyTestAverage = np.mean(frequencyTempList)\n",
        "        predictionTimeAverage = np.mean(predictionTimeTempList)\n",
        "\n",
        "\n",
        "        predictionTimeList.append(predictionTimeAverage)\n",
        "        predictionTimePerCase = (predictionTimeAverage)/numTestCases\n",
        "        predictionTimePerCaseList.append(predictionTimePerCase)\n",
        "\n",
        "        frequencyList.append(frequencyTestAverage)\n",
        "\n",
        "        globals()[dictName][annotations[i]] = {\n",
        "        'numParams' : numParams,\n",
        "        'minMSE' : minMSE,\n",
        "        'epochs' : NN_epochs,\n",
        "        'history' : NN_history,\n",
        "        }\n",
        "\n",
        "        numParamsList.append(numParams)\n",
        "        NNminMSElist.append(minMSE)\n",
        "        # fileSizeList = []\n",
        "\n",
        "        currentIterKerasDirName = dirAnnotations[i] + fidelityLevel + '_convStudyModel'\n",
        "        # model is saved separately/outside of the dictionary, because the keras model objects doesn't play nice with pickle function. Throws an error about saving local functions. \n",
        "\n",
        "        kerasPath = os.path.join(convStudyPath,currentConvStudyTopDir, currentIterKerasDirName)\n",
        "        tf.get_logger().setLevel('WARNING')\n",
        "        NN.save(kerasPath)\n",
        "        os.chdir(convStudyPath)\n",
        "\n",
        "        end = time.time()\n",
        "        currentIterTime = round((end-start),4)\n",
        "        completionTime.append(currentIterTime)\n",
        "        estimatedRemainingTime = (numIters - currentIter)*np.mean(completionTime)\n",
        "        if verbose:\n",
        "            print('Iteration ', str(i+1), ' of ',str(numIters) ,' training complete. Layer configuration: ', str(layerSizeList) ,' time elapsed: ', str(round(currentIterTime/60,4)), ' minutes ', )\n",
        "            print('Estimated time to completion: ', str(round(estimatedRemainingTime/60,4)), ' minutes')\n",
        "            print('Number of epochs: ', len(NN_epochs), 'original number of epochs: ', str(numEpochs))\n",
        "    \n",
        "    globals()[dictName]['numParamsList'] = numParamsList\n",
        "    globals()[dictName]['NNminMSElist'] = NNminMSElist\n",
        "    globals()[dictName]['predictionTimeList'] = predictionTimeList\n",
        "    globals()[dictName]['predictionTimePerCaseList'] = predictionTimePerCaseList\n",
        "    globals()[dictName]['frequencyList'] = frequencyList\n",
        "\n",
        "    saveVersionedPickle(\n",
        "    filename=dictName, \n",
        "    objectToSave=globals()[dictName],\n",
        "    path = os.path.join(convStudyPath,currentConvStudyTopDir)\n",
        "    )\n",
        "    print('Dictionary name: ', dictName)\n",
        "    os.chdir(path)\n",
        "    convStudyTimeEnd = time.time()\n",
        "    totalConvStudyTime = round((convStudyTimeEnd - convStudyTimeStart),4)/60\n",
        "\n",
        "    print('Convergence study complete. Convergene study directory name: ',currentConvStudyTopDir, '. Time elapsed: ' , str(totalConvStudyTime), ' minutes. Beginning Plotting. ')\n",
        "\n",
        "    if showConvPlot:\n",
        "        plotNNConvergence(\n",
        "            fidelityLevel = fidelityLevel,\n",
        "            numParamsList = numParamsList,\n",
        "            MSElist = NNminMSElist,\n",
        "            convStudyLayerList = convStudyLayerList,\n",
        "            savePlot = saveConvPlot\n",
        "        )\n",
        "    if showMSEplot: \n",
        "        plt.figure(figsize=(15, 15))\n",
        "        plt.subplots_adjust(hspace=0.5)\n",
        "        plt.suptitle(fidelityLevel + \" NN Convergence MSE\", fontsize=18, y=0.95)\n",
        "        mseNames = [\"mean_squared_error\",\n",
        "                    'val_mean_squared_error'\n",
        "                    ]\n",
        "        colorList = [ 'k', 'r']\n",
        "        epochRangeBegin = 0\n",
        "        for i, annotation in enumerate(annotations):\n",
        "            historyDict = globals()[dictName][annotation]['history']\n",
        "            ax = plt.subplot(int(math.ceil(len(annotations)/2)),2, i+1)\n",
        "            ax.set_title('Neural Network Hidden Layer Structure: ' + annotation)\n",
        "            for color, mse in enumerate(mseNames):\n",
        "                ax.semilogy(\n",
        "                    range(1,len(historyDict[mse][epochRangeBegin:]) + 1),\n",
        "                    historyDict[mse][epochRangeBegin:],\n",
        "                    label=mse,linestyle=\"-\", color=colorList[color]\n",
        "                    )\n",
        "        if saveMSEplot: \n",
        "            figName = 'NNMeanSquaredErrorConvStudy' + fidelityLevel + '_'\n",
        "            dt = str(datetime.date.today())\n",
        "            figName += dt\n",
        "            os.chdir(path)\n",
        "            os.chdir(figureDir)\n",
        "            baseName = figName\n",
        "            counter = 2\n",
        "            while os.path.exists('./' + figName + '.png'):\n",
        "                figName = baseName + '_v' + str(counter)\n",
        "                counter += 1\n",
        "            plt.savefig(figName)\n",
        "            os.chdir(path)\n",
        "\n",
        "    if showSpeedPlot:\n",
        "        plt.rcParams[\"figure.figsize\"] = (6.4,4.8) \n",
        "        # plt.figure()\n",
        "        # plt.scatter(numParamsList, fileSizeList)\n",
        "        # x_values = [np.min(numParamsList), np.max(numParamsList)]\n",
        "        # y_values = [np.min(fileSizeList),np.max(fileSizeList)]\n",
        "        # for i, label in enumerate(annotations):\n",
        "        #     plt.annotate(label, (numParamsList[i], predictionTimeList[i]))\n",
        "        # plt.plot(x_values,y_values,'bo', linestyle = '--')\n",
        "        # plt.xlabel('Num of NN Params')\n",
        "        # plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
        "        # plt.ylabel('File Size (MB)')\n",
        "        # plt.show()\n",
        "        plt.figure()\n",
        "        numColors = (np.max(depthList) - np.min(depthList))+1\n",
        "        colors = plt.cm.jet(np.linspace(0,1,numColors))\n",
        "\n",
        "        for j, depth in enumerate(set(depthList)):\n",
        "            depthIdx = [int(i) for i in range(len(depthList)) if depthList[i] == j+1]\n",
        "            label = 'NN Depth: ' + str(depth)\n",
        "\n",
        "            x = [numParamsList[i] for i in depthIdx]\n",
        "            y = [frequencyList[i] for i in depthIdx]\n",
        "            plt.scatter(x, y, label=label, color=colors[j])\n",
        "            plt.xlabel('Num of NN Params')\n",
        "            plt.ylabel('Prediction Frequency (Hz)')\n",
        "            plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        if saveSpeedPlot: \n",
        "            figName = 'NNPredictionSpeed' + fidelityLevel + '_'\n",
        "            dt = str(datetime.date.today())\n",
        "            figName += dt\n",
        "            os.chdir(path)\n",
        "            os.chdir(figureDir)\n",
        "            baseName = figName\n",
        "            counter = 2\n",
        "            while os.path.exists('./' + figName + '.png'):\n",
        "                figName = baseName + '_v' + str(counter)\n",
        "                counter += 1\n",
        "            plt.savefig(figName)\n",
        "            os.chdir(path)\n",
        "\n",
        "    plt.rcParams[\"figure.figsize\"] = (6.4,4.8) #reset to defaults \n",
        "    \n",
        "\n",
        "def neuralNetworkSizeAndSpeedTest(numTestCases, numInputVars, numOutputVars, layerSizeList, hyperparamDict, showPlot):\n",
        "    \n",
        "    X_dummyData = np.random.rand(numTestCases, numInputVars)\n",
        "    y_dummyData = np.random.rand(numTestCases, numOutputVars)\n",
        "\n",
        "    numParamsList = []\n",
        "    fileSizeList = []\n",
        "    predictionTimeList = []\n",
        "    predictionTimePerCaseList = []\n",
        "    frequencyList = []\n",
        "    dictName = 'SizeandSpeedStudyDict' \n",
        "    globals()[dictName] = dict()\n",
        "    globals()[dictName]['layerSizeList'] = layerSizeList\n",
        "\n",
        "    annotations = [str(item) for item in layerSizeList]\n",
        "    print(annotations)\n",
        "\n",
        "    learningRate = hyperparamDict[\"learningRate\"]\n",
        "    regType = hyperparamDict[\"regType\"]\n",
        "    regValue = hyperparamDict[\"regValue\"]\n",
        "    hiddenLayerActivation = hyperparamDict[\"hiddenLayerActivation\"]\n",
        "    outputLayerActivation = hyperparamDict[\"outputLayerActivation\"]\n",
        "    kernelInitializer = hyperparamDict[\"kernelInitializer\"]\n",
        "    optimizer = hyperparamDict[\"optimizer\"]\n",
        "    numEpochs = 1000\n",
        "    myBatchSize = hyperparamDict[\"myBatchSize\"]\n",
        "    loss = hyperparamDict[\"loss\"]\n",
        "\n",
        "    currentTestTopDir = 'sizeAndSpeedTest_' + time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    sizeAndSpeedPath = os.path.join(path,modelDir,NNDir,sizeAndSpeedDir)\n",
        "    os.chdir(sizeAndSpeedPath)\n",
        "    os.mkdir(currentTestTopDir)\n",
        "    os.chdir(currentTestTopDir)\n",
        "    currentTestTopPath = os.path.join(sizeAndSpeedPath, currentTestTopDir)\n",
        "\n",
        "    for i, layerSizeList in enumerate(layerSizeList):\n",
        "        currentIter = i+1\n",
        "        NN = None #sometimes remnants of previously trained models can hang around, it's best to clear the variable first \n",
        "        NN = build_model_parameterized(\n",
        "            input_data = X_dummyData, \n",
        "            output_data = y_dummyData,\n",
        "            layerSizeList = layerSizeList, \n",
        "            rate = learningRate, \n",
        "            regType = regType, \n",
        "            regValue = regValue,\n",
        "            hiddenLayerActivation = hiddenLayerActivation,\n",
        "            outputLayerActivation = outputLayerActivation,\n",
        "            kernelInitializer = kernelInitializer,\n",
        "            optimizer = optimizer,\n",
        "            outputLayerDataType= 'float32',\n",
        "            loss = loss)\n",
        "\n",
        "        print('Iteration ', str(currentIter), ' training start')\n",
        "\n",
        "        train_model_all_fidelity(\n",
        "            model = NN, \n",
        "            input_data = X_dummyData, \n",
        "            output_data = y_dummyData,\n",
        "            numEpochs = numEpochs, \n",
        "            myBatchSize = myBatchSize,\n",
        "            validData = validData,\n",
        "            callbacks_list= None)\n",
        "\n",
        "        numParams = NN.count_params()\n",
        "        numParamsList.append(numParams)\n",
        "\n",
        "        kerasPath = os.path.join(sizeAndSpeedPath,currentTestTopDir)\n",
        "        os.chdir(kerasPath)\n",
        "        os.mkdir('temp')\n",
        "        os.chdir('temp')\n",
        "        NN.save(os.getcwd())\n",
        "        tempDirSize = (get_dir_size('.'))/(2**20)\n",
        "        fileSizeList.append(tempDirSize)\n",
        "\n",
        "        os.chdir(kerasPath)\n",
        "        shutil.rmtree('temp')\n",
        "        os.chdir(currentTestTopPath)\n",
        "        \n",
        "        predictionStart = time.time()\n",
        "        NN.predict(X_dummyData)\n",
        "        predictionEnd = time.time()\n",
        "            \n",
        "        predictionTime = predictionEnd-predictionStart\n",
        "        predictionTimeList.append(predictionTime)\n",
        "\n",
        "        predictionTimePerCase = (predictionTime)/numTestCases\n",
        "        predictionTimePerCaseList.append(predictionTimePerCase)\n",
        "\n",
        "        frequency = 1/((predictionTime)/numTestCases)\n",
        "        frequencyList.append(frequency)\n",
        "    \n",
        "    globals()[dictName]['numParamsList'] = numParamsList\n",
        "    globals()[dictName]['fileSizeList'] = fileSizeList\n",
        "    globals()[dictName]['predictionTimeList'] = predictionTimeList\n",
        "    globals()[dictName]['predictionTimePerCaseList'] = predictionTimePerCaseList\n",
        "    globals()[dictName]['frequencyList'] = frequencyList\n",
        "\n",
        "    currentTestTopPath = os.path.join(sizeAndSpeedPath,currentTestTopDir)\n",
        "    \n",
        "    saveVersionedPickle(\n",
        "    filename=dictName, \n",
        "    objectToSave=globals()[dictName],\n",
        "    path = currentTestTopPath\n",
        "    )\n",
        "    print('Dictionary name: ', dictName)\n",
        "    \n",
        "\n",
        "    if showPlot:\n",
        "        plt.rcParams[\"figure.figsize\"] = (6.4,4.8) \n",
        "        plt.scatter(numParamsList, fileSizeList)\n",
        "        x_values = [np.min(numParamsList), np.max(numParamsList)]\n",
        "        y_values = [np.min(fileSizeList),np.max(fileSizeList)]\n",
        "        for i, label in enumerate(annotations):\n",
        "            plt.annotate(label, (numParamsList[i], predictionTimeList[i]))\n",
        "        plt.plot(x_values,y_values,'bo', linestyle = '--')\n",
        "        plt.xlabel('Num of NN Params')\n",
        "        plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
        "        plt.ylabel('File Size (MB)')\n",
        "        plt.show()\n",
        "\n",
        "        numColors = (np.max(depthList) - np.min(depthList))+1\n",
        "        colors = plt.cm.jet(np.linspace(0,1,numColors))\n",
        "\n",
        "        for j, depth in enumerate(set(depthList)):\n",
        "            depthIdx = [int(i) for i in range(len(depthList)) if depthList[i] == j+1]\n",
        "            label = 'NN Depth: ' + str(depth)\n",
        "\n",
        "            x = [numParamsList[i] for i in depthIdx]\n",
        "            y = [frequencyList[i] for i in depthIdx]\n",
        "            plt.scatter(x, y, label=label, color=colors[j])\n",
        "            plt.xlabel('Num of NN Params')\n",
        "            plt.ylabel('Prediction Frequency (Hz)')\n",
        "            plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    os.chdir(path)\n",
        "    print('Convergence study complete. ')\n",
        "    return globals()[dictName]\n",
        "\n",
        "def highFidelityDataGenAndProcess(verbose=False,split=False):\n",
        "    \n",
        "    global inputTrainingData, inputTrainingNames,outputTrainingData, outputTrainingNames,M_inf, X, y , Y_names, X_names, originalIdx, X_train, X_test, y_train, y_test, M_inf_train, M_inf_test, trainIdx, testIdx, X_val, y_val, M_inf_val,  valIdx\n",
        "\n",
        "    inputTrainingData = []\n",
        "    inputTrainingNames = []\n",
        "\n",
        "    for i, name in enumerate(inputVarNames):\n",
        "        ScalerName = name + '_InputScaler'\n",
        "        ScaledName = name + '_Scaled'\n",
        "        InputDataName = 'input' + name\n",
        "        globals()[ScalerName] = None\n",
        "        globals()[ScalerName] = preprocessing.StandardScaler()\n",
        "        globals()[ScaledName] = globals()[ScalerName].fit_transform(globals()[InputDataName])\n",
        "        inputTrainingData.append(globals()[ScaledName])\n",
        "        inputTrainingNames.append(ScaledName)\n",
        "        max_element = str(round(np.max(globals()[ScaledName]),2))\n",
        "        min_element = str(round(np.min(globals()[ScaledName]),2))\n",
        "        if verbose: \n",
        "            print(name + ' has been scaled! It is called ' + ScaledName + '. Min:' + min_element + '. Max:' + max_element)\n",
        "\n",
        "    outputTrainingData = []\n",
        "    outputTrainingNames = []\n",
        "\n",
        "    for i, name in enumerate(outputVarNames):\n",
        "        ScalerName = name + '_OutputScaler'\n",
        "        ScaledName = name + '_Scaled'\n",
        "        OutputDataName = name\n",
        "        globals()[ScalerName] = None\n",
        "        globals()[ScalerName] = preprocessing.StandardScaler()\n",
        "        globals()[ScaledName] = globals()[ScalerName].fit_transform(globals()[OutputDataName])\n",
        "        outputTrainingData.append(globals()[ScaledName])\n",
        "        outputTrainingNames.append(ScaledName)\n",
        "        max_element = str(round(np.max(globals()[ScaledName]),2))\n",
        "        min_element = str(round(np.min(globals()[ScaledName]),2))\n",
        "        if verbose:\n",
        "            print(name + ' has been scaled! It is called ' + ScaledName + '. Min:' + min_element + '. Max:' + max_element)\n",
        "\n",
        "    gamma = 1.4 # perfect gas\n",
        "    R_specific = 287.058\n",
        "\n",
        "    T_inf = inputTemperature\n",
        "    rho_inf = inputDensity\n",
        "    u_inf = inputVelocity\n",
        "    a_inf = np.sqrt(gamma*R_specific*T_inf)\n",
        "    M_inf = u_inf/a_inf\n",
        "\n",
        "    ##### SKLEARN DATA SPLIT \n",
        "\n",
        "    X = np.hstack(inputTrainingData)\n",
        "    y = np.hstack(outputTrainingData)\n",
        "    Y_names = np.hstack(outputTrainingNames)\n",
        "    X_names = np.hstack(inputTrainingNames)\n",
        "    originalIdx = np.arange(0,X.shape[0])\n",
        "    if split:\n",
        "        X_train, X_test, y_train, y_test, M_inf_train, M_inf_test, trainIdx, testIdx = train_test_split(\n",
        "            X, y, M_inf, originalIdx, test_size=0.20, random_state=random_state)\n",
        "\n",
        "        X_test, X_val, y_test, y_val, M_inf_test, M_inf_val, testIdx, valIdx = train_test_split(\n",
        "            X_test, y_test, M_inf_test, testIdx, test_size=0.50, random_state=random_state)\n",
        "        # M_inf_train, M_inf_test = train_test_split(M_inf,test_size=0.20,random_state=random_state) # used in plotting\n",
        "        # M_inf_test, M_inf_val = train_test_split(M_inf_test,test_size=0.50,random_state=random_state) # used in plotting\n",
        "        if verbose: \n",
        "            print('Input Data (stored in list inputTrainingData):\\n')\n",
        "            print('\\nOutput Data (stored in list outputTrainingData):\\n')\n",
        "            print(str(np.shape(inputTrainingData)))\n",
        "            print(str(np.shape(outputTrainingData)))\n",
        "            print(inputTrainingNames)\n",
        "            print(outputTrainingNames)\n",
        "            print(\"X_train shape: {}\".format(X_train.shape))\n",
        "            print(\"X_test shape: {}\".format(X_test.shape))\n",
        "            print(\"y_train shape: {}\".format(y_train.shape))\n",
        "            print(\"y_test shape: {}\".format(y_test.shape))\n",
        "            print(\"X_val shape: {}\".format(X_val.shape))\n",
        "            print(\"y_val shape: {}\".format(y_val.shape))\n",
        "            print(f\"concatenation order: {X_names}\")\n",
        "            print(f\"concatenation order: {Y_names}\")\n",
        "\n",
        "def lowFidelityDataGenAndProcess(downsampleLF:bool, verbose=False):\n",
        "    ## Input Conditions, low fidelity data generation\n",
        "\n",
        "    # These probably should be renamed to be consistent with the input variables already created. \n",
        "\n",
        "\n",
        "    # inputVar list contains:  ['WallTemp', 'Density', 'Temperature', 'Velocity']\n",
        "\n",
        "    gamma = 1.4 # perfect gas\n",
        "    R_specific = 287.058\n",
        "    cp1 = 1.005 #KJ/Kg*K, air at 251K\n",
        "\n",
        "    LFinputVarNames = [\n",
        "        'T_w',\n",
        "        'rho_inf',\n",
        "        'T_inf',\n",
        "        'u_inf'\n",
        "    ]\n",
        "\n",
        "    for i, inputVarName in enumerate(LFinputVarNames): \n",
        "        globals()[inputVarName] = lowFidelityInputPoints[:,i].reshape(-1,1)\n",
        "        if verbose:\n",
        "            print(inputVarName, 'created , shape ', str(globals()[inputVarName].shape))\n",
        "            print(\"Lower bound: \", globals()[inputVarName].min(), \". Upper bound: \", globals()[inputVarName].max())\n",
        "\n",
        "    numCases = lowFidelityInputPoints.shape[0]\n",
        "    if verbose:\n",
        "        print('Num low-fidelity cases: ', str(numCases))\n",
        "\n",
        "    a_inf = np.sqrt(gamma*R_specific*T_inf)\n",
        "    M_inf = u_inf/a_inf\n",
        "    P_inf = rho_inf*R_specific*T_inf\n",
        "    mu_inf = mu_suth(T_inf)\n",
        "\n",
        "    theta  = np.full((numCases,1),np.deg2rad(7))\n",
        "\n",
        "    inputDataObliqueShock = M_inf,u_inf,T_inf,P_inf,rho_inf,a_inf,theta\n",
        "\n",
        "    [*temp] = map(perfgas_oblique, M_inf,u_inf,T_inf,P_inf,rho_inf,a_inf,theta)\n",
        "    obliqueShockResults = np.array(temp)\n",
        "\n",
        "    # print(M_inf.shape,u_inf.shape,T_inf.shape,P_inf.shape,rho_inf.shape,a_inf.shape, theta.shape )\n",
        "    outputLocalMethodVarName = [\n",
        "        'H2', \n",
        "        'V2', \n",
        "        'T2', \n",
        "        'P2', \n",
        "        'rho2',\n",
        "        'beta',\n",
        "        'M2',\n",
        "        'a2', \n",
        "        'T01', \n",
        "        'T02',\n",
        "        'P01',\n",
        "        'P02'\n",
        "    ]\n",
        "\n",
        "    for i, name in enumerate(outputLocalMethodVarName):\n",
        "        globals()[name] = obliqueShockResults[:,i]\n",
        "        # print(globals()[name].shape)\n",
        "    ## ---- Pressure Coefficient ----\n",
        "\n",
        "    # Shock Expansion for 7deg Section\n",
        "\n",
        "    shockAngle = beta\n",
        "\n",
        "    cp_ShockExpansionTheory = (4/(gamma+1))*(np.sin(shockAngle)**2 - (1/(M_inf**2)))\n",
        "    cp_newtonian_coneAngle = 2*(np.sin(theta)**2)\n",
        "\n",
        "    xPressureWindowStart = 0.5\n",
        "    xPressureWindowEnd = 2.0\n",
        "    xPressureWindowMid = 0.5\n",
        "\n",
        "    xSpotBegin = (np.abs(x_cc_windowed[0,:] - xPressureWindowStart)).argmin()\n",
        "    xSpotEnd = (np.abs(x_cc_windowed[0,:] - xPressureWindowEnd)).argmin()\n",
        "    xSpotNoMean = (np.abs(x_cc_windowed[0,:] - xPressureWindowMid)).argmin()\n",
        "\n",
        "    # PressureForCPActual = p[:,xSpotNoMean].reshape(-1,1)\n",
        "    # cp_actual = (PressureForCPActual - P_inf)/ (0.5*rho_inf*(u_inf**2))\n",
        "    # cp_actual[389] = None # takes care of that one bad point\n",
        "\n",
        "    #Shock Expansion For 40deg Section\n",
        "\n",
        "    T_inf2 = T2\n",
        "    # T_w = T_w\n",
        "    rho_inf2 = rho2\n",
        "    u_inf2 = M2*a2\n",
        "    a_inf2 = a2\n",
        "    M_inf2 = M2\n",
        "    P_inf2 = P2\n",
        "    mu_inf2 = mu_suth(T2)\n",
        "    theta2  = np.full((numCases,1),np.deg2rad(33))\n",
        "\n",
        "    [*temp] = map(perfgas_oblique, M_inf2,u_inf2,T_inf2,P_inf2,rho_inf2,a_inf2,theta2)\n",
        "    obliqueShockResults = np.array(temp)\n",
        "\n",
        "    outputLocalMethodVarName = [\n",
        "        'H3', \n",
        "        'V3', \n",
        "        'T3', \n",
        "        'P3', \n",
        "        'rho3',\n",
        "        'beta2',\n",
        "        'M3',\n",
        "        'a3', \n",
        "        'T02', \n",
        "        'T03',\n",
        "        'P02',\n",
        "        'P03'\n",
        "    ]\n",
        "\n",
        "    for i, name in enumerate(outputLocalMethodVarName):\n",
        "        globals()[name] = obliqueShockResults[:,i]\n",
        "    xPressureWindowLeft = 2.353056 # elbow location\n",
        "    xPressureWindowRight = 2.5039961 # end of cone\n",
        "\n",
        "    xPressureWindowMid = 2.4\n",
        "    xSpotLeft = (np.abs(x_cc_windowed[0,:] - xPressureWindowLeft)).argmin()\n",
        "    xSpotRight = (np.abs(x_cc_windowed[0,:] - xPressureWindowRight)).argmin()\n",
        "\n",
        "    # meanPressure40DegConeSection = np.median(p[:,xSpotLeft:xSpotRight], axis = 1).reshape(-1,1)\n",
        "    # cp_actual2 = (meanPressure40DegConeSection - P_inf2)/ (0.5*rho_inf2*(u_inf2**2))\n",
        "    # cp_actual2[389] = None # takes care of that one bad case\n",
        "\n",
        "    cp_newtonian_coneAngle2 = 2*(np.sin(theta2)**2)\n",
        "    shockAngle2 = beta2\n",
        "    cp_ShockExpansionTheory2 = (4/(gamma+1))*(np.sin(shockAngle2)**2 - (1/(M_inf2**2)))\n",
        "\n",
        "    p_SE_7deg = cp_ShockExpansionTheory*(0.5*rho_inf*(u_inf**2)) + P_inf\n",
        "    p_Newtonian_40deg = cp_newtonian_coneAngle2*(0.5*rho_inf2*(u_inf2**2)) + P_inf2\n",
        "    p_SE_40deg = cp_ShockExpansionTheory2*(0.5*rho_inf2*(u_inf2**2)) + P_inf2\n",
        "\n",
        "    xSpotElbow = (np.abs(x_cc_windowed[0,:] - xPressureWindowLeft)).argmin()\n",
        "\n",
        "    p_lf_7deg = np.tile(p_SE_7deg, xSpotElbow+1)\n",
        "    p_lf_40deg_newt = np.tile(p_Newtonian_40deg, xSpotRight - xSpotLeft)\n",
        "    p_lf_40deg = np.tile(p_SE_40deg, xSpotRight - xSpotLeft)\n",
        "    p_lowFidelity_SE = np.concatenate((p_lf_7deg, p_lf_40deg), axis=1)\n",
        "    p_lowFidelity_Newt = np.concatenate((p_lf_7deg, p_lf_40deg_newt), axis=1)\n",
        "\n",
        "    p_lowFidelity_SE_truncated = np.concatenate((p_SE_7deg, p_SE_40deg), axis=1)\n",
        "    p_lowFidelity_SE_truncated = p_lowFidelity_SE_truncated.T\n",
        "\n",
        "    # normalizedHFPressure = p/P03\n",
        "    # normalizedLFPressure = p_lowFidelity_SE/P03\n",
        "    # normalizedLFPressureNewt = p_lowFidelity_Newt/P03\n",
        "\n",
        "    p_LF = p_lowFidelity_SE\n",
        "    if verbose:\n",
        "        print(\"p_LF shape: \" ,p_LF.shape)\n",
        "\n",
        "    ## ---- Eckert's Reference Temperature, Cone Example ----\n",
        "\n",
        "    Pr = 0.72\n",
        "    recovFactor = np.sqrt(Pr)\n",
        "    xSpotEndArtificial = x_cc_windowed[0,:].shape[0] - xSpotElbow\n",
        "\n",
        "    x_FrontCone = x_cc_windowed[0,:xSpotElbow]\n",
        "    x_RearCone = x_cc_windowed[0,:xSpotEndArtificial] - 0.25\n",
        "\n",
        "    T_star = 0.5*(T2 + T_w) + .22*recovFactor*(T02 - T2)\n",
        "    rho_star = P2/ (R_specific*T_star)\n",
        "    mu_star = mu_suth(T2)\n",
        "    u2 = M2 * a2\n",
        "    Re_coeff = rho_star*u2/mu_star\n",
        "    Re_x = Re_coeff * x_FrontCone\n",
        "    cone_factor = np.sqrt(3)\n",
        "    cH_coeff = (cone_factor*0.332)/((Pr**(2/3))*(Re_coeff**(.5)))\n",
        "    cH_star = cH_coeff / x_FrontCone**(1/2)\n",
        "    T_r = T2 + recovFactor*(T02 - T2)\n",
        "    q_dot_FrontCone = rho_star*u2*cp1*1000*(T_r - T_w)*cH_star\n",
        "\n",
        "    T_star2 = 0.5*(T3 + T_w) + .22*recovFactor*(T03 - T3)\n",
        "    rho_star2 = P3/ (R_specific*T_star2)\n",
        "    mu_star2 = mu_suth(T3)\n",
        "    u3 = M3* a3\n",
        "    Re_coeff2 = rho_star2*u2/mu_star2\n",
        "    Re_x2 = Re_coeff2 * x_RearCone\n",
        "    cH_coeff2 = (cone_factor*0.332)/((Pr**(2/3))*(Re_coeff2**(.5)))\n",
        "    cH_star2 = cH_coeff2 / x_RearCone**(1/2)\n",
        "    T_r2 = T3 + recovFactor*(T03 - T3)\n",
        "    q_dot_RearCone = rho_star2*u3*cp1*1000*(T_r2 - T_w)*cH_star2\n",
        "\n",
        "    qw_LF = np.concatenate((q_dot_FrontCone, q_dot_RearCone), axis=1)\n",
        "    if verbose: \n",
        "        print(\"qw_LF shape: \" ,qw_LF.shape)\n",
        "\n",
        "    LFoutputVarNames = ['qw_LF','p_LF']    \n",
        "\n",
        "    totalParamsTrainData = 0\n",
        "    for var in LFoutputVarNames:\n",
        "        globals()[var] = locals()[var]\n",
        "        totalParamsTrainData += globals()[var].shape[0] * globals()[var].shape[1]\n",
        "        if verbose: \n",
        "            print(var, \"globals:\" , globals()[var].shape,\"locals: \", locals()[var].shape)\n",
        "    if verbose:\n",
        "        print('Total number of parameters in training data: ', totalParamsTrainData)\n",
        "        print(\"outlierRemoval criteria:\", outlierRemoval, \" and \", (locals()[LFoutputVarNames[0]].shape[0] == numCases))\n",
        "        print(globals()[LFoutputVarNames[0]].shape[0], \"== \", numCases)\n",
        "\n",
        "    if outlierRemoval and (globals()[LFoutputVarNames[0]].shape[0] == numCases):\n",
        "        if verbose:\n",
        "            print('Entered outlier removal loop')\n",
        "        casesToRemove = np.argwhere(np.isnan(qw_LF).any(axis=1))\n",
        "        if numpPointsMultiplier == 2:\n",
        "            casesToRemove = [648]\n",
        "        \n",
        "        for i, outputVarName in enumerate(LFoutputVarNames): \n",
        "            globals()[outputVarName] = np.delete(locals()[outputVarName], casesToRemove, axis=0)\n",
        "            if verbose:\n",
        "                print(outputVarName, 'new shape ', str(globals()[outputVarName].shape))\n",
        "\n",
        "        for i, inputVarName in enumerate(LFinputVarNames): \n",
        "            globals()[inputVarName] = np.delete(globals()[inputVarName], casesToRemove, axis=0)\n",
        "            if verbose:\n",
        "                print(inputVarName, 'new shape ', str(globals()[inputVarName].shape))\n",
        "\n",
        "        M_inf = np.delete(M_inf, casesToRemove, axis=0)\n",
        "        if verbose:\n",
        "            print('M_inf new shape ', str(M_inf.shape))\n",
        "            print('Removed ', len(casesToRemove), ' case(s).')\n",
        "\n",
        "\n",
        "    LFinputTrainingData = []\n",
        "    LFinputTrainingNames = []\n",
        "\n",
        "    if verbose:\n",
        "        print('Input Data (stored in list inputTrainingData):\\n')\n",
        "    for i, name in enumerate(LFinputVarNames):\n",
        "        ScalerName = name + '_InputScaler'\n",
        "        ScaledName = name + '_Scaled'\n",
        "        globals()[ScalerName] = None\n",
        "        globals()[ScalerName] = preprocessing.StandardScaler()\n",
        "        globals()[ScaledName] = globals()[ScalerName].fit_transform(globals()[name])\n",
        "        LFinputTrainingData.append(globals()[ScaledName])\n",
        "        LFinputTrainingNames.append(ScaledName)\n",
        "        max_element = str(round(np.max(globals()[ScaledName]),2))\n",
        "        min_element = str(round(np.min(globals()[ScaledName]),2))\n",
        "        if verbose:\n",
        "            print(name + ' has been scaled! It is called ' + ScaledName + '. Min:' + min_element + '. Max:' + max_element)\n",
        "\n",
        "    LFoutputTrainingData = []\n",
        "    LFoutputTrainingNames = []\n",
        "\n",
        "    if verbose:\n",
        "        print('\\nOutput Data (stored in list LFoutputTrainingData):\\n')\n",
        "    for i, name in enumerate(LFoutputVarNames):\n",
        "        ScalerName = name + '_OutputScaler'\n",
        "        ScaledName = name + '_Scaled'\n",
        "        OutputDataName = name\n",
        "        globals()[ScalerName] = None\n",
        "        globals()[ScalerName] = preprocessing.StandardScaler()\n",
        "        globals()[ScaledName] = globals()[ScalerName].fit_transform(globals()[OutputDataName])\n",
        "        LFoutputTrainingData.append(globals()[ScaledName])\n",
        "        LFoutputTrainingNames.append(ScaledName)\n",
        "        max_element = str(round(np.max(globals()[ScaledName]),2))\n",
        "        min_element = str(round(np.min(globals()[ScaledName]),2))\n",
        "        if verbose:\n",
        "            print(name + ' has been scaled! It is called ' + ScaledName + '. Min:' + min_element + '. Max:' + max_element)\n",
        "    if verbose and not downsampleLF: \n",
        "            print(\"Number of input variables: \",  str(np.shape(LFinputTrainingData)[0] ) )\n",
        "            print(\"Shape of LFinputTrainingData: \",  str(np.shape(LFinputTrainingData) ) )\n",
        "            print(\"Number of output variables: \",  str(np.shape(LFoutputTrainingData)[0] ) )\n",
        "            print(\"Number of variables in output distribution: \",  str(np.shape(LFoutputTrainingData)[2] ))\n",
        "            print(\"Shape of LFoutputTrainingData: \",  str(np.shape(LFoutputTrainingData) ) )\n",
        "            print(\"LFinputTrainingNames: \", LFinputTrainingNames)\n",
        "            print(\"LFoutputVarNames: \", LFoutputVarNames)\n",
        "            print(\"LFoutputTrainingNames: \", LFoutputTrainingNames)\n",
        "\n",
        "    if downsampleLF: \n",
        "        ##################################################\n",
        "        ####### Heat Flux and Pressure Downsample ########\n",
        "        ################################################## \n",
        "        conePoint = 2.0\n",
        "        flarePoint = 2.49\n",
        "        xLocationPressureValue1 = (np.abs(x_cc_windowed[0,:] - conePoint)).argmin()\n",
        "        xLocationPressureValue2 = (np.abs(x_cc_windowed[0,:] - flarePoint)).argmin()\n",
        "\n",
        "        indices = [xLocationPressureValue1, xLocationPressureValue2]\n",
        "        LFoutputTrainingData = []\n",
        "        for name in LFoutputTrainingNames:\n",
        "            globals()[name] = np.take(globals()[name], indices, axis=1)\n",
        "            LFoutputTrainingData.append(globals()[name])\n",
        "            if verbose:\n",
        "                print(name, ' truncated. Added to LFoutputTrainingData')\n",
        "        x_downsampledPressure = np.take(x_cc_windowed, indices, axis=1)\n",
        "        if verbose:\n",
        "            print(\"Number of input variables: \",  str(np.shape(LFinputTrainingData)[0] ) )\n",
        "            print(\"Shape of LFinputTrainingData: \",  str(np.shape(LFinputTrainingData) ) )\n",
        "            print(\"Number of output variables: \",  str(np.shape(LFoutputTrainingData)[0] ) )\n",
        "            print(\"Number of variables in output distribution: \",  str(np.shape(LFoutputTrainingData)[2] ))\n",
        "            print(\"Shape of LFoutputTrainingData: \",  str(np.shape(LFoutputTrainingData) ) )\n",
        "            print(\"LFinputTrainingNames: \", LFinputTrainingNames)\n",
        "            print(\"LFoutputVarNames: \", LFoutputVarNames)\n",
        "            print(\"LFoutputTrainingNames: \", LFoutputTrainingNames)\n",
        "\n",
        "    ##### SKLEARN DATA SPLIT \n",
        "    global X, y_lf, Y_lf_names,X_names,originalIdx,X_train, y_lf_train, M_inf_train, trainIdx, X_test, X_val, y_lf_test, y_lf_val, M_inf_test, M_inf_val, testIdx, valIdx\n",
        "\n",
        "\n",
        "    X = np.hstack(LFinputTrainingData)\n",
        "    y_lf = np.hstack(LFoutputTrainingData)\n",
        "    Y_lf_names = np.hstack(LFoutputTrainingNames)\n",
        "    X_names = np.hstack(LFinputTrainingNames)\n",
        "    originalIdx = np.arange(0,X.shape[0])\n",
        "    if verbose: \n",
        "        print(\"X.shape: \", X.shape)\n",
        "        print(\"y_lf.shape: \", y_lf.shape)\n",
        "        print(\"M_inf.shape: \", M_inf.shape)\n",
        "        print(\"originalIdx.shape: \", originalIdx.shape)\n",
        "    \n",
        "\n",
        "\n",
        "    X_train, X_test, y_lf_train, y_lf_test, M_inf_train, M_inf_test, trainIdx, testIdx = train_test_split(\n",
        "        X, y_lf, M_inf, originalIdx, test_size=0.20, random_state=random_state)\n",
        "\n",
        "    X_test, X_val, y_lf_test, y_lf_val, M_inf_test, M_inf_val, testIdx, valIdx = train_test_split(\n",
        "        X_test, y_lf_test, M_inf_test, testIdx, test_size=0.50, random_state=random_state)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Low fidelity X_train shape: {}\".format(X_train.shape))\n",
        "        print(\"Low fidelity X_test shape: {}\".format(X_test.shape))\n",
        "        print(\"Low fidelity X_val shape: {}\".format(X_val.shape))\n",
        "        print(\"Low fidelity y_lf_train shape: {}\".format(y_lf_train.shape))\n",
        "        print(\"Low fidelity y_lf_test shape: {}\".format(y_lf_test.shape))\n",
        "        print(\"Low fidelity y_lf_val shape: {}\".format(y_lf_val.shape))\n",
        "        print(f\"concatenation order: {X_names}\")\n",
        "        print(f\"concatenation order: {Y_lf_names}\")\n",
        "    \n",
        "    print(\"Low fidelity data generated, scaled, and split. Low fidelity output data truncation: \", downsampleLF)\n",
        "\n",
        "def genPredictionsForError(\n",
        "    modelType:str, modelObject, fidelityLevel:str, verbose:bool,truncate:bool, X_test, X_train, y_test, y_train\n",
        "    ): \n",
        "    modelName = modelType\n",
        "\n",
        "    dataSplitNames = [\n",
        "        '_' + modelName + '_test_predict',\n",
        "        '_' + modelName + '_train_predict',\n",
        "        '_' + fidelityLevel + '_test_truth',\n",
        "        '_' + fidelityLevel + '_train_truth'\n",
        "        ]\n",
        "    numDataSplit = int(len(dataSplitNames)/2) # are we splitting into train/test (numDataSplit = 2) or train/test/validation (numDataSplit =3) ? \n",
        "\n",
        "    #######################################\n",
        "\n",
        "    locals()[dataSplitNames[0][1:]] = modelObject.predict(X_test)\n",
        "    locals()[dataSplitNames[1][1:]] = modelObject.predict(X_train)\n",
        "\n",
        "\n",
        "    locals()[dataSplitNames[2][1:]] = y_test\n",
        "    locals()[dataSplitNames[3][1:]] = y_train\n",
        "    #######################################\n",
        "\n",
        "    variableNameList =[] #to be used for the \"un-truncating\"\n",
        "    if verbose:\n",
        "        print(f'outputVarnames: {outputVarNames}, for i in np.arange(len(outputVarNames)): {np.arange(len(outputVarNames))}')\n",
        "    for i in np.arange(len(outputVarNames)):\n",
        "        for j in np.arange(numDataSplit):\n",
        "            #Input Data Split\n",
        "            locals()[outputVarNames[j] + dataSplitNames[i]] = np.hsplit(locals()[dataSplitNames[i][1:]],numDataSplit)[j]\n",
        "            variableNameList.append(outputVarNames[j] + dataSplitNames[i])\n",
        "            if verbose:\n",
        "                print(f'{outputVarNames[j] + dataSplitNames[i]} = np.hsplit({[dataSplitNames[i][1:]]},{numDataSplit})[{j}]')\n",
        "                print(f\"variableNameList.append({outputVarNames[j] + dataSplitNames[i]})\")\n",
        "\n",
        "            locals()[outputVarNames[j] + dataSplitNames[i+2]] = np.hsplit(locals()[dataSplitNames[i+2][1:]],numDataSplit)[j]\n",
        "            variableNameList.append(outputVarNames[j] + dataSplitNames[i+2])  \n",
        "            if verbose:\n",
        "                print(f'{outputVarNames[j] + dataSplitNames[i+2]} = np.hsplit({[dataSplitNames[i+2][1:]]},{numDataSplit})[{j}]')\n",
        "                print(f\"variableNameList.append({outputVarNames[j] + dataSplitNames[i+2]})\") \n",
        "    time.sleep(2)\n",
        "    if truncate: \n",
        "        leftFluidScalarDistributionLength = globals()[outputVarNames[0]][0,:xSpotLeft].shape[0]\n",
        "        rightFluidScalarDistributionLength =  globals()[outputVarNames[0]][0,xSpotLeft:].shape[0]\n",
        "        if verbose:\n",
        "            print(\"leftFluidScalarDistributionLength:\", leftFluidScalarDistributionLength)\n",
        "            print(\"rightFluidScalarDistributionLength:\", rightFluidScalarDistributionLength)\n",
        "\n",
        "        for var in variableNameList:\n",
        "            temp_left = [np.tile(entry, leftFluidScalarDistributionLength) for entry in locals()[var][:,0] ]\n",
        "            temp_right = [np.tile(entry,rightFluidScalarDistributionLength) for entry in locals()[var][:,1] ]\n",
        "            temp_stacked = np.hstack((temp_left,temp_right))\n",
        "            locals()[var] = temp_stacked\n",
        "            if verbose:\n",
        "                print(var, \" shape: \", locals()[var].shape)\n",
        "########### Inverse Scale ###########\n",
        "\n",
        "    if fidelityLevel == 'LF':\n",
        "\n",
        "        for name in LFoutputVarNames:\n",
        "            ScalerName = name + '_OutputScaler'\n",
        "            for tail in dataSplitNames:\n",
        "                fullName = name[0:-3] + tail\n",
        "                locals()[fullName] = globals()[ScalerName].inverse_transform(locals()[fullName])\n",
        "                if verbose:\n",
        "                    print(fullName + ' = ' + ScalerName + '.inverse_transform(' +  fullName + ')')\n",
        "                \n",
        "    else:\n",
        "        \n",
        "        for name in outputVarNames:\n",
        "            ScalerName = name + '_OutputScaler'\n",
        "            for tail in dataSplitNames:\n",
        "                fullName = name + tail\n",
        "                locals()[fullName] = globals()[ScalerName].inverse_transform(locals()[fullName])\n",
        "                if verbose:\n",
        "                    print( fullName + ' has been inverse transformed using ' + ScalerName + '! It is called ' + fullName)\n",
        "\n",
        "    single_nrmse = []\n",
        "    single_R2 = []\n",
        "    single_medianPeakMiss = []\n",
        "    single_meanPeakMiss = []\n",
        "\n",
        "    for var in outputVarNames:\n",
        "        chosenVar = var\n",
        "        chosenSet = 'test'\n",
        "        matches = [match for match in variableNameList if (chosenSet in match) and (chosenVar+'_' in match)]\n",
        "\n",
        "        truth = locals()[matches[1]]\n",
        "        prediction = locals()[matches[0]]\n",
        "        peakTruth = np.amax(truth,axis=1)\n",
        "        peakPrediction = np.amax(prediction,axis=1)\n",
        "        peakPercentDifference = percentdifferencecalc(peakTruth,peakPrediction)\n",
        "\n",
        "        medianPeakMiss = np.median(peakPercentDifference)\n",
        "        meanPeakMiss = np.mean(peakPercentDifference)\n",
        "        rmse = mean_squared_error(truth, prediction, squared=False)\n",
        "        ybar = truth.max()-truth.min()\n",
        "        nrmse = round(rmse/ybar,5)\n",
        "        R2 = round(r2_score(truth, prediction),4)\n",
        "        \n",
        "        single_R2.append(R2)\n",
        "        single_nrmse.append(nrmse)\n",
        "        single_medianPeakMiss.append(medianPeakMiss)\n",
        "        single_meanPeakMiss.append(meanPeakMiss)\n",
        "\n",
        "        locals()[matches[0]] = None\n",
        "        locals()[matches[1]] = None\n",
        "\n",
        "\n",
        "    average_nrmse = np.mean(single_nrmse)\n",
        "    average_R2 = np.mean(single_R2)\n",
        "    return single_nrmse, average_nrmse, single_R2, average_R2, single_medianPeakMiss, single_meanPeakMiss\n",
        "\n",
        "def buildAndTrainModel(X_train, y_train,validData, fidelityLevel,modelType,truncate:bool,verbose:bool,frequencyData: bool, layerSizeList=None,kernel=None, n_restarts=None, hyperparamDict=None, callbacks_list=None):\n",
        "\n",
        "    desiredXpredictSize = 1000\n",
        "    multiplier = math.floor(desiredXpredictSize/X_train.shape[0])\n",
        "    X_predictionSpeed = np.tile(X_train,(multiplier,1))\n",
        "    frequencyTempList = []\n",
        "    numTestCases = X_predictionSpeed.shape[0]\n",
        "\n",
        "    (X_test, y_test) = validData \n",
        "\n",
        "    if modelType == 'NN':\n",
        "        NN = None\n",
        "        NN = build_model_parameterized(\n",
        "                input_data = X_train, \n",
        "                output_data = y_train,\n",
        "                layerSizeList = layerSizeList, \n",
        "                rate = hyperparamDict[\"learningRate\"], \n",
        "                regType = hyperparamDict[\"regType\"], \n",
        "                regValue = hyperparamDict[\"regValue\"],\n",
        "                hiddenLayerActivation = hyperparamDict[\"hiddenLayerActivation\"],\n",
        "                outputLayerActivation = hyperparamDict[\"outputLayerActivation\"],\n",
        "                outputLayerDataType= 'float32',\n",
        "                kernelInitializer = hyperparamDict[\"kernelInitializer\"],\n",
        "                optimizer = hyperparamDict[\"optimizer\"],\n",
        "                loss = hyperparamDict[\"loss\"])\n",
        "\n",
        "        NN_epochs = None\n",
        "        NN_history = None\n",
        "        \n",
        "        start = time.time()\n",
        "        NN_epochs, NN_history = train_model_all_fidelity(\n",
        "            model = NN, \n",
        "            input_data = X_train, \n",
        "            output_data = y_train,\n",
        "            numEpochs = hyperparamDict[\"numEpochs\"], \n",
        "            myBatchSize = hyperparamDict[\"myBatchSize\"],\n",
        "            validData = validData,\n",
        "            callbacks_list= callbacks_list)\n",
        "        end = time.time()\n",
        "        trainTime = round(end-start,4)\n",
        "        tf.get_logger().setLevel('WARNING')\n",
        "        currentLocation = os.getcwd()\n",
        "        os.mkdir('temp')\n",
        "        os.chdir('temp')\n",
        "        NN.save(os.getcwd())\n",
        "        modelSize = (get_dir_size('.'))\n",
        "\n",
        "        os.chdir(currentLocation)\n",
        "        shutil.rmtree('temp')\n",
        "        \n",
        "    \n",
        "    if modelType == 'krig':\n",
        "        krig = None\n",
        "        krig = gaussian_process.GaussianProcessRegressor(kernel=kernel,n_restarts_optimizer=n_restarts)\n",
        "        start = time.time()\n",
        "        krig.fit(X_train, y_train)\n",
        "        end = time.time()\n",
        "        trainTime = round(end-start,4)\n",
        "        optimizedKernel = krig.kernel_\n",
        "        krigPickle = pickle.dumps(krig)\n",
        "        modelSize = sys.getsizeof(krigPickle)\n",
        "        krigPickle = None\n",
        "        \n",
        "\n",
        "    model = locals()[modelType]\n",
        "    if frequencyData:\n",
        "        frequencyTempList = []\n",
        "        predictionTimeTempList = []\n",
        "        numTestCases = X_predictionSpeed.shape[0]\n",
        "        predictionLoopStart = time.time()\n",
        "        for _ in np.arange(0,200):\n",
        "            predictionStart = time.time()\n",
        "            model.predict(X_predictionSpeed)\n",
        "            predictionEnd = time.time()\n",
        "            predictionTime = predictionEnd-predictionStart\n",
        "            predictionTimeTempList.append(predictionTime)\n",
        "            try:\n",
        "                frequency = 1/((predictionTime)/numTestCases)\n",
        "                frequencyTempList.append(frequency)\n",
        "            except:\n",
        "                print('frequency too fast!')\n",
        "                pass\n",
        "        predictionLoopEnd = time.time()\n",
        "        frequencyTestAverage = np.mean(frequencyTempList)\n",
        "        predictionLoopTime = round(predictionLoopEnd-predictionLoopStart,4)\n",
        "        print(f'Train time: {trainTime}.  Prediction time: {predictionLoopTime}')\n",
        "    else: \n",
        "        frequencyTestAverage = 'freq not tested'\n",
        "\n",
        "    single_nrmse, average_nrmse, single_R2, average_R2, single_medianPeakMiss, single_meanPeakMiss = genPredictionsForError(\n",
        "        modelType=modelType,\n",
        "        modelObject=model,\n",
        "        fidelityLevel=fidelityLevel,\n",
        "        verbose=verbose,\n",
        "        truncate=truncate,\n",
        "        X_test=X_test,\n",
        "        X_train=X_train,\n",
        "        y_test=y_test,\n",
        "        y_train= y_train\n",
        "        )\n",
        "\n",
        "    model = None; NN = None; krig = None\n",
        "\n",
        "    if modelType == 'krig':\n",
        "        return optimizedKernel, trainTime, average_nrmse, single_nrmse, single_R2, average_R2, single_medianPeakMiss, single_meanPeakMiss, modelSize, frequencyTestAverage\n",
        "    elif modelType == 'NN':\n",
        "        return NN_epochs, NN_history, trainTime, average_nrmse, single_nrmse, single_R2, average_R2, single_medianPeakMiss, single_meanPeakMiss, modelSize, frequencyTestAverage\n",
        "\n",
        "def cleanKernelList(kernelList):\n",
        "    kernelList = [str(item) for item in kernelList]\n",
        "\n",
        "    disallowed_characters = '()'\n",
        "    firstCleanList = []\n",
        "    for s in kernelList:\n",
        "        for char in disallowed_characters:\n",
        "            s = s.replace(char, ' ')\n",
        "        s = s.translate({ord(k): None for k in digits})\n",
        "        firstCleanList.append(s)\n",
        "\n",
        "    secondCleanList = []\n",
        "    for element in firstCleanList:\n",
        "        secondCleanList.append(element.split( ))\n",
        "\n",
        "    cleanedKernelList = []\n",
        "    for string in secondCleanList:\n",
        "        cleanedKernelList.append([item for item in string if item[0].isupper()])\n",
        "\n",
        "    return cleanedKernelList\n",
        "def modelConvergenceStudy(\n",
        "    fidelityLevel: str, modelType: str, M_inf, inputTrainingData, outputTrainingData, inputTrainingNames, outputTrainingNames, top_n_modelChoices: list, splitList: list, frequencyData: bool, verbose: bool, truncate: bool, hyperparamDict=None, callbacks_list=None, n_restarts=None, \n",
        "    ):\n",
        "\n",
        "    #Set variables\n",
        "    numIters = len(splitList)\n",
        "    modelName = fidelityLevel + \"_\" + modelType\n",
        "    dictName = modelName+\"_modelConvergenceDict\"\n",
        "    polyFitDict = {\"NN\": 1, \"krig\":2}\n",
        "\n",
        "    #Initialize data structures\n",
        "    completionTime = []\n",
        "    globals()[dictName]= dict()\n",
        "    \n",
        "    #Store list of model choices in dictionary\n",
        "    globals()[dictName][\"top_n_modelChoices\"] = top_n_modelChoices\n",
        "\n",
        "    #Create list of strings, top model choices. Used in dictionary\n",
        "    annotations = [str(item) for item in top_n_modelChoices]\n",
        "\n",
        "    # Name and create directories/paths\n",
        "    currentConvStudyTopDir = modelName + time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    convStudyPath = os.path.join(path,modelConvStudyDir)\n",
        "    os.chdir(convStudyPath)\n",
        "    os.mkdir(currentConvStudyTopDir)\n",
        "    os.chdir(currentConvStudyTopDir)\n",
        "\n",
        "    ##### Store input and output data in X and y variables\n",
        "    if fidelityLevel != 'MF':\n",
        "        X = np.hstack(inputTrainingData)\n",
        "    if fidelityLevel == 'MF':\n",
        "        X = inputTrainingData\n",
        "    y = np.hstack(outputTrainingData)\n",
        "    Y_names = np.hstack(outputTrainingNames)\n",
        "    X_names = np.hstack(inputTrainingNames)\n",
        "    originalIdx = np.arange(0,X.shape[0])\n",
        "\n",
        "    for i, split in enumerate(splitList):\n",
        "        start = time.time()\n",
        "        test_size = round(1-split,2)\n",
        "        currentIter = i+1\n",
        "        print(f'Training on {round(split*100,1)} percent of original train data. Data split # {currentIter} of {len(splitList)} begin. ')\n",
        "\n",
        "        ###### Split Data\n",
        "        X_train, X_test, y_train, y_test, M_inf_train, M_inf_test, trainIdx, testIdx = train_test_split(\n",
        "            X, y, M_inf, originalIdx, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        X_test, X_val, y_test, y_val, M_inf_test, M_inf_val, testIdx, valIdx = train_test_split(\n",
        "            X_test, y_test, M_inf_test, testIdx, test_size=0.50, random_state=random_state)\n",
        "\n",
        "        validData = (X_test, y_test)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"X_train shape: {}\".format(X_train.shape))\n",
        "            print(\"X_test shape: {}\".format(X_test.shape))\n",
        "            print(\"X_val shape: {}\".format(X_val.shape))\n",
        "            print(\"y_train shape: {}\".format(y_train.shape))\n",
        "            print(\"y_test shape: {}\".format(y_test.shape))\n",
        "            print(\"y_val shape: {}\".format(y_val.shape))\n",
        "            print(f\"concatenation order: {X_names}\")\n",
        "            print(f\"concatenation order: {Y_names}\")\n",
        "\n",
        "        ###### Build and Train Models ######\n",
        "\n",
        "        ## Initialize Lists ##\n",
        "        \n",
        "        kernelList = []\n",
        "        frequencyList = []\n",
        "        nrmse_list = []\n",
        "        trainTimeList = [] \n",
        "        modelSizeList = []\n",
        "        single_nrmse_list = []\n",
        "        R2_list = []\n",
        "        single_R2_list = []\n",
        "        single_medianPeakMissList = []\n",
        "        single_meanPeakMissList = []\n",
        "\n",
        "        for i, modelArchitecture in enumerate(top_n_modelChoices):\n",
        "            currentInternalIter = i+1\n",
        "            print(f'Model train iteration {currentIter}.{currentInternalIter} of {currentIter}.{len(top_n_modelChoices)} begin. (Total iters: {len(splitList)}) Model architecture: {str(modelArchitecture)}. ')\n",
        "\n",
        "            tempDict = {}\n",
        "            if modelType == 'NN':\n",
        "                NN_epochs, NN_history, trainTime, average_nrmse, single_nrmse, single_R2, average_R2, single_medianPeakMiss, single_meanPeakMiss, modelSize, frequencyTestAverage = buildAndTrainModel(\n",
        "                    X_train=X_train,\n",
        "                    y_train=y_train,\n",
        "                    fidelityLevel = fidelityLevel,\n",
        "                    modelType = modelType,\n",
        "                    layerSizeList=modelArchitecture,\n",
        "                    hyperparamDict=hyperparamDict,\n",
        "                    validData=validData,\n",
        "                    callbacks_list = callbacks_list,\n",
        "                    truncate = truncate,\n",
        "                    verbose=verbose,\n",
        "                    frequencyData = frequencyData\n",
        "                    )\n",
        "                tempDict.update( {\n",
        "                'epochs' : NN_epochs,\n",
        "                'history' : NN_history,\n",
        "                } )\n",
        "\n",
        "            elif modelType == 'krig':\n",
        "                optimizedKernel, trainTime, average_nrmse, single_nrmse, single_R2, average_R2, single_medianPeakMiss, single_meanPeakMiss, modelSize, frequencyTestAverage = buildAndTrainModel(\n",
        "                    X_train=X_train,\n",
        "                    y_train=y_train,\n",
        "                    fidelityLevel = fidelityLevel,\n",
        "                    modelType = modelType,\n",
        "                    kernel=modelArchitecture,\n",
        "                    n_restarts=n_restarts,\n",
        "                    validData=validData,\n",
        "                    truncate = truncate,\n",
        "                    verbose=verbose,\n",
        "                    frequencyData = frequencyData\n",
        "                    )\n",
        "                kernelList.append(optimizedKernel)\n",
        "                tempDict.update( {\n",
        "                'originalKernel' : kernel,\n",
        "                'optimizedKernel' : optimizedKernel,\n",
        "                } )\n",
        "\n",
        "            frequencyList.append(frequencyTestAverage)\n",
        "            nrmse_list.append(average_nrmse)\n",
        "            trainTimeList.append(trainTime)\n",
        "            modelSizeList.append(modelSize)\n",
        "            single_nrmse_list.append(single_nrmse)\n",
        "            R2_list.append(average_R2)\n",
        "            single_R2_list.append(single_R2)\n",
        "            single_medianPeakMissList.append(single_medianPeakMiss)\n",
        "            single_meanPeakMissList.append(single_meanPeakMiss)\n",
        "\n",
        "            tempDict.update( {\n",
        "                'average_nrmse' : average_nrmse,\n",
        "                'single_nrmse' : single_nrmse,\n",
        "                'trainTime' : trainTime,\n",
        "                'modelSize' : modelSize,\n",
        "                'frequency' : frequencyTestAverage,\n",
        "                'single_R2': single_R2,\n",
        "                'average_R2': average_R2,\n",
        "                'single_medianPeakMiss' : single_medianPeakMiss,\n",
        "                'single_meanPeakMiss' : single_meanPeakMiss\n",
        "                } )\n",
        "\n",
        "            globals()[dictName][split] = {\n",
        "                annotations[i] : tempDict\n",
        "            }\n",
        "\n",
        "            print(f'Model train iteration {currentIter}.{currentInternalIter} of {currentIter}.{len(top_n_modelChoices)} complete. (Total iters: {len(splitList)})') \n",
        "            \n",
        "            globals()[dictName][split].update( {\n",
        "                'modelSizeList' : modelSizeList,\n",
        "                'nrmse_list' : nrmse_list,\n",
        "                'single_nrmse_list' : single_nrmse_list,\n",
        "                'R2_list': R2_list,\n",
        "                'single_R2_list': single_R2_list,\n",
        "                'frequencyList' : frequencyList,\n",
        "                'trainTimeList' : trainTimeList,\n",
        "                'single_medianPeakMissList' : single_medianPeakMissList,\n",
        "                'single_meanPeakMissList' : single_meanPeakMissList\n",
        "            }\n",
        "            )\n",
        "\n",
        "        end = time.time()\n",
        "        currentLoopTimeElapsed = round((end-start)/60,4)\n",
        "        completionTime.append(currentLoopTimeElapsed)\n",
        "        totalTime = round(np.sum(completionTime),4)\n",
        "        # estimatedRemainingTime = round((numIters - currentIter)*np.mean(completionTime),4)\n",
        "\n",
        "        print(f'Iteration {currentIter} of {numIters} complete. Loop time elapsed: {currentLoopTimeElapsed} minutes')\n",
        "        polynomialOrder = polyFitDict[modelType]\n",
        "        if currentIter != 1:\n",
        "            iters = np.arange(0,currentIter)\n",
        "            z = np.polyfit(iters,completionTime,polynomialOrder)\n",
        "            polynomial = np.poly1d(z)\n",
        "            xRemaining = np.arange(currentIter+1,numIters)\n",
        "            yRemaining = polynomial(xRemaining)\n",
        "            estimatedRemainingTime = round(np.sum(yRemaining),4)\n",
        "        else: \n",
        "            estimatedRemainingTime = round((numIters - currentIter)*np.mean(completionTime),4)\n",
        "        hoursElapsed = math.floor(totalTime / 60)\n",
        "        minutesElapsed = math.floor(totalTime % 60)\n",
        "        hoursRemain = math.floor(estimatedRemainingTime / 60)\n",
        "        minutesRemain = math.floor(estimatedRemainingTime % 60)\n",
        "        print(f'Total time elapsed: {hoursElapsed} hours & {minutesElapsed} minute(s). Estimated time remaining: {hoursRemain} hours & {minutesRemain} minute(s). ')\n",
        "\n",
        "    #### Save dictionary \n",
        "    saveVersionedPickle(\n",
        "    filename=dictName, \n",
        "    objectToSave=globals()[dictName],\n",
        "    path = os.path.join(convStudyPath,currentConvStudyTopDir)\n",
        "    )\n",
        "\n",
        "    #### Plotting ####\n",
        "    os.chdir(path)\n",
        "    print(f'Dictionary name: {dictName}, saved at {str(os.path.join(convStudyPath,currentConvStudyTopDir))}')\n",
        "    print('Convergence study complete. ')\n",
        "    return globals()[dictName]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e8f1178",
      "metadata": {},
      "source": [
        "## Hypermodel Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "61fed42d",
      "metadata": {},
      "outputs": [],
      "source": [
        "## There is a better way to do the number of units in the layers, but it may only work when you exclusively use the def build_model(hp) method of HP tuning. \n",
        "## f\"units{i}\"\n",
        "class hyperMLP(kt.HyperModel):\n",
        "    def __init__(\n",
        "        self,regType,regValue, hiddenLayerActivation, \n",
        "        outputLayerActivation,kernelInitializer, \n",
        "        optimizer, loss, input_data,output_data\n",
        "        ):\n",
        "\n",
        "        self.regType = regType\n",
        "        self.regValue = regValue\n",
        "        self.hiddenLayerActivation = hiddenLayerActivation\n",
        "        self.outputLayerActivation = outputLayerActivation\n",
        "        self.kernelInitializer = kernelInitializer\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "        self.input_data = input_data\n",
        "        self.output_data = output_data \n",
        "\n",
        "    def build(self,hp):\n",
        "        inputlayershape = int(len(self.input_data[0,:]))\n",
        "        outputlayershape = int(len(self.output_data[0,:]))\n",
        "\n",
        "        hp_units1 = hp.Int('units1', min_value=32, max_value=80, step=8)\n",
        "        hp_units2 = hp.Int('units2', min_value=32, max_value=80, step=8)\n",
        "        hp_units3 = hp.Int('units3', min_value=32, max_value=80, step=8)\n",
        "        hp_layers = hp.Int('layers', min_value=1, max_value =3,step=1)\n",
        "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "        hp_units_list = [hp_units1, hp_units2, hp_units3]\n",
        "        \n",
        "        model = keras.Sequential()\n",
        "        model.add(tf.keras.layers.Dense(inputlayershape))\n",
        "        for layerNumber in np.arange(hp_layers):\n",
        "            model.add(tf.keras.layers.Dense(\n",
        "                hp_units_list[layerNumber],\n",
        "                activation = self.outputLayerActivation,\n",
        "                kernel_regularizer = self.regType(self.regValue),\n",
        "                kernel_initializer = self.kernelInitializer\n",
        "        ))\n",
        "        model.add(tf.keras.layers.Dense(outputlayershape, dtype='float32'))\n",
        "        model.compile(\n",
        "            optimizer = self.optimizer(learning_rate=hp_learning_rate),\n",
        "            loss = self.loss,\n",
        "            metrics = [tf.keras.metrics.MeanSquaredError()],\n",
        "            steps_per_execution=10\n",
        "                    )\n",
        "        return model\n",
        "\n",
        "class hyperMLPv2(kt.HyperModel):\n",
        "    def __init__(\n",
        "        self,regType,regValue, hiddenLayerActivation, \n",
        "        outputLayerActivation,kernelInitializer, \n",
        "        optimizer, loss, input_data,output_data\n",
        "        ):\n",
        "\n",
        "        self.regType = regType\n",
        "        self.regValue = regValue\n",
        "        self.hiddenLayerActivation = hiddenLayerActivation\n",
        "        self.outputLayerActivation = outputLayerActivation\n",
        "        self.kernelInitializer = kernelInitializer\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "        self.input_data = input_data\n",
        "        self.output_data = output_data \n",
        "\n",
        "    def build(self,hp):\n",
        "        inputlayershape = int(len(self.input_data[0,:]))\n",
        "        outputlayershape = int(len(self.output_data[0,:]))\n",
        "\n",
        "        hp_units1 = hp.Int('units1', min_value=32, max_value=80, step=8)\n",
        "        hp_units2 = hp.Int('units2', min_value=32, max_value=80, step=8)\n",
        "        hp_units3 = hp.Int('units3', min_value=32, max_value=80, step=8)\n",
        "        hp_layers = hp.Int('layers', min_value=1, max_value =3,step=1)\n",
        "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "        hp_units_list = [hp_units1, hp_units2, hp_units3]\n",
        "        \n",
        "        model = keras.Sequential()\n",
        "        model.add(tf.keras.layers.Dense(inputlayershape))\n",
        "\n",
        "        for layerNumber in np.arange(hp_layers):\n",
        "            model.add(tf.keras.layers.Dense(\n",
        "                units = hp.Int(f\"units{layerNumber}\", min_value=32,max_value=80, steps=8),\n",
        "                activation = self.outputLayerActivation,\n",
        "                kernel_regularizer = self.regType(self.regValue),\n",
        "                kernel_initializer = self.kernelInitializer\n",
        "        ))\n",
        "        model.add(tf.keras.layers.Dense(outputlayershape, dtype='float32'))\n",
        "        model.compile(\n",
        "            optimizer = self.optimizer(learning_rate=hp_learning_rate),\n",
        "            loss = self.loss,\n",
        "            metrics = [tf.keras.metrics.MeanSquaredError()],\n",
        "            steps_per_execution=10\n",
        "                    )\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4902532e",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6156ddad-50a4-4d8c-a8e9-72a9fd508a23",
      "metadata": {
        "id": "6156ddad-50a4-4d8c-a8e9-72a9fd508a23",
        "toc-hr-collapsed": true
      },
      "source": [
        "# Import and clean data from CFD runs \n",
        "If you have not run the post-processing scripts housed in the top folder, run those first. The below code assumes that all us3d output has been post-processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a40b35c3-d684-4558-a558-9d68ecd5b162",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a40b35c3-d684-4558-a558-9d68ecd5b162",
        "outputId": "de2b6014-59a7-43a8-a4ee-680756a3c7b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================== Importing Data ========================================\n",
            "Placed inputWallTemp into inputVar list\n",
            "inputWallTemp range from: 200.0 to 600.0\n",
            "\n",
            "Placed inputDensity into inputVar list\n",
            "inputDensity range from: 0.01803 to 0.5\n",
            "\n",
            "Placed inputTemperature into inputVar list\n",
            "inputTemperature range from: 56.667 to 226.65\n",
            "\n",
            "Placed inputVelocity into inputVar list\n",
            "inputVelocity range from: 931.13 to 1871.24\n",
            "\n",
            "inputVar list contains:  ['WallTemp', 'Density', 'Temperature', 'Velocity']\n",
            "qw has been imported!\n",
            "p has been imported!\n",
            "Total number of parameters in training data:  1022064\n",
            "Input Data Shape: (398, 1)\n",
            "Output Data Shape: (398, 1284)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*40, \"Importing Data\", \"=\"*40)\n",
        "\n",
        "casesToRemove = [196,389]\n",
        "\n",
        "# Provide the file name that holds your input data: \n",
        "fileName = '1st_Round_LS.cvs'\n",
        "\n",
        "# First thing is to read in the data file\n",
        "data = pd.read_csv(fileName)\n",
        "\n",
        "# Convert the pandas dataframe to numpy and transpose\n",
        "inputData = pd.DataFrame(data).to_numpy()\n",
        "inputData = inputData.T\n",
        "\n",
        "# Iteratively assign the input data names. The enumerate function has a second output, which I've stored \n",
        "# here with \"i\" that indexes your data for you, so you don't need to use an initialized counter (i=0)\n",
        "# and then count with an i += 1 at the end. This section of code uses the locals()[] to turn a string\n",
        "#into a variable so we can iteratively create variables.\n",
        "inputVarNames = [\n",
        "    'WallTemp',\n",
        "    'Density',\n",
        "    'Temperature',\n",
        "    'Velocity',\n",
        "]\n",
        "\n",
        "l_bounds = []\n",
        "u_bounds = []\n",
        "inputVar = []\n",
        "inputVarNameList = []\n",
        "\n",
        "for i, name in enumerate(inputVarNames):\n",
        "    name = 'input' + name\n",
        "    inputVarNameList.append(name)\n",
        "    locals()[name] = inputData[i,:].reshape(-1,1)\n",
        "    minInputVal = np.min(locals()[name])\n",
        "    maxInputVal = np.max(locals()[name])\n",
        "    l_bounds.append(minInputVal)\n",
        "    u_bounds.append(maxInputVal)\n",
        "    inputVar.append(locals()[name])\n",
        "    print('Placed ' + name + ' into inputVar list')\n",
        "    print( name + ' range from: ' + str(minInputVal) + ' to ' + str(maxInputVal) + '\\n') \n",
        "    if outlierRemoval:\n",
        "        locals()[name] = np.delete(locals()[name], casesToRemove, axis=0)\n",
        "\n",
        "print('inputVar list contains: ' , inputVarNames)\n",
        "# Import the *output* data, i.e. what the RANS code does with our input file. \n",
        "# Take these from the files \n",
        "\n",
        "# Add Mach to input variables, just for data cleaning/analysis\n",
        "gamma = 1.4 # perfect gas\n",
        "R_specific = 287.058\n",
        "a_inf = np.sqrt(gamma*R_specific*inputTemperature)\n",
        "inputMach = inputVelocity/a_inf\n",
        "inputVarNameList.append('inputMach')\n",
        "\n",
        "outputVarNames = [\n",
        "    'x',\n",
        "    'y',\n",
        "    'z',\n",
        "    'qw',\n",
        "    'taux',\n",
        "    'tauy',\n",
        "    'tauz',\n",
        "    'tauw',\n",
        "    'yplus',\n",
        "    'T',\n",
        "    'p',\n",
        "    'x_cc',\n",
        "    'y_cc',\n",
        "    'z_cc'\n",
        "]\n",
        "for name in outputVarNames:\n",
        "    locals()[name] = None\n",
        "    pickleName = './' + name + '.pkl'\n",
        "    F = open(pickleName, 'rb')\n",
        "    locals()[name] = pickle.load(F)\n",
        "    locals()[name] = locals()[name].T\n",
        "    if outlierRemoval:\n",
        "        locals()[name] = np.delete(locals()[name], casesToRemove, axis=0)\n",
        "    # Uncomment the below line if you'd like confirmation that your data made it \n",
        "    # print(locals()[name].shape)\n",
        "\n",
        "pickleName = './' + 'conn' + '.pkl'\n",
        "F = open(pickleName, 'rb')    \n",
        "connDict = pickle.load(F)\n",
        "\n",
        "# Pruning our list of output variables to what we'll need for training, testing, and validation\n",
        "outputVarNames = [\n",
        "    'qw',\n",
        "    'p',\n",
        "]\n",
        "\n",
        "for name in outputVarNames:\n",
        "    print(name + ' has been imported!')\n",
        "    \n",
        "# Do you desire to \"window\" the data and remove the pressure/heat transfer values from the nose region? If so, set Window to \"True\"\n",
        "# If you desire to window the data, also select the location in which you'd like to do that. \n",
        "Window = True \n",
        "\n",
        "if Window:\n",
        "    caseWePick = 389\n",
        "    xWindowStart = 0.3\n",
        "    xIndex = np.argsort(x_cc[0])\n",
        "    x_cc_sorted = x_cc[:,xIndex]\n",
        "    idxWindowStart = (np.abs(x_cc_sorted[0,:] - xWindowStart)).argmin()\n",
        "    \n",
        "    for name in outputVarNames:\n",
        "        sortedName = name + '_sorted'\n",
        "        windowedName = name + '_windowed'\n",
        "        locals()[sortedName] = locals()[name][:,xIndex]\n",
        "        locals()[windowedName] = locals()[sortedName][:,idxWindowStart:]\n",
        "    \n",
        "    x_cc_windowed = x_cc_sorted[:,idxWindowStart:]\n",
        "    \n",
        "#     plt.rcParams[\"figure.figsize\"] = (20,5)\n",
        "#     fig, axs = plt.subplots(1, 2)\n",
        "#     fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=.5)\n",
        "#     fig.patch.set_facecolor('white')\n",
        "\n",
        "\n",
        "#     axs[0].scatter(x_cc_sorted[caseWePick,idxWindowStart:], p_sorted[caseWePick,idxWindowStart:],s=30, label = 'Windowed Data')\n",
        "#     axs[0].scatter(x_cc_sorted[caseWePick,:], p_sorted[caseWePick,:],s=3, label = 'Full Data')\n",
        "#     axs[0].axvline(x=xWindowStart, linewidth=1, color='k', label = 'Chosen Start of Window')\n",
        "#     axs[1].scatter(x_cc_sorted[caseWePick,idxWindowStart:], qw_sorted[caseWePick,idxWindowStart:],s=30, label = 'Windowed Data')\n",
        "#     axs[1].scatter(x_cc_sorted[caseWePick,:], qw_sorted[caseWePick,:],s=3, label = 'Full Data')\n",
        "#     axs[1].axvline(x=xWindowStart, linewidth=1, color='k', label = 'Chosen Start of Window')\n",
        "\n",
        "#     axs[0].set_title(\"Pressure Window Results\")\n",
        "#     axs[0].set_ylabel(\"Pressure (Pa)\")\n",
        "#     axs[0].grid()\n",
        "#     axs[1].set_title(\"Heat Transfer Window Results\")\n",
        "#     axs[1].set_ylabel('Heat Transfer (w/m^2')\n",
        "#     axs[1].grid()\n",
        "\n",
        "#     axs[0].set_xlabel(\"x Distance Along Cone\")\n",
        "#     axs[1].set_xlabel(\"x Distance Along Cone\")\n",
        "    \n",
        "#     axs[0].legend()\n",
        "#     axs[1].legend()\n",
        "    \n",
        "# Do you desire to overwrite the original output data with the windowed and sorted output data? If so, set windowedOverwrite\n",
        "# to \"true.\" This will only run if Window is also true\n",
        "windowedOverwrite = True\n",
        "\n",
        "if Window and windowedOverwrite and (qw_windowed.any() != None):\n",
        "    for name in outputVarNames:\n",
        "        sortedName = name + '_sorted'\n",
        "        windowedName = name + '_windowed'\n",
        "        locals()[name] = None\n",
        "        locals()[name] = locals()[windowedName]\n",
        "        locals()[sortedName] = None\n",
        "        locals()[windowedName] = None\n",
        "\n",
        "totalParamsTrainData = 0\n",
        "for var in outputVarNames:\n",
        "    totalParamsTrainData += globals()[var].shape[0] * globals()[var].shape[1]\n",
        "numCases = globals()[inputVarNameList[0]].shape[0]\n",
        "print('Total number of parameters in training data: ', totalParamsTrainData)\n",
        "print('Input Data Shape: ' + str(globals()[inputVarNameList[0]].shape))\n",
        "print('Output Data Shape: ' + str(globals()[outputVarNames[0]].shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ddd9c51d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotPressureHeatTransferSideBySideTruthData(caseIndexArray=[389], qw_truth=qw, p_truth=p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ccaa4ad0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "# casestoPlot = 1\n",
        "# for case in np.arange(casestoPlot):\n",
        "#     caseWePick = random.randint(0,numCases)\n",
        "#     caseWePick = 389\n",
        "#     plt.semilogy(x_cc_windowed[0,:],qw[caseWePick,:],label = 'Qw')\n",
        "#     # plt.semilogy(x_cc_windowed[0,:],qw[caseWePick,:], label = 'Truth (RANS) Heat Transfer')\n",
        "#     plt.grid()\n",
        "#     plt.xlabel('Location Along Double Cone Wall, $x$ (meters)')\n",
        "#     plt.ylabel('Heat Transfer Rate ($\\\\frac{W}{m^2}$)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "589a9fd6-b19e-47ed-8679-a1c2f2bb5a59",
      "metadata": {
        "id": "589a9fd6-b19e-47ed-8679-a1c2f2bb5a59"
      },
      "source": [
        "### Input Data\n",
        "\n",
        "A quick explanation of our models' input data \n",
        "\n",
        "inputWallTemp = wall temperature of double cone\n",
        "\n",
        "inputDensity = free stream density\n",
        "\n",
        "inputTemperature = free stream temperature\n",
        "\n",
        "inputVelocity = free stream velocity\n",
        "\n",
        "These values are all chosen by the user, and the values are fed to US3D to generate CFD results for the entire flowfield. To keep the data and the model light, we're only going to analyze the \"wall\" values., which in this case will be pressure and heat transfer (maybe eventually the shear stresses, too). "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5b051b6-de85-46d1-a987-46d3d480204d",
      "metadata": {
        "id": "f5b051b6-de85-46d1-a987-46d3d480204d"
      },
      "source": [
        "### Output Data\n",
        "\n",
        "A quick explanation of our models' output data \n",
        "\n",
        "qw = heat transfer at the wall\n",
        "\n",
        "p = pressure at the wall\n",
        "\n",
        "We won't be training the model using the x,y,z,tau,yplus, T, or the cell center locations. These will be used after the model is trained for analysis purposes. Note that the \"T\", or wall temperature value, was fixed by the CFD code as the thermal boundary condition. If you take a look inside the output T array, you'll find that it's all the same number as the input wall temperature. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7209d0b-88f8-4075-8d31-7e8b1669b703",
      "metadata": {
        "id": "b7209d0b-88f8-4075-8d31-7e8b1669b703",
        "toc-hr-collapsed": true
      },
      "source": [
        "# Generate Low Fidelity Data\n",
        "Shock Expansion and Eckert's Reference Temp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeb7981c-4665-4388-b247-a0b8745373d0",
      "metadata": {
        "id": "eeb7981c-4665-4388-b247-a0b8745373d0"
      },
      "source": [
        "### Generate Low-Fidelity Space Sample Points "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5d9a0c56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# testy test test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ca7fff1a-0e0f-4665-96fa-5ce531490ddc",
      "metadata": {
        "id": "ca7fff1a-0e0f-4665-96fa-5ce531490ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory required for Kriging:  12.1188 Gigabytes\n"
          ]
        }
      ],
      "source": [
        "dimensionParameterSpace = 4 # wall temp, free stream temp, free stream density, free stream velocity\n",
        "numpPointsMultiplier = 2 # if this number is 5, then we'll sample LF cases 5x the number of HF cases \n",
        "# numpPointsMultiplier = 0.5\n",
        "numPointsToSample = int(globals()[outputVarNames[0]].shape[0]*numpPointsMultiplier)\n",
        "seed = 5 # seed with a number for reproducibility. It will be the same LHS sampling every time the function\n",
        "        # is run using seed = x. \n",
        "\n",
        "lowFidelityInputPoints = latinHypercubeSample(\n",
        "    dimensionParameterSpace,\n",
        "    numPointsToSample,\n",
        "    l_bounds,\n",
        "    u_bounds,\n",
        "    seed\n",
        ")\n",
        "\n",
        "requiredMemoryCalculator(numPointsToSample**2*(globals()[outputVarNames[0]].shape[1]*len(outputVarNames)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d0b9c607",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================== Generate Low Fidelity Data ========================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*40, \"Generate Low Fidelity Data\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64d950b3",
      "metadata": {},
      "source": [
        "## Shock Expansion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4ddc0d68-632c-4d74-8e6b-b977133d829a",
      "metadata": {
        "id": "4ddc0d68-632c-4d74-8e6b-b977133d829a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0  Big  T_w created , shape  (796, 1)\n",
            "599.544442276851 200.47191359532894\n",
            "1  Big  rho_inf created , shape  (796, 1)\n",
            "0.49941014005079754 0.01831460248187648\n",
            "2  Big  T_inf created , shape  (796, 1)\n",
            "226.55611821056678 56.71996356203486\n",
            "3  Big  u_inf created , shape  (796, 1)\n",
            "1870.5645982537449 932.2566935369646\n",
            "Num cases:  796\n"
          ]
        }
      ],
      "source": [
        "## Input Conditions, low fidelity data generation\n",
        "\n",
        "# These probably should be renamed to be consistent with the input variables already created. \n",
        "\n",
        "\n",
        "# inputVar list contains:  ['WallTemp', 'Density', 'Temperature', 'Velocity']\n",
        "\n",
        "gamma = 1.4 # perfect gas\n",
        "R_specific = 287.058\n",
        "cp1 = 1.005 #KJ/Kg*K, air at 251K\n",
        "\n",
        "# if bigInputSpace:\n",
        "#     for i, inputVarName in enumerate(inputVarNames): \n",
        "#         print(i)\n",
        "#         globals()[inputVarName] = lowFidelityInputPoints[:,i].reshape(-1,1)\n",
        "#     numCases = lowFidelityInputPoints.shape[0]\n",
        "# else: \n",
        "#     for i, inputVarName in enumerate(inputVarNames):\n",
        "#         globals()[inputVarName] = inputVar[i]\n",
        "#         print(i)\n",
        "\n",
        "# T_inf = inputTemperature\n",
        "# T_w = inputWallTemp\n",
        "# rho_inf = inputDensity\n",
        "# u_inf = inputVelocity\n",
        "\n",
        "LFinputVarNames = [\n",
        "    'T_w',\n",
        "    'rho_inf',\n",
        "    'T_inf',\n",
        "    'u_inf'\n",
        "]\n",
        "\n",
        "for i, inputVarName in enumerate(LFinputVarNames): \n",
        "    globals()[inputVarName] = lowFidelityInputPoints[:,i].reshape(-1,1)\n",
        "    print(i, ' Big ', inputVarName, 'created , shape ', str(globals()[inputVarName].shape))\n",
        "    print(globals()[inputVarName].max(), globals()[inputVarName].min())\n",
        "\n",
        "numCases = lowFidelityInputPoints.shape[0]\n",
        "print('Num cases: ', str(numCases))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d28aaff3",
      "metadata": {},
      "outputs": [],
      "source": [
        "a_inf = np.sqrt(gamma*R_specific*T_inf)\n",
        "M_inf = u_inf/a_inf\n",
        "P_inf = rho_inf*R_specific*T_inf\n",
        "mu_inf = mu_suth(T_inf)\n",
        "\n",
        "theta  = np.full((numCases,1),np.deg2rad(7))\n",
        "\n",
        "inputDataObliqueShock = M_inf,u_inf,T_inf,P_inf,rho_inf,a_inf,theta\n",
        "\n",
        "[*temp] = map(perfgas_oblique, M_inf,u_inf,T_inf,P_inf,rho_inf,a_inf,theta)\n",
        "obliqueShockResults = np.array(temp)\n",
        "\n",
        "\n",
        "outputLocalMethodVarName = [\n",
        "    'H2', \n",
        "    'V2', \n",
        "    'T2', \n",
        "    'P2', \n",
        "    'rho2',\n",
        "    'beta',\n",
        "    'M2',\n",
        "    'a2', \n",
        "    'T01', \n",
        "    'T02',\n",
        "    'P01',\n",
        "    'P02'\n",
        "]\n",
        "\n",
        "for i, name in enumerate(outputLocalMethodVarName):\n",
        "    locals()[name] = obliqueShockResults[:,i]\n",
        "## ---- Pressure Coefficient ----\n",
        "\n",
        "# Shock Expansion for 7deg Section\n",
        "\n",
        "shockAngle = beta\n",
        "\n",
        "cp_ShockExpansionTheory = (4/(gamma+1))*(np.sin(shockAngle)**2 - (1/(M_inf**2)))\n",
        "cp_newtonian_coneAngle = 2*(np.sin(theta)**2)\n",
        "\n",
        "xPressureWindowStart = 0.5\n",
        "xPressureWindowEnd = 2.0\n",
        "xPressureWindowMid = 0.5\n",
        "\n",
        "xSpotBegin = (np.abs(x_cc_windowed[0,:] - xPressureWindowStart)).argmin()\n",
        "xSpotEnd = (np.abs(x_cc_windowed[0,:] - xPressureWindowEnd)).argmin()\n",
        "xSpotNoMean = (np.abs(x_cc_windowed[0,:] - xPressureWindowMid)).argmin()\n",
        "\n",
        "# PressureForCPActual = p[:,xSpotNoMean].reshape(-1,1)\n",
        "# cp_actual = (PressureForCPActual - P_inf)/ (0.5*rho_inf*(u_inf**2))\n",
        "# cp_actual[389] = None # takes care of that one bad point\n",
        "\n",
        "#Shock Expansion For 40deg Section\n",
        "\n",
        "T_inf2 = T2\n",
        "# T_w = T_w\n",
        "rho_inf2 = rho2\n",
        "u_inf2 = M2*a2\n",
        "a_inf2 = a2\n",
        "M_inf2 = M2\n",
        "P_inf2 = P2\n",
        "mu_inf2 = mu_suth(T2)\n",
        "theta2  = np.full((numCases,1),np.deg2rad(33))\n",
        "\n",
        "[*temp] = map(perfgas_oblique, M_inf2,u_inf2,T_inf2,P_inf2,rho_inf2,a_inf2,theta2)\n",
        "obliqueShockResults = np.array(temp)\n",
        "\n",
        "outputLocalMethodVarName = [\n",
        "    'H3', \n",
        "    'V3', \n",
        "    'T3', \n",
        "    'P3', \n",
        "    'rho3',\n",
        "    'beta2',\n",
        "    'M3',\n",
        "    'a3', \n",
        "    'T02', \n",
        "    'T03',\n",
        "    'P02',\n",
        "    'P03'\n",
        "]\n",
        "\n",
        "for i, name in enumerate(outputLocalMethodVarName):\n",
        "    locals()[name] = obliqueShockResults[:,i]\n",
        "xPressureWindowLeft = 2.353056 # elbow location\n",
        "xPressureWindowRight = 2.5039961 # end of cone\n",
        "\n",
        "xPressureWindowMid = 2.4\n",
        "xSpotLeft = (np.abs(x_cc_windowed[0,:] - xPressureWindowLeft)).argmin()\n",
        "xSpotRight = (np.abs(x_cc_windowed[0,:] - xPressureWindowRight)).argmin()\n",
        "\n",
        "# meanPressure40DegConeSection = np.median(p[:,xSpotLeft:xSpotRight], axis = 1).reshape(-1,1)\n",
        "# cp_actual2 = (meanPressure40DegConeSection - P_inf2)/ (0.5*rho_inf2*(u_inf2**2))\n",
        "# cp_actual2[389] = None # takes care of that one bad case\n",
        "\n",
        "cp_newtonian_coneAngle2 = 2*(np.sin(theta2)**2)\n",
        "shockAngle2 = beta2\n",
        "cp_ShockExpansionTheory2 = (4/(gamma+1))*(np.sin(shockAngle2)**2 - (1/(M_inf2**2)))\n",
        "\n",
        "p_SE_7deg = cp_ShockExpansionTheory*(0.5*rho_inf*(u_inf**2)) + P_inf\n",
        "p_Newtonian_40deg = cp_newtonian_coneAngle2*(0.5*rho_inf2*(u_inf2**2)) + P_inf2\n",
        "p_SE_40deg = cp_ShockExpansionTheory2*(0.5*rho_inf2*(u_inf2**2)) + P_inf2\n",
        "\n",
        "xSpotElbow = (np.abs(x_cc_windowed[0,:] - xPressureWindowLeft)).argmin()\n",
        "\n",
        "p_lf_7deg = np.tile(p_SE_7deg, xSpotElbow+1)\n",
        "p_lf_40deg_newt = np.tile(p_Newtonian_40deg, xSpotRight - xSpotLeft)\n",
        "p_lf_40deg = np.tile(p_SE_40deg, xSpotRight - xSpotLeft)\n",
        "p_lowFidelity_SE = np.concatenate((p_lf_7deg, p_lf_40deg), axis=1)\n",
        "p_lowFidelity_Newt = np.concatenate((p_lf_7deg, p_lf_40deg_newt), axis=1)\n",
        "\n",
        "p_lowFidelity_SE_truncated = np.concatenate((p_SE_7deg, p_SE_40deg), axis=1)\n",
        "p_lowFidelity_SE_truncated = p_lowFidelity_SE_truncated.T\n",
        "\n",
        "# normalizedHFPressure = p/P03\n",
        "# normalizedLFPressure = p_lowFidelity_SE/P03\n",
        "# normalizedLFPressureNewt = p_lowFidelity_Newt/P03\n",
        "\n",
        "p_LF = p_lowFidelity_SE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645ad4a3-8a5c-4261-84e9-35bfa7bd5303",
      "metadata": {
        "id": "645ad4a3-8a5c-4261-84e9-35bfa7bd5303"
      },
      "source": [
        "### Plotting Pressure Coefficient Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4d14f705-aaad-4965-a0a1-c8c93f4ca8cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "4d14f705-aaad-4965-a0a1-c8c93f4ca8cf",
        "outputId": "044c9f09-b9e1-4f5f-b3c6-5ba14f1654e6"
      },
      "outputs": [],
      "source": [
        "# if not superComputerTrain:\n",
        "\n",
        "#   caseWePick = random.randint(0,400)\n",
        "\n",
        "#   plt.plot(x_cc_windowed[0,:],normalizedLFPressure[caseWePick,:], label = 'Low Fidelity (SE)', color = 'k')\n",
        "#   plt.plot(x_cc_windowed[0,:],normalizedLFPressureNewt[caseWePick,:], label = 'Low Fidelity (Newtonian)', color = 'b', linestyle='-.')\n",
        "#   plt.scatter(x_cc_sorted[caseWePick,idxWindowStart:], normalizedHFPressure[caseWePick,:],s=5, label = 'Truth Data (RANS)', color='r')\n",
        "#   plt.legend()\n",
        "#   # plt.title('Case Number ' + str(caseWePick))\n",
        "#   plt.xlabel('x (meters)')\n",
        "#   plt.ylabel('$P/P_{03}$')\n",
        "#   plt.grid()\n",
        "\n",
        "  # plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "  # plt.grid()\n",
        "  # plt.scatter(M_inf,cp_actual, label = 'RANS Truth CP', s=3)\n",
        "  # plt.scatter(M_inf,cp_ShockExpansionTheory, label = 'S-E Theory CP', s=3)\n",
        "  # plt.scatter(M_inf,cp_newtonian_coneAngle, label = 'Newtonian Theory CP', s=3)\n",
        "  # lgnd = plt.legend(loc=\"upper right\", scatterpoints=1, fontsize=20)\n",
        "  # plt.xlabel(\"Mach Number\",fontsize='xx-large')\n",
        "  # plt.ylabel(\"Pressure Coefficient\",fontsize='xx-large')\n",
        "  # plt.ylim([0,0.12])\n",
        "  # lgnd = plt.legend(loc='upper right', fontsize='x-large', markerscale = 5)\n",
        "  # # for i in range(0,7):\n",
        "  # #     lgnd.legendHandles[i]._sizes = [50]\n",
        "\n",
        "  # # TURN THIS INTO A SUBLPLOT, side by side\n",
        "\n",
        "  # plt.rcParams[\"figure.figsize\"] = (7,5)\n",
        "  # plt.rcParams['figure.dpi'] = 300\n",
        "  # plt.grid()\n",
        "  # plt.scatter(M_inf,cp_actual2, label = 'RANS Truth CP', s=3)\n",
        "  # plt.scatter(M_inf,cp_ShockExpansionTheory2, label = 'S-E Theory CP', s=3)\n",
        "  # plt.scatter(M_inf,cp_newtonian_coneAngle2, label = 'Newtonian Theory CP', s=3)\n",
        "  # plt.scatter(M_inf,cp_actual, label = 'RANS Truth CP', s=3)\n",
        "  # plt.scatter(M_inf,cp_ShockExpansionTheory, label = 'S-E Theory CP', s=3)\n",
        "  # plt.scatter(M_inf,cp_newtonian_coneAngle, label = 'Newtonian Theory CP', s=3)\n",
        "  # lgnd = plt.legend(loc=\"upper right\", scatterpoints=1, fontsize=20)\n",
        "  # plt.rcParams['legend.facecolor'] = 'white'\n",
        "  # plt.xlabel(\"Mach Number\",fontsize='xx-large')\n",
        "  # plt.ylabel(\"Pressure Coefficient\",fontsize='xx-large')\n",
        "  # lgnd = plt.legend(loc='upper right', fontsize='x-large', markerscale = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42a98c55-f2bc-4bb9-b20c-0861b8d2056f",
      "metadata": {
        "id": "42a98c55-f2bc-4bb9-b20c-0861b8d2056f"
      },
      "source": [
        "## Eckert's Reference Temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dae5ced7-25af-4653-9d6a-f76d530877ab",
      "metadata": {
        "id": "dae5ced7-25af-4653-9d6a-f76d530877ab"
      },
      "outputs": [],
      "source": [
        "## ---- Eckert's Reference Temperature, Cone Example ----\n",
        "\n",
        "\n",
        "Pr = 0.72\n",
        "recovFactor = np.sqrt(Pr)\n",
        "xSpotEndArtificial = x_cc_windowed[0,:].shape[0] - xSpotElbow\n",
        "\n",
        "x_FrontCone = x_cc_windowed[0,:xSpotElbow]\n",
        "x_RearCone = x_cc_windowed[0,:xSpotEndArtificial] - 0.25\n",
        "\n",
        "T_star = 0.5*(T2 + T_w) + .22*recovFactor*(T02 - T2)\n",
        "rho_star = P2/ (R_specific*T_star)\n",
        "mu_star = mu_suth(T2)\n",
        "u2 = M2 * a2\n",
        "Re_coeff = rho_star*u2/mu_star\n",
        "Re_x = Re_coeff * x_FrontCone\n",
        "cone_factor = np.sqrt(3)\n",
        "cH_coeff = (cone_factor*0.332)/((Pr**(2/3))*(Re_coeff**(.5)))\n",
        "cH_star = cH_coeff / x_FrontCone**(1/2)\n",
        "T_r = T2 + recovFactor*(T02 - T2)\n",
        "q_dot_FrontCone = rho_star*u2*cp1*1000*(T_r - T_w)*cH_star\n",
        "\n",
        "T_star2 = 0.5*(T3 + T_w) + .22*recovFactor*(T03 - T3)\n",
        "rho_star2 = P3/ (R_specific*T_star2)\n",
        "mu_star2 = mu_suth(T3)\n",
        "u3 = M3* a3\n",
        "Re_coeff2 = rho_star2*u2/mu_star2\n",
        "Re_x2 = Re_coeff2 * x_RearCone\n",
        "cH_coeff2 = (cone_factor*0.332)/((Pr**(2/3))*(Re_coeff2**(.5)))\n",
        "cH_star2 = cH_coeff2 / x_RearCone**(1/2)\n",
        "T_r2 = T3 + recovFactor*(T03 - T3)\n",
        "q_dot_RearCone = rho_star2*u3*cp1*1000*(T_r2 - T_w)*cH_star2\n",
        "\n",
        "qw_LF = np.concatenate((q_dot_FrontCone, q_dot_RearCone), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03aa0a98-615e-4a8e-b4bc-b8fa45992372",
      "metadata": {
        "id": "03aa0a98-615e-4a8e-b4bc-b8fa45992372",
        "toc-hr-collapsed": true
      },
      "source": [
        "# Low Fidelity Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ac4a4858",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================== Low Fidelity Data Processing ========================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*40, \"Low Fidelity Data Processing\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "33807a0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "LFoutputVarNames = [\n",
        "    'qw_LF',\n",
        "    'p_LF',\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6f68083d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of parameters in training data:  2044128\n"
          ]
        }
      ],
      "source": [
        "totalParamsTrainData = 0\n",
        "for var in LFoutputVarNames:\n",
        "    totalParamsTrainData += globals()[var].shape[0] * globals()[var].shape[1]\n",
        "print('Total number of parameters in training data: ', totalParamsTrainData)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c977a0e",
      "metadata": {},
      "source": [
        "### Outlier Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2ce1dae5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed  1  cases.\n",
            "qw_LF new shape  (795, 1284)\n",
            "Removed  1  cases.\n",
            "p_LF new shape  (795, 1284)\n",
            "Removed  1  cases.\n",
            "T_w new shape  (795, 1)\n",
            "Removed  1  cases.\n",
            "rho_inf new shape  (795, 1)\n",
            "Removed  1  cases.\n",
            "T_inf new shape  (795, 1)\n",
            "Removed  1  cases.\n",
            "u_inf new shape  (795, 1)\n",
            "M_inf new shape  (795, 1)\n"
          ]
        }
      ],
      "source": [
        "if outlierRemoval and (globals()[LFoutputVarNames[0]].shape[0] == numCases):\n",
        "    casesToRemove = np.argwhere(np.isnan(qw_LF).any(axis=1))\n",
        "    if numpPointsMultiplier == 2:\n",
        "        casesToRemove = [648]\n",
        "    \n",
        "    for i, outputVarName in enumerate(LFoutputVarNames): \n",
        "        globals()[outputVarName] = np.delete(locals()[outputVarName], casesToRemove, axis=0)\n",
        "        print('Removed ', len(casesToRemove), ' cases.')\n",
        "        print(outputVarName, 'new shape ', str(globals()[outputVarName].shape))\n",
        "\n",
        "    for i, inputVarName in enumerate(LFinputVarNames): \n",
        "        globals()[inputVarName] = np.delete(locals()[inputVarName], casesToRemove, axis=0)\n",
        "        print('Removed ', len(casesToRemove), ' cases.')\n",
        "        print(inputVarName, 'new shape ', str(globals()[inputVarName].shape))\n",
        "\n",
        "    M_inf = np.delete(M_inf, casesToRemove, axis=0)\n",
        "    print('M_inf new shape ', str(M_inf.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f614e1c-9eff-4dec-a303-1bd6470f680e",
      "metadata": {
        "id": "6f614e1c-9eff-4dec-a303-1bd6470f680e"
      },
      "source": [
        "### Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b0663ad1-63c6-40ec-8f3c-9402f6fedb2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0663ad1-63c6-40ec-8f3c-9402f6fedb2a",
        "outputId": "a2a4b8e8-9960-4fe1-f7f7-cccc4d66c11a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Data (stored in list inputTrainingData):\n",
            "\n",
            "T_w has been scaled! It is called T_w_Scaled. Min:-1.73. Max:1.73\n",
            "rho_inf has been scaled! It is called rho_inf_Scaled. Min:-1.73. Max:1.73\n",
            "T_inf has been scaled! It is called T_inf_Scaled. Min:-1.73. Max:1.73\n",
            "u_inf has been scaled! It is called u_inf_Scaled. Min:-1.73. Max:1.73\n",
            "\n",
            "Output Data (stored in list LFoutputTrainingData):\n",
            "\n",
            "qw_LF has been scaled! It is called qw_LF_Scaled. Min:-1.37. Max:4.35\n",
            "p_LF has been scaled! It is called p_LF_Scaled. Min:-1.57. Max:3.91\n",
            "(4, 795, 1)\n",
            "(2, 795, 1284)\n",
            "['T_w_Scaled', 'rho_inf_Scaled', 'T_inf_Scaled', 'u_inf_Scaled']\n",
            "['qw_LF', 'p_LF']\n",
            "['qw_LF_Scaled', 'p_LF_Scaled']\n",
            "qw_LF_Scaled  truncated. Added to LFoutputTrainingData\n",
            "p_LF_Scaled  truncated. Added to LFoutputTrainingData\n",
            "(4, 795, 1)\n",
            "(2, 795, 2)\n",
            "['T_w_Scaled', 'rho_inf_Scaled', 'T_inf_Scaled', 'u_inf_Scaled']\n",
            "['qw_LF', 'p_LF']\n",
            "['qw_LF_Scaled', 'p_LF_Scaled']\n"
          ]
        }
      ],
      "source": [
        "LFinputTrainingData = []\n",
        "LFinputTrainingNames = []\n",
        "\n",
        "print('Input Data (stored in list inputTrainingData):\\n')\n",
        "for i, name in enumerate(LFinputVarNames):\n",
        "    ScalerName = name + '_InputScaler'\n",
        "    ScaledName = name + '_Scaled'\n",
        "    locals()[ScalerName] = None\n",
        "    locals()[ScalerName] = preprocessing.StandardScaler()\n",
        "    locals()[ScaledName] = locals()[ScalerName].fit_transform(globals()[name])\n",
        "    LFinputTrainingData.append(locals()[ScaledName])\n",
        "    LFinputTrainingNames.append(ScaledName)\n",
        "    max_element = str(round(np.max(locals()[ScaledName]),2))\n",
        "    min_element = str(round(np.min(locals()[ScaledName]),2))\n",
        "    print(name + ' has been scaled! It is called ' + ScaledName + '. Min:' + min_element + '. Max:' + max_element)\n",
        "\n",
        "LFoutputTrainingData = []\n",
        "LFoutputTrainingNames = []\n",
        "\n",
        "print('\\nOutput Data (stored in list LFoutputTrainingData):\\n')\n",
        "for i, name in enumerate(LFoutputVarNames):\n",
        "    ScalerName = name + '_OutputScaler'\n",
        "    ScaledName = name + '_Scaled'\n",
        "    OutputDataName = name\n",
        "    locals()[ScalerName] = None\n",
        "    locals()[ScalerName] = preprocessing.StandardScaler()\n",
        "    locals()[ScaledName] = locals()[ScalerName].fit_transform(globals()[OutputDataName])\n",
        "    LFoutputTrainingData.append(locals()[ScaledName])\n",
        "    LFoutputTrainingNames.append(ScaledName)\n",
        "    max_element = str(round(np.max(locals()[ScaledName]),2))\n",
        "    min_element = str(round(np.min(locals()[ScaledName]),2))\n",
        "    print(name + ' has been scaled! It is called ' + ScaledName + '. Min:' + min_element + '. Max:' + max_element)\n",
        "\n",
        "print(str(np.shape(LFinputTrainingData)))\n",
        "print(str(np.shape(LFoutputTrainingData)))\n",
        "print(LFinputTrainingNames)\n",
        "print(LFoutputVarNames)\n",
        "print(LFoutputTrainingNames)\n",
        "\n",
        "if downsampleLF: \n",
        "    ##################################################\n",
        "    ####### Heat Flux and Pressure Downsample ########\n",
        "    ################################################## \n",
        "    conePoint = 2.0\n",
        "    flarePoint = 2.49\n",
        "    xLocationPressureValue1 = (np.abs(x_cc_windowed[0,:] - conePoint)).argmin()\n",
        "    xLocationPressureValue2 = (np.abs(x_cc_windowed[0,:] - flarePoint)).argmin()\n",
        "\n",
        "    indices = [xLocationPressureValue1, xLocationPressureValue2]\n",
        "    LFoutputTrainingData = []\n",
        "    for name in LFoutputTrainingNames:\n",
        "        globals()[name] = np.take(globals()[name], indices, axis=1)\n",
        "        LFoutputTrainingData.append(globals()[name])\n",
        "        print(name, ' truncated. Added to LFoutputTrainingData')\n",
        "    x_downsampledPressure = np.take(x_cc_windowed, indices, axis=1)\n",
        "\n",
        "print(str(np.shape(LFinputTrainingData)))\n",
        "print(str(np.shape(LFoutputTrainingData)))\n",
        "print(LFinputTrainingNames)\n",
        "print(LFoutputVarNames)\n",
        "print(LFoutputTrainingNames)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "545c283c",
      "metadata": {},
      "source": [
        "## Model Convergence Study"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbcf3860",
      "metadata": {},
      "source": [
        "### LF Kriging Convergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "23416b6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T_w created , shape  (796, 1)\n",
            "Lower bound:  200.47191359532894 . Upper bound:  599.544442276851\n",
            "rho_inf created , shape  (796, 1)\n",
            "Lower bound:  0.01831460248187648 . Upper bound:  0.49941014005079754\n",
            "T_inf created , shape  (796, 1)\n",
            "Lower bound:  56.71996356203486 . Upper bound:  226.55611821056678\n",
            "u_inf created , shape  (796, 1)\n",
            "Lower bound:  932.2566935369646 . Upper bound:  1870.5645982537449\n",
            "Num low-fidelity cases:  796\n",
            "p_LF shape:  (796, 1284)\n",
            "qw_LF shape:  (796, 1284)\n",
            "qw_LF globals: (796, 1284) locals:  (796, 1284)\n",
            "p_LF globals: (796, 1284) locals:  (796, 1284)\n",
            "Total number of parameters in training data:  2044128\n",
            "outlierRemoval criteria: True  and  True\n",
            "796 ==  796\n",
            "Entered outlier removal loop\n",
            "qw_LF new shape  (795, 1284)\n",
            "p_LF new shape  (795, 1284)\n",
            "T_w new shape  (795, 1)\n",
            "rho_inf new shape  (795, 1)\n",
            "T_inf new shape  (795, 1)\n",
            "u_inf new shape  (795, 1)\n",
            "M_inf new shape  (795, 1)\n",
            "Removed  1  case(s).\n",
            "Input Data (stored in list inputTrainingData):\n",
            "\n",
            "T_w has been scaled! It is called T_w_Scaled. Min:-1.73. Max:1.73\n",
            "rho_inf has been scaled! It is called rho_inf_Scaled. Min:-1.73. Max:1.73\n",
            "T_inf has been scaled! It is called T_inf_Scaled. Min:-1.73. Max:1.73\n",
            "u_inf has been scaled! It is called u_inf_Scaled. Min:-1.73. Max:1.73\n",
            "\n",
            "Output Data (stored in list LFoutputTrainingData):\n",
            "\n",
            "qw_LF has been scaled! It is called qw_LF_Scaled. Min:-1.37. Max:4.35\n",
            "p_LF has been scaled! It is called p_LF_Scaled. Min:-1.57. Max:3.91\n",
            "qw_LF_Scaled  truncated. Added to LFoutputTrainingData\n",
            "p_LF_Scaled  truncated. Added to LFoutputTrainingData\n",
            "Number of input variables:  4\n",
            "Shape of LFinputTrainingData:  (4, 795, 1)\n",
            "Number of output variables:  2\n",
            "Number of variables in output distribution:  2\n",
            "Shape of LFoutputTrainingData:  (2, 795, 2)\n",
            "LFinputTrainingNames:  ['T_w_Scaled', 'rho_inf_Scaled', 'T_inf_Scaled', 'u_inf_Scaled']\n",
            "LFoutputVarNames:  ['qw_LF', 'p_LF']\n",
            "LFoutputTrainingNames:  ['qw_LF_Scaled', 'p_LF_Scaled']\n",
            "X.shape:  (795, 4)\n",
            "y_lf.shape:  (795, 4)\n",
            "M_inf.shape:  (795, 1)\n",
            "originalIdx.shape:  (795,)\n",
            "Low fidelity X_train shape: (636, 4)\n",
            "Low fidelity X_test shape: (79, 4)\n",
            "Low fidelity X_val shape: (80, 4)\n",
            "Low fidelity y_lf_train shape: (636, 4)\n",
            "Low fidelity y_lf_test shape: (79, 4)\n",
            "Low fidelity y_lf_val shape: (80, 4)\n",
            "concatenation order: ['T_w_Scaled' 'rho_inf_Scaled' 'T_inf_Scaled' 'u_inf_Scaled']\n",
            "concatenation order: ['qw_LF_Scaled' 'p_LF_Scaled']\n",
            "Low fidelity data generated, scaled, and split. Low fidelity output data truncation:  True\n"
          ]
        }
      ],
      "source": [
        "lowFidelityDataGenAndProcess(downsampleLF=True,verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6d78f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "LFoptimizedKernel1 = 0.0873**2 + Matern(length_scale=7.53, nu=1.5) + WhiteKernel(noise_level=0.00121)\n",
        "LFoptimizedKernel2 = 5.31**2 * RBF(length_scale=5.08) + WhiteKernel(noise_level=0.00179)\n",
        "LFoptimizedKernel3 = 4.33**2 * RationalQuadratic(alpha=0.00285, length_scale=12.1)\n",
        "\n",
        "top_n_modelChoices = [ \n",
        "        LFoptimizedKernel1,\n",
        "        LFoptimizedKernel2,\n",
        "        LFoptimizedKernel3\n",
        "        ] \n",
        "\n",
        "start = 0.20 ; stop = 0.80 ; step = 0.03\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "LF_krig_modelConvergenceDict = modelConvergenceStudy(\n",
        "    fidelityLevel= 'LF', \n",
        "    modelType= 'krig',\n",
        "    M_inf=M_inf,\n",
        "    inputTrainingData=LFinputTrainingData,\n",
        "    outputTrainingData=LFoutputTrainingData,\n",
        "    inputTrainingNames=LFinputTrainingNames,\n",
        "    outputTrainingNames=LFoutputTrainingNames,\n",
        "    top_n_modelChoices=top_n_modelChoices,\n",
        "    splitList=splitList,\n",
        "    verbose=False,\n",
        "    truncate=True,\n",
        "    hyperparamDict=None,\n",
        "    callbacks_list=None,\n",
        "    n_restarts=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a17f99",
      "metadata": {},
      "outputs": [],
      "source": [
        "plotModelConvergenceStudy(\n",
        "    top_n_modelChoices,\n",
        "    splitList,\n",
        "    convDict= LF_krig_modelConvergenceDict,\n",
        "    fidelityLevel='LF',\n",
        "    modelChoice='krig',\n",
        "    peakMiss = 'median')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbcf3860",
      "metadata": {},
      "source": [
        "### LF Neural Network Convergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6d78f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n_modelChoices = [ \n",
        "        [56, 80],\n",
        "        [40,32],\n",
        "        [32, 64],\n",
        "        [48, 56, 40],\n",
        "        [80,32,80]\n",
        "        ] \n",
        "\n",
        "start = 0.20 ; stop = 0.80 ; step = 0.03\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "hyperparamDict = {\n",
        "    \"learningRate\" : 1.0e-3,\n",
        "    \"regType\" : keras.regularizers.L2,\n",
        "    \"regValue\" : 1.0e-6,\n",
        "    \"hiddenLayerActivation\" : tf.nn.tanh,\n",
        "    \"outputLayerActivation\" : tf.nn.leaky_relu,\n",
        "    \"kernelInitializer\" : tf.keras.initializers.GlorotUniform(),\n",
        "    \"optimizer\" : tf.keras.optimizers.Adamax,\n",
        "    \"numEpochs\" : 7000,\n",
        "    \"myBatchSize\" : 224,\n",
        "    \"loss\" : 'mse'\n",
        "}\n",
        "\n",
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor = \"val_mean_squared_error\",mode=\"min\",\n",
        "        patience=200, verbose=0,\n",
        "        restore_best_weights=False \n",
        "        )\n",
        "    ]\n",
        "\n",
        "LF_NN_modelConvergenceDict = modelConvergenceStudy(\n",
        "    fidelityLevel= 'LF', \n",
        "    modelType= 'NN',\n",
        "    M_inf=M_inf,\n",
        "    inputTrainingData=LFinputTrainingData,\n",
        "    outputTrainingData=LFoutputTrainingData,\n",
        "    inputTrainingNames=LFinputTrainingNames,\n",
        "    outputTrainingNames=LFoutputTrainingNames,\n",
        "    top_n_modelChoices=top_n_modelChoices,\n",
        "    splitList=splitList,\n",
        "    frequencyData = False,\n",
        "    verbose=False,\n",
        "    truncate=True,\n",
        "    hyperparamDict=hyperparamDict,\n",
        "    callbacks_list=callbacks_list,\n",
        "    n_restarts=None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "693d4bff",
      "metadata": {},
      "outputs": [],
      "source": [
        "plotModelConvergenceStudy(\n",
        "    top_n_modelChoices,\n",
        "    splitList,\n",
        "    convDict= LF_NN_modelConvergenceDict,\n",
        "    fidelityLevel='LF',\n",
        "    modelChoice='NN',\n",
        "    peakMiss = 'median')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80080302-eb61-4838-be1f-9eb26a61d9d0",
      "metadata": {
        "id": "80080302-eb61-4838-be1f-9eb26a61d9d0"
      },
      "source": [
        "### Validation Split "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5b83fc1d-22f2-48a7-8d61-5f834b6f5691",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b83fc1d-22f2-48a7-8d61-5f834b6f5691",
        "outputId": "3846843c-6b84-41fb-d68e-6de144fb63dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Low fidelity X_train shape: (612, 4)\n",
            "Low fidelity X_test shape: (91, 4)\n",
            "Low fidelity X_val shape: (92, 4)\n",
            "Low fidelity y_lf_train shape: (612, 4)\n",
            "Low fidelity y_lf_test shape: (91, 4)\n",
            "Low fidelity y_lf_val shape: (92, 4)\n",
            "concatenation order: ['T_w_Scaled' 'rho_inf_Scaled' 'T_inf_Scaled' 'u_inf_Scaled']\n",
            "concatenation order: ['qw_LF_Scaled' 'p_LF_Scaled']\n"
          ]
        }
      ],
      "source": [
        "##### SKLEARN DATA SPLIT \n",
        "\n",
        "dataSplit = 0.77\n",
        "test_size = round(1-dataSplit,4)\n",
        "\n",
        "X = np.hstack(LFinputTrainingData)\n",
        "y_lf = np.hstack(LFoutputTrainingData)\n",
        "Y_lf_names = np.hstack(LFoutputTrainingNames)\n",
        "X_names = np.hstack(LFinputTrainingNames)\n",
        "originalIdx = np.arange(0,X.shape[0])\n",
        "\n",
        "X_train, X_test, y_lf_train, y_lf_test, M_inf_train, M_inf_test, trainIdx, testIdx = train_test_split(\n",
        "    X, y_lf, M_inf, originalIdx, test_size=test_size, random_state=random_state)\n",
        "\n",
        "X_test, X_val, y_lf_test, y_lf_val, M_inf_test, M_inf_val, testIdx, valIdx = train_test_split(\n",
        "    X_test, y_lf_test, M_inf_test, testIdx, test_size=0.50, random_state=random_state)\n",
        "\n",
        "print(\"Low fidelity X_train shape: {}\".format(X_train.shape))\n",
        "print(\"Low fidelity X_test shape: {}\".format(X_test.shape))\n",
        "print(\"Low fidelity X_val shape: {}\".format(X_val.shape))\n",
        "print(\"Low fidelity y_lf_train shape: {}\".format(y_lf_train.shape))\n",
        "print(\"Low fidelity y_lf_test shape: {}\".format(y_lf_test.shape))\n",
        "print(\"Low fidelity y_lf_val shape: {}\".format(y_lf_val.shape))\n",
        "print(f\"concatenation order: {X_names}\")\n",
        "print(f\"concatenation order: {Y_lf_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f117bdd",
      "metadata": {},
      "source": [
        "# LF Data Gen and Process Func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f34e5f7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "lowFidelityDataGenAndProcess(verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0386b527-836f-49c1-8304-3e33ee21eb1a",
      "metadata": {
        "id": "0386b527-836f-49c1-8304-3e33ee21eb1a"
      },
      "source": [
        "# LF Kriging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "514d1ed3",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"Low Fidelity Kriging\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a32a282-7683-42e4-a613-be6706312c6b",
      "metadata": {
        "id": "8a32a282-7683-42e4-a613-be6706312c6b"
      },
      "outputs": [],
      "source": [
        "# # Kernel options include: Compound, Constant, Dot Product, Exponentiation, ExpSineSquared, \n",
        "# # Product, Rational Quadratic, RBF, Sum, White\n",
        "\n",
        "# # Benchmark Function 1\n",
        "# kernel1 = ConstantKernel(1.0, (1e-8, 1e2)) * RBF(1.0, (1e-8, 1e2)) # Works great for Benchmark Function 1\n",
        "\n",
        "# #Benchmark Function 2\n",
        "# kernel2 = 66.3*RBF(0.1, (1e-8, 1e2)) #seems to work well for discontinuities, so we'll try for Benchmark Function 2\n",
        "\n",
        "# #Benchmark Function 3\n",
        "# kernel3 = kernel2\n",
        "\n",
        "LFoptimizedKernel1 = 0.0873**2 + Matern(length_scale=7.53, nu=1.5) + WhiteKernel(noise_level=0.00121)\n",
        "LFoptimizedKernel2 = 5.31**2 * RBF(length_scale=5.08) + WhiteKernel(noise_level=0.00179)\n",
        "LFoptimizedKernel3 = 4.33**2 * RationalQuadratic(alpha=0.00285, length_scale=12.1)\n",
        "\n",
        "# Below are the different kernels (and combinations of kernels) that Dr. Reasor used in his code\n",
        "\n",
        "#kernel = ConstantKernel(1.0) + Matern(length_scale=0.1, nu=3/2) #+ WhiteKernel(noise_level=1)\n",
        "#kernel = 1.0*Matern(length_scale=0.1, nu=1.5)\n",
        "#kernel = RationalQuadratic()\n",
        "#kernel = Matern(length_scale=0.1, nu=2.5)  #\n",
        "#kernel = ConstantKernel(1.0, (1e-8, 1e2)) * RBF(0.1, (1e-8, 1e2))\n",
        "#kernel = Cdatetime.dateonstantKernel(1.0, (1e-3, 1e3))*RBF(1.0, (1e-2, 1e2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e8adec2",
      "metadata": {},
      "source": [
        "## Optimize Kriging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5605a6d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "if LFKrigOptimize:\n",
        "\n",
        "    longKernel = 34.4**2 * RBF(length_scale=41.8) \\\n",
        "    + 3.27**2 * RBF(length_scale=180) \\\n",
        "        * ExpSineSquared(length_scale=1.44, periodicity=1) \\\n",
        "        + 0.446**2 * RationalQuadratic(alpha=17.7, length_scale=0.957) \\\n",
        "            + 0.197**2 * RBF(length_scale=0.138) + WhiteKernel(noise_level=0.0336)\n",
        "\n",
        "    LFoptimizedKernel1 = 3.01**2 * RationalQuadratic(alpha=0.00531, length_scale=0.712)\t\n",
        "    LFoptimizedKernel2 = 0.00316**2 + Matern(length_scale=5.35, nu=1.5) + WhiteKernel(noise_level=0.134)\n",
        "    HFoptimizedKernel1 = 2.28**2 * RBF(length_scale=3.09) + WhiteKernel(noise_level=0.002)\n",
        "    HFoptimizedKernel2 = 1.54**2 * Matern(length_scale=3.7, nu=2.5)\n",
        "    HFoptimizedKernel3 = 2.75**2 * RBF(length_scale=3.48) + WhiteKernel(noise_level=0.00161)\n",
        "\n",
        "    kernels = [\n",
        "    100 * RBF(length_scale=0.1, length_scale_bounds=(1e-1, 10.0)) + WhiteKernel(noise_level=1),\n",
        "    2.44**2 * RBF(length_scale=2.41),\n",
        "    1.0 * RationalQuadratic(length_scale=1.0, alpha=0.1),\n",
        "    #ConstantKernel(0.1, (0.01, 10.0)) * (DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)) ** 2),\n",
        "    1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0),nu=2.5),\n",
        "    ConstantKernel(1.0) + Matern(length_scale=0.1, nu=3/2) + WhiteKernel(noise_level=1),\n",
        "    LFoptimizedKernel1,\n",
        "    bigInputSpaceLFOptimizedKernel,\n",
        "    HFoptimizedKernel1,\n",
        "    HFoptimizedKernel2,\n",
        "    HFoptimizedKernel3,\n",
        "    # LFoptimizedKernel2,\n",
        "    # HFoptimizedKernel,\n",
        "    # #]\n",
        "    longKernel\n",
        "    ]\n",
        "\n",
        "    LFerrorCompDataFrame, LFerrorDict, LFmodelDict = optimizeKrig(\n",
        "        kernelList = kernels,\n",
        "        X_train = X_train, \n",
        "        y_train = y_lf_train, \n",
        "        X_test = X_test,\n",
        "        y_test = y_lf_test,\n",
        "        fidelityLevel = \"LF\",\n",
        "        method = \"krig\",\n",
        "        n_restarts = 1,\n",
        "        verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f564448",
      "metadata": {},
      "outputs": [],
      "source": [
        "# df = LFerrorCompDataFrame\n",
        "# df\n",
        "# pd.set_option('display.max_colwidth', None)\n",
        "# newdf = df.sort_values(by=['NRMSE (Pressure)', 'NRMSE (Heat Transfer)'])\n",
        "# newdf\n",
        "# loadKrigOpt(filename='optimizerPickle_LF_2022-06-09.pkl',dictName='krigOptDict',printKeys=True)\n",
        "# df = pd.DataFrame.from_dict(krigOptDict)\n",
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bdd64f8-61a8-449e-bda8-eef10e4db4ab",
      "metadata": {
        "id": "9bdd64f8-61a8-449e-bda8-eef10e4db4ab"
      },
      "source": [
        "## Train LF Kriging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0c3d03cc-9acd-407c-a261-c483546246fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c3d03cc-9acd-407c-a261-c483546246fa",
        "outputId": "477efd0b-7f46-40b4-aa5c-6ab3b2b0c85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Low fidelity data generated, scaled, and split. Low fidelity output data truncation:  True\n",
            "LF_krig training begin\n",
            "LF_krig training end\n",
            "LF Kriging train time: 7.0910289 seconds\n",
            "Model name:  LF_krig\n",
            "Original kernel: 0.0109**2 + Matern(length_scale=6.91, nu=1.5) + WhiteKernel(noise_level=0.00212)\n",
            "Optimized kernel: 0.0109**2 + Matern(length_scale=6.94, nu=1.5) + WhiteKernel(noise_level=0.00202)\n",
            "_________________________\n"
          ]
        }
      ],
      "source": [
        "# if there are convergence issues, we need to change the optimizer in a manual way. possibly through \"inheritance,\" \n",
        "# or maybe by copying the source code and modifying the optimizer to increase max iters\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html\n",
        "# https://github.com/scikit-learn/scikit-learn/blob/16625450b/sklearn/gaussian_process/_gpr.py#L24\n",
        "\n",
        "# LFoptimizedKernel = 3.01**2 * RationalQuadratic(alpha=0.00531, length_scale=0.712)\t\n",
        "# LFoptimizedKernel = 2.44**2 * RBF(length_scale=2.41)\n",
        "\n",
        "# LFoptimizedKernel = 0.00316**2 + Matern(length_scale=5.35, nu=1.5) + WhiteKernel(noise_level=0.134)\n",
        "\n",
        "# bigInputSpaceLFOptimizedKernel = 5.15**2 * RBF(length_scale=5.01) + WhiteKernel(noise_level=0.00288)\t\n",
        "lowFidelityDataGenAndProcess(verbose=False, downsampleLF=downsampleLF)\n",
        "\n",
        "LFoptimizedKernel1 = 0.0109**2 + Matern(length_scale=6.91, nu=1.5) + WhiteKernel(noise_level=0.00212)\n",
        "\n",
        "if LFKrigTrain: \n",
        "\n",
        "  krigTrain(\n",
        "    X_train=X_train,\n",
        "    y_train=y_lf_train, \n",
        "    fidelityLevel='LF',\n",
        "    kernel=LFoptimizedKernel1, \n",
        "    n_restarts = 1,\n",
        "    verbose=True\n",
        "    )\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f18009-4d57-4c22-8b7f-7a29bb29234f",
      "metadata": {
        "id": "56f18009-4d57-4c22-8b7f-7a29bb29234f"
      },
      "source": [
        "## Save LF Kriging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c3020b-04f2-43f0-89f3-7734a34cf200",
      "metadata": {
        "id": "e6c3020b-04f2-43f0-89f3-7734a34cf200"
      },
      "outputs": [],
      "source": [
        "if LFKrigSave:\n",
        "    saveKrig(fidelityLevel='LF')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79e301b5-8f62-4f14-a57f-c0a97b68bbbd",
      "metadata": {
        "id": "79e301b5-8f62-4f14-a57f-c0a97b68bbbd"
      },
      "source": [
        "## Load LF Kriging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2cad34-17ce-4abf-932f-26cefe0b596c",
      "metadata": {
        "id": "ad2cad34-17ce-4abf-932f-26cefe0b596c"
      },
      "outputs": [],
      "source": [
        "if LFKrigLoad:\n",
        "\n",
        "    filename = 'LF_krig_2022-05-17.sav'\n",
        "    desiredLoadedModelName = 'LF_krig_loaded'\n",
        "\n",
        "    locals()[desiredLoadedModelName] = pickle.load(open(filename, 'rb'))\n",
        "    \n",
        "    LF_krig = None\n",
        "    LF_krig = LF_krig_loaded\n",
        "    LF_krig_loaded = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1416c194-d937-40e8-acff-bcdb2263af37",
      "metadata": {
        "id": "1416c194-d937-40e8-acff-bcdb2263af37"
      },
      "source": [
        "## Generate Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "778788b0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method: kriging, Fidelity Level: LF\n",
            "_________________________\n",
            "LF_krig_test_predict part 1--> qw_LF_krig_test_predict\n",
            "LF_test_truth part 1--> qw_LF_test_truth\n",
            "LF_krig_test_predict part 2--> p_LF_krig_test_predict\n",
            "LF_test_truth part 2--> p_LF_test_truth\n",
            "LF_krig_train_predict part 1--> qw_LF_krig_train_predict\n",
            "LF_train_truth part 1--> qw_LF_train_truth\n",
            "LF_krig_train_predict part 2--> p_LF_krig_train_predict\n",
            "LF_train_truth part 2--> p_LF_train_truth\n",
            "['qw_LF_krig_test_predict', 'qw_LF_test_truth', 'p_LF_krig_test_predict', 'p_LF_test_truth', 'qw_LF_krig_train_predict', 'qw_LF_train_truth', 'p_LF_krig_train_predict', 'p_LF_train_truth']\n",
            "_______________\n",
            "Prediction frequency: 29464.35878 Hz. Prediction time per case: 0.0000351 seconds\n",
            "_______________\n",
            "leftFluidScalarDistributionLength: 885\n",
            "rightFluidScalarDistributionLength: 399\n",
            "qw_LF_krig_test_predict  shape:  (79, 1284)\n",
            "qw_LF_test_truth  shape:  (79, 1284)\n",
            "p_LF_krig_test_predict  shape:  (79, 1284)\n",
            "p_LF_test_truth  shape:  (79, 1284)\n",
            "qw_LF_krig_train_predict  shape:  (636, 1284)\n",
            "qw_LF_train_truth  shape:  (636, 1284)\n",
            "p_LF_krig_train_predict  shape:  (636, 1284)\n",
            "p_LF_train_truth  shape:  (636, 1284)\n",
            "qw_LF_krig_test_predict = qw_LF_OutputScaler.inverse_transform(qw_LF_krig_test_predict)\n",
            "qw_LF_krig_train_predict = qw_LF_OutputScaler.inverse_transform(qw_LF_krig_train_predict)\n",
            "qw_LF_test_truth = qw_LF_OutputScaler.inverse_transform(qw_LF_test_truth)\n",
            "qw_LF_train_truth = qw_LF_OutputScaler.inverse_transform(qw_LF_train_truth)\n",
            "p_LF_krig_test_predict = p_LF_OutputScaler.inverse_transform(p_LF_krig_test_predict)\n",
            "p_LF_krig_train_predict = p_LF_OutputScaler.inverse_transform(p_LF_krig_train_predict)\n",
            "p_LF_test_truth = p_LF_OutputScaler.inverse_transform(p_LF_test_truth)\n",
            "p_LF_train_truth = p_LF_OutputScaler.inverse_transform(p_LF_train_truth)\n"
          ]
        }
      ],
      "source": [
        "if LFKrigTrain or LFKrigLoad:\n",
        "\n",
        "    generateInverseTransformedPredictions(\n",
        "        X_train = X_train,\n",
        "        X_test = X_test,\n",
        "        y_train = y_lf_train,\n",
        "        y_test = y_lf_test,\n",
        "        method = 'kriging',\n",
        "        fidelityLevel = 'LF',\n",
        "        verbose= True,\n",
        "        truncate=downsampleLF\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f6dc20b",
      "metadata": {},
      "outputs": [],
      "source": [
        "if LFKrigTrain or LFKrigLoad: \n",
        "    if 'tempLFinputVarNames' not in globals():\n",
        "        tempLFinputVarNames = LFinputVarNames + ['M_inf']\n",
        "    # rmse = mean_squared_error(truth, prediction, squared=False)\n",
        "    pdDict = dict()\n",
        "    for name in tempLFinputVarNames:\n",
        "        xss = globals()[name][testIdx].tolist()\n",
        "        pdDict[name] = [x for xs in xss for x in xs]\n",
        "    errorList = []\n",
        "    totalTestCases = X_test.shape[0]\n",
        "\n",
        "    for case in np.arange(totalTestCases):\n",
        "        p_nrmse = normalizedRootMeanSquaredError(p_LF_test_truth[case], p_LF_krig_test_predict[case])\n",
        "        qw_nrmse = normalizedRootMeanSquaredError(qw_LF_test_truth[case], qw_LF_krig_test_predict[case])\n",
        "        mean_nrmse = np.mean((p_nrmse, qw_nrmse))\n",
        "        added_nrmse = p_nrmse + qw_nrmse\n",
        "        errorList.append(added_nrmse)\n",
        "\n",
        "    #     caseList = [testIdx, trainIdx]\n",
        "    pdDict[\"Error\"] = errorList\n",
        "    df1 = pd.DataFrame(pdDict) \n",
        "    plt.hist(errorList)\n",
        "    plt.title('Test NRMSE Histogram')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406b4f4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "if LFKrigTrain or LFKrigLoad: \n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i, name in enumerate(tempLFinputVarNames):\n",
        "        ax = plt.subplot(len(tempLFinputVarNames), 2, i+1)\n",
        "        ax.scatter(globals()[name][testIdx],errorList)\n",
        "        ax.set_title(name + ' error')\n",
        "        # ax.set_yscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1746cde",
      "metadata": {},
      "outputs": [],
      "source": [
        "# g = sns.pairplot(df1, hue=\"Error\",diag_kind=\"histogram\", corner=True)\n",
        "# g.map_lower(sns.kdeplot, levels=4, color=\".2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f129cf8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "if LFKrigTrain or LFKrigLoad: \n",
        "    plotInputSpaceErrorColorMap(\n",
        "        testIdxArray = testIdx,\n",
        "        trainIdxArray = trainIdx,\n",
        "        topErrorValuesToPlot = 5,\n",
        "        inputVarNameList=tempLFinputVarNames,\n",
        "        errorList = errorList,\n",
        "        logPlot=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dad974b-90da-4c77-8a39-651bb4d77395",
      "metadata": {
        "id": "4dad974b-90da-4c77-8a39-651bb4d77395",
        "outputId": "444b6152-3b60-414f-debe-924e9d59caa2"
      },
      "outputs": [],
      "source": [
        "if LFKrigTrain or LFKrigLoad:\n",
        "    oneToOnePlotTool(method='Kriging', \n",
        "                    desiredNumCasesForPlot=30, \n",
        "                    X_test=X_test, \n",
        "                    qw_prediction = qw_LF_krig_test_predict, \n",
        "                    qw_truth = qw_LF_test_truth, \n",
        "                    p_prediction = p_LF_krig_test_predict, \n",
        "                    p_truth = p_LF_test_truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "855e22ee-d74e-4437-9999-d3dec7e09e1a",
      "metadata": {
        "id": "855e22ee-d74e-4437-9999-d3dec7e09e1a",
        "outputId": "f0ba2bd6-52df-4555-e94c-7ba2421991ec"
      },
      "outputs": [],
      "source": [
        "if LFKrigTrain or LFKrigLoad:\n",
        "    oneToOneVisualizationPlotAllData(case=33, \n",
        "        qw_test_predict=qw_LF_krig_test_predict,\n",
        "        p_test_predict=p_LF_krig_test_predict, \n",
        "        qw_test_truth=qw_LF_test_truth, \n",
        "        p_test_truth=p_LF_test_truth, \n",
        "        M_inf_test=M_inf_test,\n",
        "        method='Kriging')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f0efe118",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01c5a3115a84458a8b7fd57599229a79",
              "version_major": 2,
              "version_minor": 0
            },
            "image/png": "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",
            "text/html": [
              "\n",
              "            <div style=\"display: inline-block;\">\n",
              "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
              "                    Figure\n",
              "                </div>\n",
              "                <img src='data:image/png;base64,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' width=640.0/>\n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib ipympl\n",
        "\n",
        "modelType = 'krig'\n",
        "fidelityLevel = 'LF'\n",
        "truncate = True\n",
        "\n",
        "plt.close('all')\n",
        "\n",
        "def genSinglePredictionForSliderPlot(\n",
        "    modelType, fidelityLevel,inputArray, truncate\n",
        "    ):\n",
        "\n",
        "    modelName = f'{fidelityLevel}_{modelType}'\n",
        "    predictions  = globals()[modelName].predict(inputArray)\n",
        "    variableNameList = ['qw_plotting', 'p_plotting']\n",
        "    for i, name in enumerate(variableNameList):\n",
        "        globals()[name] = np.hsplit(predictions,len(variableNameList))[i]\n",
        "    if truncate: \n",
        "        leftFluidScalarDistributionLength = globals()[outputVarNames[0]][0,:xSpotLeft].shape[0]\n",
        "        rightFluidScalarDistributionLength =  globals()[outputVarNames[0]][0,xSpotLeft:].shape[0]\n",
        "\n",
        "        for var in variableNameList:\n",
        "            temp_left = [np.tile(entry, leftFluidScalarDistributionLength) for entry in globals()[var][:,0] ]\n",
        "            temp_right = [np.tile(entry,rightFluidScalarDistributionLength) for entry in globals()[var][:,1] ]\n",
        "            temp_stacked = np.hstack((temp_left,temp_right))\n",
        "            globals()[var] = temp_stacked\n",
        "    qw_plotting = qw_LF_OutputScaler.inverse_transform(globals()['qw_plotting'])\n",
        "\n",
        "    distribution = qw_plotting\n",
        "\n",
        "    return distribution\n",
        "\n",
        "\n",
        "variableNameList = ['qw_plotting', 'p_plotting']\n",
        "\n",
        "fig,ax = plt.subplots()\n",
        "plt.subplots_adjust(bottom=0.35, left=0.25)\n",
        "plt.title('Low Fidelity Kriging Prediction')\n",
        "plt.xlabel('X location (meters)')\n",
        "plt.ylabel('Wall Heat Flux (W/m^3)')\n",
        "# initialize axis location\n",
        "\n",
        "allInputVars = [globals()[name] for name in LFinputVarNames]\n",
        "valinitList = [np.median(val) for val in allInputVars]\n",
        "allInputVars = None\n",
        "\n",
        "qw_plotting = genSinglePredictionForSliderPlot(\n",
        "    modelType=modelType, \n",
        "    fidelityLevel=fidelityLevel,\n",
        "    inputArray=np.asarray(valinitList).reshape(1,-1), \n",
        "    truncate=truncate\n",
        "    )\n",
        "\n",
        "# display initial plot. initial case can be anything, I just chose number 10\n",
        "xPlot = x_cc_windowed[0,:].reshape(-1,)\n",
        "yPlot = qw_plotting.reshape(-1,)\n",
        "l, = plt.plot(xPlot, yPlot)\n",
        "\n",
        "axLocation = 0\n",
        "for varName in LFinputVarNames: \n",
        "# set up axis location for slider bars\n",
        "    axName = 'ax_'+ varName\n",
        "    globals()[axName] = plt.axes([0.25, axLocation, 0.65, 0.03])\n",
        "    axLocation += .05\n",
        "\n",
        "    # define the values to use for snapping\n",
        "    snapValueName = 'allowed_'+varName\n",
        "    globals()[snapValueName] = globals()[varName].reshape(-1,)\n",
        "\n",
        "    # create sliders\n",
        "    sliderName = 'slider_'+varName\n",
        "    valmin = globals()[varName].min()\n",
        "    valmax = globals()[varName].max()\n",
        "    valinit = np.median(globals()[varName])\n",
        "    valinitList.append(valinit)\n",
        "    globals()[sliderName] = Slider(\n",
        "        ax = globals()[axName],\n",
        "        label = varName,\n",
        "        valmin = valmin,\n",
        "        valmax = valmax,\n",
        "        valinit = valinit,\n",
        "        valstep = globals()[snapValueName]\n",
        "    )\n",
        "\n",
        "\n",
        "def update(val):\n",
        "    inputArrayShape = (1, len(LFinputVarNames))\n",
        "    inputArray = None\n",
        "    inputArray = np.empty(inputArrayShape)\n",
        "    for i, varName in enumerate(LFinputVarNames):\n",
        "        ScalerName = varName + '_InputScaler'\n",
        "        sliderName = f'slider_{varName}'\n",
        "        preTransformedInput = globals()[sliderName].val\n",
        "        inputArray[0,i] = globals()[ScalerName].transform(np.array(preTransformedInput).reshape(1,-1))\n",
        "    \n",
        "    distribution = genSinglePredictionForSliderPlot(\n",
        "        modelType = modelType,\n",
        "        fidelityLevel = fidelityLevel,\n",
        "        inputArray = inputArray,\n",
        "        truncate=truncate)\n",
        "\n",
        "    l.set_ydata(distribution)\n",
        "    fig.canvas.draw_idle()\n",
        "\n",
        "for varName in LFinputVarNames:\n",
        "    sliderName = f'slider_{varName}'\n",
        "    globals()[sliderName].on_changed(update)\n",
        "\n",
        "ax_reset = plt.axes([0.0, 0.025, 0.1, 0.04])\n",
        "button = Button(ax_reset, 'Reset', hovercolor='0.975')\n",
        "\n",
        "def reset(event):\n",
        "    for varName in LFinputVarNames:\n",
        "        sliderName = f'slider_{varName}'\n",
        "        globals()[sliderName].reset()\n",
        "\n",
        "button.on_clicked(reset)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "168986b7-24a1-44bb-9daf-5b1f7c9bc477",
      "metadata": {
        "id": "168986b7-24a1-44bb-9daf-5b1f7c9bc477"
      },
      "source": [
        "# Low Fidelity Neural Network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8134831e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"Low Fidelity Neural Network\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37c34d80",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build hypermodel. Essentially capable of accepting one more argument, not listed, 'hp.' \n",
        "if LFNNOptimize:\n",
        "\n",
        "    hypermodel = hyperMLP(\n",
        "        input_data = X_train, \n",
        "        output_data = y_lf_train,\n",
        "        regType = keras.regularizers.L2, \n",
        "        regValue = 1.0e-6,\n",
        "        hiddenLayerActivation = tf.nn.tanh,\n",
        "        outputLayerActivation = tf.nn.leaky_relu,\n",
        "        kernelInitializer = tf.keras.initializers.GlorotUniform(),\n",
        "        optimizer = tf.keras.optimizers.Adamax,\n",
        "        loss = 'mse'\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd55a50",
      "metadata": {},
      "outputs": [],
      "source": [
        "if LFNNOptimize:\n",
        "\n",
        "    numEpochs = 200\n",
        "    validData = (X_test, y_lf_test)\n",
        "    hyperband_iterations = 5\n",
        "    callbacks_list = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor = \"val_mean_squared_error\",mode=\"min\",\n",
        "            patience=100, verbose=0,\n",
        "            restore_best_weights=False \n",
        "            )\n",
        "        ]\n",
        "\n",
        "    if quickTestRun:\n",
        "        numEpochs = 10\n",
        "        hyberband_iterations = 1\n",
        "        callbacks_list = []\n",
        "\n",
        "\n",
        "    if tunerChoice == 'RandomSearch':\n",
        "        tuner = kt.RandomSearch(\n",
        "            hypermodel = hypermodel,\n",
        "            objective = 'val_mean_squared_error',\n",
        "            max_trials = 100,\n",
        "            executions_per_trial = 2,\n",
        "            directory =  tunerDir,\n",
        "            overwrite = True,\n",
        "            project_name='ktRS'\n",
        "        )\n",
        "\n",
        "    elif tunerChoice == 'Hyperband':\n",
        "        tuner = kt.Hyperband(\n",
        "            hypermodel = hypermodel,\n",
        "            objective = 'val_mean_squared_error',\n",
        "            max_epochs= 1000,\n",
        "            factor=3,\n",
        "            hyperband_iterations=hyperband_iterations,\n",
        "            directory = tunerDir,\n",
        "            overwrite = True,\n",
        "            project_name='ktHB',\n",
        "            max_model_size = int(totalParamsTrainData)/2\n",
        "        )\n",
        "\n",
        "    tuner.search_space_summary()\n",
        "\n",
        "    tuner.search(\n",
        "        x=X_train,\n",
        "        y=y_lf_train,\n",
        "        batch_size=224,\n",
        "        epochs=numEpochs,\n",
        "        callbacks = [],\n",
        "        verbose=True,\n",
        "        shuffle=False,\n",
        "        validation_data=validData,\n",
        "        use_multiprocessing=True, \n",
        "        )\n",
        "\n",
        "    top_n = 10\n",
        "    best_hps = tuner.get_best_hyperparameters(top_n)\n",
        "        \n",
        "    for best_hp in best_hps:\n",
        "        print('_'*10)\n",
        "        print('learning rate: ', best_hp.get('learning_rate'))\n",
        "        print('layers: ',best_hp.get('layers'))\n",
        "        print('units1: ',best_hp.get('units1'))\n",
        "        print('units2: ',best_hp.get('units2'))\n",
        "        print('units3: ',best_hp.get('units3'))\n",
        "        print('_'*10)\n",
        "\n",
        "    saveTuner(tuner = tuner, fidelityLevel = 'LF')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5993f604",
      "metadata": {},
      "outputs": [],
      "source": [
        "if LFNNOptimize:\n",
        "    model = tuner.hypermodel.build(best_hps)\n",
        "    history = model.fit(    \n",
        "        x=X_train,\n",
        "        y=y_lf_train,\n",
        "        batch_size=None,\n",
        "        epochs=numEpochs,\n",
        "        callbacks = [],\n",
        "        verbose=True,\n",
        "        shuffle=False,\n",
        "        validation_data=validData,\n",
        "        use_multiprocessing=True#,\n",
        "        # steps_per_execution=10,\n",
        "        # jit_compile=True\n",
        "        )\n",
        "\n",
        "    val_mse_per_epoch = history.history['val_mean_squared_error']\n",
        "    best_epoch = val_mse_per_epoch.index(max(val_mse_per_epoch)) + 1\n",
        "    print('Best epoch: %d' % (best_epoch,))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5918ba7",
      "metadata": {},
      "outputs": [],
      "source": [
        "if LFNNOptimize:\n",
        "    mseNames = [\"mean_squared_error\",\n",
        "                'val_mean_squared_error'\n",
        "                ]\n",
        "    colorList = [ 'k', 'r']\n",
        "\n",
        "    plotTrainAndTestLoss(historyDict = history.history,\n",
        "                        mseNames = mseNames,\n",
        "                        colorList = colorList,\n",
        "                        fidelityLevel = 'Tuned Model')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f2cd1fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "lowFidelityDataGenAndProcess(verbose=True, downsampleLF=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00319b08",
      "metadata": {},
      "outputs": [],
      "source": [
        "if LFNNConvergence: \n",
        "    callbacks_list = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor = \"val_mean_squared_error\",mode=\"min\",\n",
        "            patience=200, verbose=0,\n",
        "            restore_best_weights=False \n",
        "            )\n",
        "        ]\n",
        "\n",
        "    convStudyLayerList = [ \n",
        "        [64],\n",
        "        [72],\n",
        "        [80],\n",
        "        [40, 32],\n",
        "        [32, 64],\n",
        "        [56, 72],\n",
        "        [56, 80],\n",
        "        [80, 80],\n",
        "        [64, 80, 80],\n",
        "        [48, 56, 40],\n",
        "        [64, 80, 32],\n",
        "        [40, 56, 64],\n",
        "        [80, 80, 80],\n",
        "        [32, 64, 128],\n",
        "        [64, 128, 128+32]\n",
        "        ] \n",
        "\n",
        "    # convStudyLayerList = [ \n",
        "\n",
        "    #     # [80],\n",
        "    #     [32, 64],\n",
        "    #     # [56, 80],\n",
        "    #     # [64, 80, 32],\n",
        "    #     # [40, 56, 64],\n",
        "    #     [80, 80, 80],\n",
        "    #     [32, 64, 128],\n",
        "    #     [64, 128, 128+32],\n",
        "    #     [32, 64, 96, 128],\n",
        "    #     # [64, 80 ,80, 32],\n",
        "    #     # [64, 80 , 80, 80, 32],\n",
        "    #     # [32, 64, 32, 128]\n",
        "    #     ]   \n",
        "\n",
        "    hyperparamDict = {\n",
        "        \"learningRate\" : 1.0e-3,\n",
        "        \"regType\" : keras.regularizers.L2,\n",
        "        \"regValue\" : 1.0e-6,\n",
        "        \"hiddenLayerActivation\" : tf.nn.tanh,\n",
        "        \"outputLayerActivation\" : tf.nn.leaky_relu,\n",
        "        \"kernelInitializer\" : tf.keras.initializers.GlorotUniform(),\n",
        "        \"optimizer\" : tf.keras.optimizers.Adamax,\n",
        "        \"numEpochs\" : 10000,\n",
        "        \"myBatchSize\" : 224,\n",
        "        \"loss\" : 'mse'\n",
        "    }\n",
        "    validData = (X_test, y_lf_test)\n",
        "\n",
        "    neuralNetworkConvergence(\n",
        "        fidelityLevel='LF',\n",
        "        convStudyLayerList = convStudyLayerList,\n",
        "        hyperparamDict = hyperparamDict,\n",
        "        X_train = X_train,\n",
        "        y_train = y_lf_train,\n",
        "        validData = validData,\n",
        "        callbacks_list = callbacks_list,\n",
        "        verbose = True,\n",
        "        showConvPlot = True,\n",
        "        saveConvPlot = True,\n",
        "        showMSEplot = True,\n",
        "        saveMSEplot = True,\n",
        "        showSpeedPlot = True,\n",
        "        saveSpeedPlot =True\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7df3702-d257-4969-967b-80d305058134",
      "metadata": {
        "id": "a7df3702-d257-4969-967b-80d305058134",
        "outputId": "d91b21e2-ac90-4938-98d1-fa77ffb82aac"
      },
      "outputs": [],
      "source": [
        "lowFidelityDataGenAndProcess(verbose=False, downsampleLF=True)\n",
        "if LFNNTrain:\n",
        "      lowFidelityLayerSizeList = [56, 80] #input the number of neurons per layer. Length of this list indicates number of hidden layers\n",
        "      learningRate = 1.0e-3 #From Deep Learning w/ Python (Chollet)\n",
        "      regType = keras.regularizers.L2\n",
        "      regValue = 1.0e-6\n",
        "      hiddenLayerActivation = tf.nn.tanh\n",
        "      outputLayerActivation = tf.nn.leaky_relu\n",
        "      kernelInitializer = tf.keras.initializers.GlorotUniform()\n",
        "      optimizer = tf.keras.optimizers.Adamax\n",
        "      numEpochs = 10000\n",
        "      if quickTestRun:\n",
        "            numEpochs = 50\n",
        "      myBatchSize = None\n",
        "      validSplit = None\n",
        "      loss = 'mse'\n",
        "      validData = (X_test, y_lf_test)\n",
        "\n",
        "      callbacks_list = None\n",
        "      callbacks_list = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor = \"val_mean_squared_error\",mode=\"min\",\n",
        "            patience=200, verbose=0,\n",
        "            restore_best_weights=False \n",
        "            )\n",
        "        ]\n",
        "\n",
        "      LF_NN = None #sometimes remnants of previously trained models can hang around, it's best \n",
        "                  #to clear the variable first \n",
        "\n",
        "      LF_NN = build_model_parameterized(\n",
        "            input_data = X_train, \n",
        "            output_data = y_lf_train,\n",
        "            layerSizeList = lowFidelityLayerSizeList, \n",
        "            rate = learningRate, \n",
        "            regType = regType, \n",
        "            regValue = regValue,\n",
        "            hiddenLayerActivation = hiddenLayerActivation,\n",
        "            outputLayerActivation = outputLayerActivation,\n",
        "            kernelInitializer = kernelInitializer,\n",
        "            optimizer = optimizer,\n",
        "            outputLayerDataType= 'float64',\n",
        "            loss = loss)\n",
        "\n",
        "\n",
        "            \n",
        "kerasPlotModel(model=LF_NN,fidelityLevel='LF')\n",
        "LF_NN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d5b4e84",
      "metadata": {},
      "outputs": [],
      "source": [
        "batchTest(\n",
        "    model=LF_NN,\n",
        "    fidelityLevel = 'LF',\n",
        "    batchSizeMultiples=10,\n",
        "    input_data=X_train,\n",
        "    output_data=y_lf_train,\n",
        "    validData=validData,\n",
        "    numEpochs=40\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04338b63",
      "metadata": {},
      "outputs": [],
      "source": [
        "loadTunerPKL(\n",
        "    filename = 'tunerPickle_LF_2022-06-10.pkl',\n",
        ")\n",
        "\n",
        "\n",
        "top_n = 20\n",
        "best_hps = tuner.get_best_hyperparameters(top_n)\n",
        "    \n",
        "for best_hp in best_hps:\n",
        "    print('_'*10)\n",
        "    print('learning rate: ', best_hp.get('learning_rate'))\n",
        "    print('layers: ',best_hp.get('layers'))\n",
        "    print('units1: ',best_hp.get('units1'))\n",
        "    print('units2: ',best_hp.get('units2'))\n",
        "    print('units3: ',best_hp.get('units3'))\n",
        "    print('_'*10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10cf35d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "loadBatchTest(\n",
        "    filename='timePickle_LF_2022-06-09.pkl',\n",
        "    DFname='timeDF',\n",
        "    printDF=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "134d2959-9e3f-432f-9132-1aa0764fda98",
      "metadata": {
        "id": "134d2959-9e3f-432f-9132-1aa0764fda98",
        "outputId": "91fb7b1b-649d-4601-d2e4-3d0bc4fda341"
      },
      "outputs": [],
      "source": [
        "# tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "if LFNNTrain:\n",
        "        \n",
        "    LF_NN_epochs = None\n",
        "    LF_NN_history = None\n",
        "    print('GPU training start')\n",
        "    start = time.time()\n",
        "    LF_NN_epochs, LF_NN_history = train_model_all_fidelity(\n",
        "        model = LF_NN, \n",
        "        input_data = X_train, \n",
        "        output_data = y_lf_train,\n",
        "        numEpochs = numEpochs, \n",
        "        myBatchSize = myBatchSize,\n",
        "        validData = validData,\n",
        "        callbacks_list= callbacks_list)\n",
        "    end = time.time()\n",
        "    print('GPU training complete')\n",
        "    print(round((end-start),4))\n",
        "    \n",
        "#     # with tf.device('/CPU:0'):\n",
        "#     #     LF_NN_epochs = None\n",
        "#     #     LF_NN_history = None\n",
        "#     #     print('CPU training start')\n",
        "#     #     start = time.time()\n",
        "#     #     LF_NN_epochs, LF_NN_history = train_model_all_fidelity(\n",
        "#     #         model = LF_NN, \n",
        "#     #         input_data = X_train, \n",
        "#     #         output_data = y_lf_train,\n",
        "#     #         numEpochs = numEpochs, \n",
        "#     #         myBatchSize = myBatchSize,\n",
        "#     #         validData = validData,\n",
        "#     #         callbacks_list= callbacks_list)\n",
        "#     #     end = time.time()\n",
        "#     #     print('CPU training complete')\n",
        "#     #     print(round((end-start),4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "216ccc22-05ca-47ad-ab7e-9d5014b38743",
      "metadata": {
        "id": "216ccc22-05ca-47ad-ab7e-9d5014b38743",
        "outputId": "a611eb6e-a3c5-4d90-c4b9-ebd7a0058693"
      },
      "outputs": [],
      "source": [
        "if LFNNSave:\n",
        "    saveNN(fidelityLevel='LF')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56a09f43-5702-468b-b35d-e6afe87e1fcb",
      "metadata": {
        "id": "56a09f43-5702-468b-b35d-e6afe87e1fcb"
      },
      "source": [
        "## Load LF NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd6d0b8b-d063-49fc-a396-fafedd55dc42",
      "metadata": {
        "id": "fd6d0b8b-d063-49fc-a396-fafedd55dc42"
      },
      "outputs": [],
      "source": [
        "if LFNNLoad: \n",
        "    loadNN(\n",
        "        neuralNetFolderName = 'LF_NN_2022-05-19'\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7417314-33ed-4d82-8ea4-3837387dffd8",
      "metadata": {
        "id": "a7417314-33ed-4d82-8ea4-3837387dffd8"
      },
      "source": [
        "## Plot Training MSE for LF NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc6d8090-f2b3-44fb-aae4-cc7d9a8e86c8",
      "metadata": {
        "id": "dc6d8090-f2b3-44fb-aae4-cc7d9a8e86c8",
        "outputId": "becf1e79-6273-4ed6-eec4-03127fd85740"
      },
      "outputs": [],
      "source": [
        "mseNames = [\"mean_squared_error\",\n",
        "            'val_mean_squared_error'\n",
        "            ]\n",
        "colorList = [ 'k', 'r']\n",
        "\n",
        "plotTrainAndTestLoss(historyDict = LF_NN_history,\n",
        "                     mseNames = mseNames,\n",
        "                     colorList = colorList,\n",
        "                     fidelityLevel = 'Low-Fidelity')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f3ef323-1f56-440e-b19c-aa22f8ede4f2",
      "metadata": {
        "id": "4f3ef323-1f56-440e-b19c-aa22f8ede4f2"
      },
      "source": [
        "## LF NN Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ecf9866",
      "metadata": {},
      "outputs": [],
      "source": [
        "generateInverseTransformedPredictions(\n",
        "    X_train = X_train,\n",
        "    X_test = X_test,\n",
        "    y_train = y_lf_train,\n",
        "    y_test = y_lf_test,\n",
        "    method = 'NN',\n",
        "    fidelityLevel = 'LF',\n",
        "    verbose = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ca18c75",
      "metadata": {},
      "source": [
        "## Analyze Our Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df2dd87",
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'tempLFinputVarNames' not in globals():\n",
        "    tempLFinputVarNames = LFinputVarNames + ['M_inf']\n",
        "# rmse = mean_squared_error(truth, prediction, squared=False)\n",
        "pdDict = dict()\n",
        "for name in tempLFinputVarNames:\n",
        "    pdDict[name] = globals()[name]\n",
        "errorList = []\n",
        "totalTestCases = X_test.shape[0]\n",
        "\n",
        "for case in np.arange(totalTestCases):\n",
        "    p_nrmse = normalizedRootMeanSquaredError(p_LF_test_truth[case], p_LF_NN_test_predict[case])\n",
        "    qw_nrmse = normalizedRootMeanSquaredError(qw_LF_test_truth[case], qw_LF_NN_test_predict[case])\n",
        "    mean_nrmse = np.mean((p_nrmse, qw_nrmse))\n",
        "    added_nrmse = p_nrmse + qw_nrmse\n",
        "    errorList.append(added_nrmse)\n",
        "\n",
        "#     caseList = [testIdx, trainIdx]\n",
        "\n",
        "\n",
        "plotInputSpaceErrorColorMap(\n",
        "    testIdxArray = testIdx,\n",
        "    trainIdxArray = trainIdx,\n",
        "    inputVarNameList=tempLFinputVarNames,\n",
        "    errorList = errorList,\n",
        "    topErrorValuesToPlot=10,\n",
        "    logPlot = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bdabe0",
      "metadata": {},
      "outputs": [],
      "source": [
        "qw_LF_NN_test_predict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8cd5720",
      "metadata": {},
      "outputs": [],
      "source": [
        "missedPeakList = (abs(np.amax(qw_LF_test_truth, axis = 1) - np.amax(qw_LF_NN_test_predict, axis=1)) / abs(np.amax(qw_LF_test_truth, axis = 1)))*100\n",
        "\n",
        "avgMissedPeak = np.mean(missedPeakList)\n",
        "avgMissedPeak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a0815b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plotInputSpaceMissedPeakColorMap(\n",
        "    testIdxArray = testIdx,\n",
        "    trainIdxArray = trainIdx,\n",
        "    inputVarNameList=tempLFinputVarNames,\n",
        "    errorList = missedPeakList,\n",
        "    topErrorValuesToPlot=10,\n",
        "    logPlot = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ece4597-1fac-4bfb-afa3-e1d6777dc319",
      "metadata": {
        "id": "2ece4597-1fac-4bfb-afa3-e1d6777dc319",
        "outputId": "be601f86-36a4-4dd9-d89d-2cac5014f8dd"
      },
      "outputs": [],
      "source": [
        "oneToOnePlotTool(method='Neural Network', \n",
        "                 desiredNumCasesForPlot=30, \n",
        "                 X_test=X_test, \n",
        "                 qw_prediction = qw_LF_NN_test_predict, \n",
        "                 qw_truth = qw_LF_test_truth, \n",
        "                 p_prediction = p_LF_NN_test_predict, \n",
        "                 p_truth = p_LF_test_truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab7f581d-064a-40ae-b256-b6ceee48615d",
      "metadata": {
        "id": "ab7f581d-064a-40ae-b256-b6ceee48615d",
        "outputId": "8b99ce35-5d99-4a32-d807-ac177195f4fd"
      },
      "outputs": [],
      "source": [
        "oneToOneVisualizationPlotAllData(\n",
        "    case = 9, \n",
        "    qw_test_predict = qw_LF_NN_test_predict,\n",
        "    p_test_predict = p_LF_NN_test_predict,\n",
        "    qw_test_truth = qw_LF_test_truth, \n",
        "    p_test_truth = p_LF_test_truth, \n",
        "    M_inf_test = M_inf_test,\n",
        "    method = 'LF NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1dc91b2-fdd5-4bcb-9394-19beb4127a04",
      "metadata": {
        "id": "a1dc91b2-fdd5-4bcb-9394-19beb4127a04"
      },
      "source": [
        "# Low Fidelity Error Metrics Comparison "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482f8e21",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"Low Fidelity Error Metrics\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "755bbc6c-51e6-497f-a32a-8f9f644e3c61",
      "metadata": {
        "id": "755bbc6c-51e6-497f-a32a-8f9f644e3c61",
        "outputId": "d6483060-9fa9-420f-9403-f9a03af76c77"
      },
      "outputs": [],
      "source": [
        "[LF_krig_NRMSE_pressure, LF_krig_R2_pressure] = errorMetrics(\n",
        "    truth = p_LF_test_truth,\n",
        "    prediction = p_LF_krig_test_predict,\n",
        "    fidelity = 'LF',\n",
        "    model = 'Kriging',\n",
        "    variable = 'Pressure',\n",
        "    verbose = 1)\n",
        "\n",
        "[LF_krig_NRMSE_heatTransfer, LF_krig_R2_heatTransfer] = errorMetrics(\n",
        "    truth = qw_LF_test_truth,\n",
        "    prediction = qw_LF_krig_test_predict,\n",
        "    fidelity = 'LF',\n",
        "    model = 'Kriging',\n",
        "    variable = 'Heat Transfer',\n",
        "    verbose = 1)\n",
        "\n",
        "[LF_NN_NRMSE_pressure, LF_NN_R2_pressure] = errorMetrics(\n",
        "    truth = p_LF_test_truth,\n",
        "    prediction = p_LF_NN_test_predict,\n",
        "    fidelity = 'LF',\n",
        "    model = 'NN',\n",
        "    variable = 'Pressure',\n",
        "    verbose = 1)\n",
        "\n",
        "[LF_NN_NRMSE_heatTransfer, LF_NN_R2_heatTransfer] = errorMetrics(\n",
        "    truth = qw_LF_test_truth,\n",
        "    prediction = qw_LF_NN_test_predict,\n",
        "    fidelity = 'LF',\n",
        "    model = 'NN',\n",
        "    variable = 'Heat Transfer',\n",
        "    verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffdac9a4-23e5-4f25-b539-f7ea49ccfcb8",
      "metadata": {
        "id": "ffdac9a4-23e5-4f25-b539-f7ea49ccfcb8",
        "toc-hr-collapsed": true
      },
      "source": [
        "# High Fidelity Data Processing \n",
        "\n",
        "## Data scaling\n",
        "using sklearn's ```Standard.Scaler```\n",
        "\n",
        "In order to model effectively, we'll want to scale our training data appropriately. In this case, we're using sklearn's ```preprocessing.StandardScaler()```. The module standardizes features by removing the mean and scaling to unit variance. The standard score of a sample x is calculated as: ```z = (x - u) / s```, where ```u``` is the mean of the training samples or zero if ```with_mean=False```, and ```s``` is the standard deviation of the training samples or one if ```with_std=False```.\n",
        "\n",
        "This is included in the comments of the below code block, but keep in my that each data set needs its own distinct scaler object. If you don't create a scaler object for each data set, you won't be able to inverse transform the data properly. \n",
        "\n",
        "The code in the next cell looks ugly, but it is a more robust way to do what the code directly below this sentence is doing. First, we make sure our new variable is not pointing to a Scaler object with the \"None.\" Then, we assign the variable a Scaler object. Lastly, we create a new np.array with our scaled dating using the \".fit_transform\" function. \n",
        "\n",
        "ScalerName = None\n",
        "\n",
        "ScalerName = preprocessing.StandardScaler()\n",
        "\n",
        "ScaledData = ScalerName.fit_transform(original_data)\n",
        "\n",
        "## Validation Split\n",
        "Validation Split: ```sklearn.model_selection.train_test_split```\n",
        "\n",
        "[scikit-learn: train test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f94fb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"High Fidelity Data Processing\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bf7d040-8507-4eea-8d5b-0c05c5ba4f9e",
      "metadata": {
        "id": "0bf7d040-8507-4eea-8d5b-0c05c5ba4f9e",
        "outputId": "e68d5139-e1eb-4e0a-d676-2a40ce13e8e5"
      },
      "outputs": [],
      "source": [
        "inputTrainingData = []\n",
        "inputTrainingNames = []\n",
        "\n",
        "print('Input Data (stored in list inputTrainingData):\\n')\n",
        "for i, name in enumerate(inputVarNames):\n",
        "    ScalerName = name + '_InputScaler'\n",
        "    ScaledName = name + '_Scaled'\n",
        "    InputDataName = 'input' + name\n",
        "    locals()[ScalerName] = None\n",
        "    locals()[ScalerName] = preprocessing.StandardScaler()\n",
        "    locals()[ScaledName] = locals()[ScalerName].fit_transform(globals()[InputDataName])\n",
        "    inputTrainingData.append(locals()[ScaledName])\n",
        "    inputTrainingNames.append(ScaledName)\n",
        "    max_element = str(round(np.max(locals()[ScaledName]),2))\n",
        "    min_element = str(round(np.min(locals()[ScaledName]),2))\n",
        "    print(name + ' has been scaled! It is called ' + ScaledName + '. Min:' + min_element + '. Max:' + max_element)\n",
        "\n",
        "outputTrainingData = []\n",
        "outputTrainingNames = []\n",
        "\n",
        "print('\\nOutput Data (stored in list outputTrainingData):\\n')\n",
        "for i, name in enumerate(outputVarNames):\n",
        "    ScalerName = name + '_OutputScaler'\n",
        "    ScaledName = name + '_Scaled'\n",
        "    OutputDataName = name\n",
        "    locals()[ScalerName] = None\n",
        "    locals()[ScalerName] = preprocessing.StandardScaler()\n",
        "    locals()[ScaledName] = locals()[ScalerName].fit_transform(globals()[OutputDataName])\n",
        "    outputTrainingData.append(locals()[ScaledName])\n",
        "    outputTrainingNames.append(ScaledName)\n",
        "    max_element = str(round(np.max(locals()[ScaledName]),2))\n",
        "    min_element = str(round(np.min(locals()[ScaledName]),2))\n",
        "    print(name + ' has been scaled! It is called ' + ScaledName + '. Min:' + min_element + '. Max:' + max_element)\n",
        "\n",
        "print(str(np.shape(inputTrainingData)))\n",
        "print(str(np.shape(outputTrainingData)))\n",
        "print(inputTrainingNames)\n",
        "print(outputTrainingNames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082d5c94-92be-432b-957a-dee359ce1395",
      "metadata": {
        "id": "082d5c94-92be-432b-957a-dee359ce1395"
      },
      "outputs": [],
      "source": [
        "# these values are already calculated in the low fidelity data generation section, but repeated here in the event that\n",
        "# that section of the notebook has not been run yet. \n",
        "\n",
        "gamma = 1.4 # perfect gas\n",
        "R_specific = 287.058\n",
        "\n",
        "T_inf = inputTemperature\n",
        "rho_inf = inputDensity\n",
        "u_inf = inputVelocity\n",
        "a_inf = np.sqrt(gamma*R_specific*T_inf)\n",
        "M_inf = u_inf/a_inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ebbd0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "inputTrainingNames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4641e11e",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n_modelChoices = [\n",
        "2.28**2 * RBF(length_scale=3.09) + WhiteKernel(noise_level=0.002),\n",
        "1.54**2 * Matern(length_scale=3.7, nu=2.5)\n",
        "]\n",
        "\n",
        "start = 0.20 ; stop = 0.80 ; step = .1\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "\n",
        "fakeConvDict = modelConvergenceStudy(\n",
        "    fidelityLevel= 'HF', \n",
        "    modelType= 'krig',\n",
        "    M_inf=M_inf,\n",
        "    inputTrainingData=inputTrainingData,\n",
        "    outputTrainingData=outputTrainingData,\n",
        "    inputTrainingNames=inputTrainingNames,\n",
        "    outputTrainingNames=outputTrainingNames,\n",
        "    top_n_modelChoices=top_n_modelChoices,\n",
        "    splitList=splitList,\n",
        "    verbose=False,\n",
        "    hyperparamDict=None,\n",
        "    callbacks_list=None,\n",
        "    n_restarts=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379e78db",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n_modelChoices = [\n",
        "2.28**2 * RBF(length_scale=3.09) + WhiteKernel(noise_level=0.002),\n",
        "1.54**2 * Matern(length_scale=3.7, nu=2.5)\n",
        "]\n",
        "\n",
        "start = 0.20 ; stop = 0.80 ; step = 0.03\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "HF_krig_convDict = modelConvergenceStudy(\n",
        "    fidelityLevel= 'HF', \n",
        "    modelType= 'krig',\n",
        "    M_inf=M_inf,\n",
        "    inputTrainingData=inputTrainingData,\n",
        "    outputTrainingData=outputTrainingData,\n",
        "    inputTrainingNames=inputTrainingNames,\n",
        "    outputTrainingNames=outputTrainingNames,\n",
        "    top_n_modelChoices=top_n_modelChoices,\n",
        "    splitList=splitList,\n",
        "    verbose=False,\n",
        "    hyperparamDict=None,\n",
        "    callbacks_list=None,\n",
        "    n_restarts=1\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d709bb10",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n_modelChoices = [\n",
        "2.28**2 * RBF(length_scale=3.09) + WhiteKernel(noise_level=0.002),\n",
        "1.54**2 * Matern(length_scale=3.7, nu=2.5)\n",
        "]\n",
        "\n",
        "start = 0.20 ; stop = 0.80 ; step = 0.03\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "plotModelConvergenceStudy(\n",
        "    top_n_modelChoices,\n",
        "    splitList,\n",
        "    convDict= HF_krig_convDict,\n",
        "    fidelityLevel='HF',\n",
        "    modelChoice='krig',\n",
        "    peakMiss = 'median')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c5f0d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "twoLevelDictStructurePrint(HF_krig_convDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf673a73-43e4-42e8-b0b4-4a9ac2a6157c",
      "metadata": {
        "id": "cf673a73-43e4-42e8-b0b4-4a9ac2a6157c",
        "outputId": "d0712d6f-4cd0-4dda-8223-f8f147b2d722"
      },
      "outputs": [],
      "source": [
        "##### SKLEARN DATA SPLIT \n",
        "\n",
        "X = np.hstack(inputTrainingData)\n",
        "y = np.hstack(outputTrainingData)\n",
        "Y_names = np.hstack(outputTrainingNames)\n",
        "X_names = np.hstack(inputTrainingNames)\n",
        "originalIdx = np.arange(0,X.shape[0])\n",
        "\n",
        "X_train, X_test, y_train, y_test, M_inf_train, M_inf_test, trainIdx, testIdx = train_test_split(\n",
        "    X, y, M_inf, originalIdx, test_size=0.20, random_state=random_state)\n",
        "\n",
        "X_test, X_val, y_test, y_val, M_inf_test, M_inf_val, testIdx, valIdx = train_test_split(\n",
        "    X_test, y_test, M_inf_test, testIdx, test_size=0.50, random_state=random_state)\n",
        "# M_inf_train, M_inf_test = train_test_split(M_inf,test_size=0.20,random_state=random_state) # used in plotting\n",
        "# M_inf_test, M_inf_val = train_test_split(M_inf_test,test_size=0.50,random_state=random_state) # used in plotting\n",
        "\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))\n",
        "print(\"X_val shape: {}\".format(X_val.shape))\n",
        "print(\"y_val shape: {}\".format(y_val.shape))\n",
        "print(f\"concatenation order: {X_names}\")\n",
        "print(f\"concatenation order: {Y_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c070cfcb-82ea-4092-b0ed-3f4dd499bf11",
      "metadata": {
        "id": "c070cfcb-82ea-4092-b0ed-3f4dd499bf11",
        "tags": []
      },
      "source": [
        "# HF Kriging (Gaussian Process, or GP)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce595305-5bf2-4324-abe9-2ca59928d8c5",
      "metadata": {
        "id": "ce595305-5bf2-4324-abe9-2ca59928d8c5"
      },
      "source": [
        "## Gaussian Process Kernels\n",
        "What kernels do/how to select kernels:\n",
        "\n",
        "[The Kernel Cookbook: Advice on Covariance functions](https://www.cs.toronto.edu/~duvenaud/cookbook/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1426e335",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"High Fidelity Kriging\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ad90222-d646-4706-803d-e949e0febc61",
      "metadata": {
        "id": "9ad90222-d646-4706-803d-e949e0febc61"
      },
      "outputs": [],
      "source": [
        "kernel2 = 66.3*RBF(0.1, (1e-9, 1e2)) + WhiteKernel(noise_level=1) #seems to work well for discontinuities on the analytical functions\n",
        "kernel = 1.0*Matern(length_scale=0.1, nu=1.5)\n",
        "\n",
        "# Generated on 4Jul22\n",
        "HFoptimizedKernel1 = 2.28**2 * RBF(length_scale=3.09) + WhiteKernel(noise_level=0.002)\n",
        "HFoptimizedKernel2 = 1.54**2 * Matern(length_scale=3.7, nu=2.5)\n",
        "HFoptimizedKernel3 = 2.75**2 * RBF(length_scale=3.48) + WhiteKernel(noise_level=0.00161)\n",
        "\n",
        "HFoptimizedKernel = 2.75**2 * RBF(length_scale=3.48) + WhiteKernel(noise_level=0.00161)\n",
        "\n",
        "# Below are the different kernels (and combinations of kernels) that Dr. Reasor used in his code\n",
        "\n",
        "#kernel = ConstantKernel(1.0) + Matern(length_scale=0.1, nu=3/2) #+ WhiteKernel(noise_level=1)\n",
        "#kernel = 1.0*Matern(length_scale=0.1, nu=1.5)\n",
        "#kernel = RationalQuadratic()\n",
        "#kernel = Matern(length_scale=0.1, nu=2.5)  #\n",
        "#kernel = ConstantKernel(1.0, (1e-8, 1e2)) * RBF(0.1, (1e-8, 1e2))\n",
        "#kernel = Cdatetime.dateonstantKernel(1.0, (1e-3, 1e3))*RBF(1.0, (1e-2, 1e2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "517401b7-79eb-4976-b094-790d686c7af7",
      "metadata": {
        "id": "517401b7-79eb-4976-b094-790d686c7af7",
        "tags": []
      },
      "source": [
        "## Gaussian Process (using sklearn's gaussian_process)\n",
        "\n",
        "*Building our multi-fidelity kriging the ol' fashioned way* \n",
        "\n",
        "This module provides the user control over the hyperparameters (specifically the kernels, n restarts optimizer), but is a bit more abstract that GPy, which is why it was chosen over other GP modules (like GPy). \n",
        "\n",
        "kernel: class-kernel instance, default=None\n",
        "The kernel specifying the covariance function of the GP. If None is passed, the kernel ConstantKernel(1.0, constant_value_bounds=\"fixed\" * RBF(1.0, length_scale_bounds=\"fixed\") is used as default. Note that the kernel hyperparameters are optimized during fitting unless the bounds are marked as “fixed”.\n",
        "\n",
        "n_restarts_optimizer: class-int, default=0\n",
        "The number of restarts of the optimizer for finding the kernel’s parameters which maximize the log-marginal likelihood. The first run of the optimizer is performed from the kernel’s initial parameters, the remaining ones (if any) from thetas sampled log-uniform randomly from the space of allowed theta-values. If greater than 0, all bounds must be finite. Note that n_restarts_optimizer == 0 implies that one run is performed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88accb88-1c35-445e-bffb-9bb75a104682",
      "metadata": {
        "id": "88accb88-1c35-445e-bffb-9bb75a104682"
      },
      "source": [
        "$\\textit{Some words about multi-output Kriging} $\n",
        "\n",
        "Multi-input, multi-output Kriging\n",
        "\n",
        "\"At the heart of your issue lies something rarely mentioned (or even hinted at) in practice and in relevant tutorials: Gaussian Process regression with multiple outputs is highly non-trivial and still a field of active research. Arguably, scikit-learn cannot really handle the case, despite the fact that it will superficially appear to do so, without issuing at least some relevant warning.\"\n",
        "\n",
        "https://stackoverflow.com/questions/50185399/multiple-output-gaussian-process-regression-in-scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c54dd8f-04e4-4500-90c9-1371d5226185",
      "metadata": {
        "id": "3c54dd8f-04e4-4500-90c9-1371d5226185"
      },
      "source": [
        "## Building the GP Model and Fitting the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50266ed4-54c3-4e87-94b5-d3de5332ac3d",
      "metadata": {
        "id": "50266ed4-54c3-4e87-94b5-d3de5332ac3d"
      },
      "outputs": [],
      "source": [
        "if HFKrigTrain:\n",
        "    krigTrain(\n",
        "        X_train=X_train,\n",
        "        y_train=y_train, \n",
        "        fidelityLevel='HF',\n",
        "        kernel=HFoptimizedKernel, \n",
        "        n_restarts = 1,\n",
        "        verbose=True\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3c3b27",
      "metadata": {},
      "outputs": [],
      "source": [
        "if HFKrigOptimize:\n",
        "    longKernel = 34.4**2 * RBF(length_scale=41.8) \\\n",
        "    + 3.27**2 * RBF(length_scale=180) \\\n",
        "        * ExpSineSquared(length_scale=1.44, periodicity=1) \\\n",
        "        + 0.446**2 * RationalQuadratic(alpha=17.7, length_scale=0.957) \\\n",
        "            + 0.197**2 * RBF(length_scale=0.138) + WhiteKernel(noise_level=0.0336)\n",
        "\n",
        "    kernels = [\n",
        "    100 * RBF(length_scale=0.1, length_scale_bounds=(1e-1, 10.0)),\n",
        "    2.44**2 * RBF(length_scale=2.41),\n",
        "    1.0 * RationalQuadratic(length_scale=1.0, alpha=0.1),\n",
        "    ConstantKernel(0.1, (0.01, 10.0)) * (DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0)) ** 2),\n",
        "    1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0),nu=2.5),\n",
        "    ConstantKernel(1.0) + Matern(length_scale=0.1, nu=3/2) + WhiteKernel(noise_level=1),\n",
        "    HFoptimizedKernel\n",
        "    #]\n",
        "    #longKernel\n",
        "    ]\n",
        "\n",
        "    HFerrorCompDataFrame, HFerrorDict, HFmodelDict = optimizeKrig(\n",
        "        kernelList = kernels,\n",
        "        X_train = X_train, \n",
        "        y_train = y_train, \n",
        "        X_test = X_test,\n",
        "        y_test = y_test,\n",
        "        fidelityLevel = \"HF\",\n",
        "        method = \"krig\",\n",
        "        n_restarts = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db860f01-a7b2-4f0c-a923-ebca861af621",
      "metadata": {
        "id": "db860f01-a7b2-4f0c-a923-ebca861af621"
      },
      "source": [
        "## Saving or loading your models\n",
        "\n",
        "The larger your data gets, and the longer the train time gets, the more you may be interested in saving/loading a pre-trained model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b88b2134-f056-44a5-913f-662ecf8accfd",
      "metadata": {
        "id": "b88b2134-f056-44a5-913f-662ecf8accfd"
      },
      "outputs": [],
      "source": [
        "## Saving your model\n",
        "if HFKrigSave:\n",
        "\n",
        "    saveKrig(fidelityLevel='HF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "711e1ef0-666c-4f02-b14f-731d3c386169",
      "metadata": {
        "id": "711e1ef0-666c-4f02-b14f-731d3c386169"
      },
      "outputs": [],
      "source": [
        "# some time later... load the model from disk\n",
        "if HFKrigLoad:\n",
        "    os.chdir(path)\n",
        "    os.chdir(modelDir + '/' + krigDir)\n",
        "    filename = 'HF_krig_2022-06-15.sav'\n",
        "    desiredLoadedModelName = 'HF_krig_loaded'\n",
        "\n",
        "    HF_krig = pickle.load(open(filename, 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3170d7bf-d445-4f80-8758-94ed41a4c8fc",
      "metadata": {
        "id": "3170d7bf-d445-4f80-8758-94ed41a4c8fc",
        "tags": []
      },
      "source": [
        "## Inverse Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2967da6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "generateInverseTransformedPredictions(\n",
        "    X_train = X_train,\n",
        "    X_test = X_test,\n",
        "    y_train = y_train,\n",
        "    y_test = y_test,\n",
        "    method = 'kriging',\n",
        "    fidelityLevel = 'HF',\n",
        "    verbose = True,\n",
        "    truncate=False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed8be07",
      "metadata": {},
      "outputs": [],
      "source": [
        "# peakHeatPredict = np.amax(qw_HF_krig_test_predict, axis=1)\n",
        "# peakHeatTruth = np.amax(qw_HF_test_truth, axis=1)\n",
        "\n",
        "# print(peakHeatPredict[0],peakHeatTruth[0])\n",
        "# x1=peakHeatPredict[0]; x2 = peakHeatTruth[0]\n",
        "# print(abs(((x1-x2)/x1)*100))\n",
        "\n",
        "# x1=peakHeatPredict; x2 = peakHeatTruth\n",
        "# mean = np.mean((x1,x2),axis=0)\n",
        "# percentDifference = abs(((x1-x2)/mean)*100)\n",
        "# np.sort(percentDifference)[::-1]\n",
        "# print(np.mean(percentDifference),np.median(percentDifference))\n",
        "\n",
        "# np.median(percentdifferencecalc(peakHeatTruth,peakHeatPredict))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a63f67e0-6e3b-4d4a-88ed-71ca155467d1",
      "metadata": {
        "id": "a63f67e0-6e3b-4d4a-88ed-71ca155467d1"
      },
      "source": [
        "## Analyze Our Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6efb4591",
      "metadata": {},
      "source": [
        "### Input Space Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc57d7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plt.hist( T_inf, alpha=0.5, histtype='bar', ec='black' )\n",
        "# plt.xlabel(\"Freestream Temperature\")\n",
        "# plt.ylabel(\"Number of cases\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51747d28",
      "metadata": {},
      "outputs": [],
      "source": [
        "errorList = []\n",
        "totalTestCases = X_test.shape[0]\n",
        "\n",
        "# rmse = mean_squared_error(truth, prediction, squared=False)\n",
        "\n",
        "for case in np.arange(totalTestCases):\n",
        "    p_nrmse = normalizedRootMeanSquaredError(p_HF_test_truth[case], p_HF_krig_test_predict[case])\n",
        "    qw_nrmse = normalizedRootMeanSquaredError(qw_HF_test_truth[case], qw_HF_krig_test_predict[case])\n",
        "    # p_score = r2_score(p_HF_test_truth[case], p_HF_krig_test_predict[case])\n",
        "    # qw_score = r2_score(qw_HF_test_truth[case], qw_HF_krig_test_predict[case])\n",
        "    score = np.mean((p_nrmse, qw_nrmse))\n",
        "    errorList.append(score)\n",
        "\n",
        "#     caseList = [testIdx, trainIdx]\n",
        "\n",
        "plotInputSpaceErrorColorMap(\n",
        "    testIdxArray = testIdx,\n",
        "    trainIdxArray = trainIdx,\n",
        "    inputVarNameList=inputVarNameList,\n",
        "    errorList = errorList,\n",
        "    logPlot = False,\n",
        "    topErrorValuesToPlot= 10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed5b363",
      "metadata": {},
      "outputs": [],
      "source": [
        "[HF_krig_NRMSE_pressure, HF_krig_R2_pressure] = errorMetrics(\n",
        "    truth = p_HF_test_truth,\n",
        "    prediction = p_HF_krig_test_predict,\n",
        "    fidelity = 'HF',\n",
        "    model = 'Kriging',\n",
        "    variable = 'Pressure',\n",
        "    verbose = True)\n",
        "\n",
        "[HF_krig_NRMSE_heatTransfer, HF_krig_R2_heatTransfer] = errorMetrics(\n",
        "    truth = qw_HF_test_truth,\n",
        "    prediction = qw_HF_krig_test_predict,\n",
        "    fidelity = 'HF',\n",
        "    model = 'Kriging',\n",
        "    variable = 'Heat Transfer',\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da9e6c3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "caseList = [testIdx, trainIdx]\n",
        "\n",
        "plotInputSpace(\n",
        "    caseList= caseList,\n",
        "    inputVarNameList=inputVarNameList\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d880dd1-5d50-414a-ba51-42bae38cef78",
      "metadata": {
        "id": "5d880dd1-5d50-414a-ba51-42bae38cef78",
        "outputId": "c5f3258a-a55f-4842-9fa0-31a5c859533b"
      },
      "outputs": [],
      "source": [
        "oneToOnePlotTool(method='Kriging', \n",
        "                 desiredNumCasesForPlot=10, \n",
        "                 X_test=X_test, \n",
        "                 qw_prediction = qw_HF_krig_test_predict, \n",
        "                 qw_truth = qw_HF_test_truth, \n",
        "                 p_prediction = p_HF_krig_test_predict, \n",
        "                 p_truth = p_HF_test_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4f49141-cae0-450f-ac93-d33fbd3a228c",
      "metadata": {
        "id": "a4f49141-cae0-450f-ac93-d33fbd3a228c"
      },
      "source": [
        "plt.fill_between(\n",
        "    X.ravel(),\n",
        "    mean_prediction - 1.96 * std_prediction,\n",
        "    mean_prediction + 1.96 * std_prediction,\n",
        "    alpha=0.5,\n",
        "    label=r\"95% confidence interval\",\n",
        ")\n",
        "https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html#sphx-glr-auto-examples-gaussian-process-plot-gpr-noisy-targets-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a484653-6ef8-4e8b-9468-8cf190ff47f2",
      "metadata": {
        "id": "4a484653-6ef8-4e8b-9468-8cf190ff47f2",
        "outputId": "6c2b57ba-db65-4985-d592-f96b41d580c6"
      },
      "outputs": [],
      "source": [
        "plotPressureHeatTransferSideBySide(\n",
        "    case = 11,\n",
        "    qw_test_predict = qw_HF_krig_test_predict,\n",
        "    p_test_predict = p_HF_krig_test_predict,\n",
        "    qw_test_truth = qw_HF_test_truth,\n",
        "    p_test_truth = p_HF_test_truth,\n",
        "    method = 'Kriging')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c07afb82-5143-4209-a4d3-6c5da1370d9e",
      "metadata": {
        "id": "c07afb82-5143-4209-a4d3-6c5da1370d9e",
        "tags": []
      },
      "source": [
        "## Mean Predicition and Truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec0deae4-9d54-4c7d-b392-32303628b4b0",
      "metadata": {
        "id": "ec0deae4-9d54-4c7d-b392-32303628b4b0",
        "outputId": "c9e8cb46-e828-4b26-c8e3-63b63019d0d8"
      },
      "outputs": [],
      "source": [
        "plotAverageDistributions(\n",
        "    qw_test_predict = qw_HF_krig_test_predict,\n",
        "    p_test_predict = p_HF_krig_test_predict, \n",
        "    qw_test_truth = qw_HF_test_truth, \n",
        "    p_test_truth = p_HF_test_truth, \n",
        "    method = 'Kriging',\n",
        "    fidelityLevel = 'HF')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d0ad813-3f39-4c11-9945-05c38c0e385b",
      "metadata": {
        "id": "9d0ad813-3f39-4c11-9945-05c38c0e385b"
      },
      "source": [
        "## One to One Plot Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e049042d-eae8-43f2-a720-cd56be3ab1cb",
      "metadata": {
        "id": "e049042d-eae8-43f2-a720-cd56be3ab1cb"
      },
      "source": [
        "https://stackoverflow.com/questions/33275189/how-can-i-make-points-of-a-python-plot-appear-over-time?noredirect=1&lq=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4dbcbd5-3e44-4370-ad91-d2253e61cb3a",
      "metadata": {
        "id": "f4dbcbd5-3e44-4370-ad91-d2253e61cb3a",
        "outputId": "a14855c0-ab03-46ab-faf6-4208d0f0adb8"
      },
      "outputs": [],
      "source": [
        "oneToOneVisualizationPlotAllData(\n",
        "    case = 12, \n",
        "    qw_test_predict = qw_HF_krig_test_predict,\n",
        "    p_test_predict = p_HF_krig_test_predict,\n",
        "    qw_test_truth = qw_HF_test_truth, \n",
        "    p_test_truth = p_HF_test_truth, \n",
        "    M_inf_test = M_inf_test,\n",
        "    method = 'HF Kriging'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d623bfc-a106-4bcd-bf3b-524af5f8e68a",
      "metadata": {
        "id": "9d623bfc-a106-4bcd-bf3b-524af5f8e68a",
        "tags": []
      },
      "source": [
        "# HF Artificial Neural Network\n",
        "Below are the functions that create and train the Neural Network models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cafd0e46",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"High Fidelity Neural Network\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb2bf9c2",
      "metadata": {},
      "source": [
        "## Optimize Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "551899e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n_modelChoices = [ \n",
        "        [56, 80],\n",
        "        [64, 80, 80],\n",
        "        ] \n",
        "start = 0.20 ; stop = 0.80 ; step = 0.2\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "hyperparamDict = {\n",
        "    \"learningRate\" : 1.0e-3,\n",
        "    \"regType\" : keras.regularizers.L2,\n",
        "    \"regValue\" : 1.0e-6,\n",
        "    \"hiddenLayerActivation\" : tf.nn.tanh,\n",
        "    \"outputLayerActivation\" : tf.nn.leaky_relu,\n",
        "    \"kernelInitializer\" : tf.keras.initializers.GlorotUniform(),\n",
        "    \"optimizer\" : tf.keras.optimizers.Adamax,\n",
        "    \"numEpochs\" : 5,\n",
        "    \"myBatchSize\" : 224,\n",
        "    \"loss\" : 'mse'\n",
        "}\n",
        "\n",
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor = \"val_mean_squared_error\",mode=\"min\",\n",
        "        patience=200, verbose=0,\n",
        "        restore_best_weights=False \n",
        "        )\n",
        "    ]\n",
        "\n",
        "_ = modelConvergenceStudy(\n",
        "    fidelityLevel= 'HF', \n",
        "    modelType= 'NN',\n",
        "    M_inf=M_inf,\n",
        "    inputTrainingData=inputTrainingData,\n",
        "    outputTrainingData=outputTrainingData,\n",
        "    inputTrainingNames=inputTrainingNames,\n",
        "    outputTrainingNames=outputTrainingNames,\n",
        "    top_n_modelChoices=top_n_modelChoices,\n",
        "    splitList=splitList,\n",
        "    verbose=False,\n",
        "    hyperparamDict=hyperparamDict,\n",
        "    callbacks_list=callbacks_list,\n",
        "    n_restarts=None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5929a65f",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n_modelChoices = [ \n",
        "        [56, 80],\n",
        "        [64, 80, 80],\n",
        "        [40, 56, 64]\n",
        "        ] \n",
        "start = 0.20 ; stop = 0.80 ; step = 0.03\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "hyperparamDict = {\n",
        "    \"learningRate\" : 1.0e-3,\n",
        "    \"regType\" : keras.regularizers.L2,\n",
        "    \"regValue\" : 1.0e-6,\n",
        "    \"hiddenLayerActivation\" : tf.nn.tanh,\n",
        "    \"outputLayerActivation\" : tf.nn.leaky_relu,\n",
        "    \"kernelInitializer\" : tf.keras.initializers.GlorotUniform(),\n",
        "    \"optimizer\" : tf.keras.optimizers.Adamax,\n",
        "    \"numEpochs\" : 7000,\n",
        "    \"myBatchSize\" : 224,\n",
        "    \"loss\" : 'mse'\n",
        "}\n",
        "\n",
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor = \"val_mean_squared_error\",mode=\"min\",\n",
        "        patience=200, verbose=0,\n",
        "        restore_best_weights=False \n",
        "        )\n",
        "    ]\n",
        "\n",
        "HF_NN_modelConvergenceDict = modelConvergenceStudy(\n",
        "    fidelityLevel= 'HF', \n",
        "    modelType= 'NN',\n",
        "    M_inf=M_inf,\n",
        "    inputTrainingData=inputTrainingData,\n",
        "    outputTrainingData=outputTrainingData,\n",
        "    inputTrainingNames=inputTrainingNames,\n",
        "    outputTrainingNames=outputTrainingNames,\n",
        "    top_n_modelChoices=top_n_modelChoices,\n",
        "    splitList=splitList,\n",
        "    verbose=False,\n",
        "    hyperparamDict=hyperparamDict,\n",
        "    callbacks_list=callbacks_list,\n",
        "    n_restarts=None\n",
        "    )\n",
        "\n",
        "# twoLevelDictStructurePrint(HF_NN_modelConvergenceDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5333a705",
      "metadata": {},
      "outputs": [],
      "source": [
        "twoLevelDictStructurePrint(HF_NN_modelConvergenceDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4acfa08d",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n_modelChoices = [ \n",
        "        [56, 80],\n",
        "        [64, 80, 80],\n",
        "        [40, 56, 64]\n",
        "        ] \n",
        "start = 0.20 ; stop = 0.80 ; step = 0.03\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "plotModelConvergenceStudy(\n",
        "    top_n_modelChoices,\n",
        "    splitList,\n",
        "    convDict= HF_NN_modelConvergenceDict,\n",
        "    fidelityLevel='HF',\n",
        "    modelChoice='NN',\n",
        "    peakMiss = 'median')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b41c9e14",
      "metadata": {},
      "outputs": [],
      "source": [
        "if HFNNConvergence:\n",
        "    callbacks_list = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor = \"val_mean_squared_error\",mode=\"min\",\n",
        "            patience=200, verbose=0,\n",
        "            restore_best_weights=False \n",
        "            )\n",
        "        ]\n",
        "\n",
        "    convStudyLayerList = [ \n",
        "        # [64],\n",
        "        # [72],\n",
        "        # [80],\n",
        "        # [40, 32],\n",
        "        # [32, 64],\n",
        "        # [56, 72],\n",
        "        [56, 80],\n",
        "        [80, 80],\n",
        "        [64, 80, 80],\n",
        "        [48, 56, 40],\n",
        "        # [64, 80, 32],\n",
        "        [40, 56, 64],\n",
        "        [80, 80, 80],\n",
        "        [32, 64, 96, 128],\n",
        "        [32, 32+8, + 32+8+8, 32+8+8+8, 32+8+8+8]\n",
        "        # [32, 64, 128],\n",
        "        # [64, 128, 128+32]\n",
        "        ] \n",
        "\n",
        "\n",
        "    hyperparamDict = {\n",
        "        \"learningRate\" : 1.0e-3,\n",
        "        \"regType\" : keras.regularizers.L2,\n",
        "        \"regValue\" : 1.0e-6,\n",
        "        \"hiddenLayerActivation\" : tf.nn.tanh,\n",
        "        \"outputLayerActivation\" : tf.nn.leaky_relu,\n",
        "        \"kernelInitializer\" : tf.keras.initializers.GlorotUniform(),\n",
        "        \"optimizer\" : tf.keras.optimizers.Adamax,\n",
        "        \"numEpochs\" : 10000,\n",
        "        \"myBatchSize\" : 224,\n",
        "        \"loss\" : 'mse'\n",
        "    }\n",
        "    validData = (X_test, y_test)\n",
        "\n",
        "    neuralNetworkConvergence(\n",
        "        fidelityLevel='HF',\n",
        "        convStudyLayerList = convStudyLayerList,\n",
        "        hyperparamDict = hyperparamDict,\n",
        "        X_train = X_train,\n",
        "        y_train = y_train,\n",
        "        validData = validData,\n",
        "        callbacks_list = callbacks_list,\n",
        "        verbose = True,\n",
        "        showConvPlot = True,\n",
        "        saveConvPlot = True,\n",
        "        showMSEplot = True,\n",
        "        saveMSEplot = True,\n",
        "        showSpeedPlot = True,\n",
        "        saveSpeedPlot = True\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1dd7d9-5f82-462a-973c-32d0e893d4d4",
      "metadata": {
        "id": "3e1dd7d9-5f82-462a-973c-32d0e893d4d4"
      },
      "source": [
        "## Build Model and Plot Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f5b6322-020f-4156-8709-72196a2213bd",
      "metadata": {
        "id": "8f5b6322-020f-4156-8709-72196a2213bd",
        "outputId": "de9be3f9-6a9e-469c-dd12-7099ed1a0210",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Initialize hyperparamters for Single Fidelity Model\n",
        "if HFNNTrain: \n",
        "    highFidelityLayerSizeList = [56, 80] #input the number of neurons per layer. Length of this list indicates number of hidden layers\n",
        "    learningRate = 1.0e-3 #From Deep Learning w/ Python (Chollet)\n",
        "    regType = keras.regularizers.L2\n",
        "    regValue = 1.0e-6\n",
        "    hiddenLayerActivation = tf.nn.tanh\n",
        "    outputLayerActivation = tf.nn.leaky_relu\n",
        "    kernelInitializer = tf.keras.initializers.GlorotUniform()\n",
        "    optimizer = tf.keras.optimizers.Adamax\n",
        "    numEpochs = 5000\n",
        "    if quickTestRun:\n",
        "        numEpochs = 10\n",
        "    myBatchSize = None\n",
        "    validSplit = None\n",
        "    loss = 'mse'\n",
        "    validData = (X_test, y_test)\n",
        "\n",
        "    callbacks_list = None\n",
        "\n",
        "    HF_NN = None #sometimes remnants of previously trained models can hang around, it's best \n",
        "                #to clear the variable first \n",
        "\n",
        "    HF_NN = build_model_parameterized(\n",
        "        input_data = X_train, \n",
        "        output_data = y_train,\n",
        "        layerSizeList = highFidelityLayerSizeList, \n",
        "        rate = learningRate, \n",
        "        regType = regType, \n",
        "        regValue = regValue,\n",
        "        hiddenLayerActivation = hiddenLayerActivation,\n",
        "        outputLayerActivation = outputLayerActivation,\n",
        "        outputLayerDataType='float32',\n",
        "        kernelInitializer = kernelInitializer,\n",
        "        optimizer = optimizer,\n",
        "        loss = loss)\n",
        "kerasPlotModel(model=HF_NN,fidelityLevel='HF')\n",
        "HF_NN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44e20e6e-fc9d-4cc0-8081-fc2b18a2e668",
      "metadata": {
        "id": "44e20e6e-fc9d-4cc0-8081-fc2b18a2e668"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d994372e-20e1-401a-9335-354d5db0c7c2",
      "metadata": {
        "id": "d994372e-20e1-401a-9335-354d5db0c7c2",
        "outputId": "419c75e0-5559-4a11-dcad-4e29e37754cf"
      },
      "outputs": [],
      "source": [
        "if HFNNTrain: \n",
        "\n",
        "    HF_NN_epochs = None\n",
        "    HF_NN_history = None\n",
        "    print('HF NN training start')\n",
        "    start = time.time()\n",
        "    HF_NN_epochs, HF_NN_history = train_model_all_fidelity(\n",
        "        model = HF_NN, \n",
        "        input_data = X_train, \n",
        "        output_data = y_train,\n",
        "        numEpochs = numEpochs, \n",
        "        myBatchSize = myBatchSize,\n",
        "        validData = validData,\n",
        "        callbacks_list= callbacks_list)\n",
        "    end = time.time()\n",
        "    print('HF NN training complete. Time to train:')\n",
        "    print(round((end-start),4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab638b4b-7599-45fd-a1d3-49e3a6da48be",
      "metadata": {
        "id": "ab638b4b-7599-45fd-a1d3-49e3a6da48be"
      },
      "source": [
        "### Save NN, History, and Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "954da572-bfd0-4a9e-a382-c4b8326b6580",
      "metadata": {
        "id": "954da572-bfd0-4a9e-a382-c4b8326b6580",
        "outputId": "efd2b7e5-886d-48a8-b9ee-ff1839c45ff3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "if HFNNSave:\n",
        "    saveNN(fidelityLevel='HF')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5825af9-1083-4621-8487-6a2a2617d080",
      "metadata": {
        "id": "f5825af9-1083-4621-8487-6a2a2617d080"
      },
      "source": [
        "### Load NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c964ea9-3e4d-4c97-b02a-08920bc05c0e",
      "metadata": {
        "id": "7c964ea9-3e4d-4c97-b02a-08920bc05c0e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "if HFNNLoad: \n",
        "    loadNN(\n",
        "        neuralNetFolderName = 'HF_NN_2022-XX-XX'\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05b48b81-3907-4df6-8f0f-f2d2a59b5604",
      "metadata": {
        "id": "05b48b81-3907-4df6-8f0f-f2d2a59b5604"
      },
      "source": [
        "## Summary of Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2304378a-41ab-43ac-b579-a153ff927c49",
      "metadata": {
        "id": "2304378a-41ab-43ac-b579-a153ff927c49",
        "outputId": "cd88e710-db3b-4412-d066-ca15f3fb2737"
      },
      "outputs": [],
      "source": [
        "HF_NN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c63207a5-74f7-4638-a36f-eef627c9fecd",
      "metadata": {
        "id": "c63207a5-74f7-4638-a36f-eef627c9fecd"
      },
      "source": [
        "## Analyze Error (MSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c14e44-dc5d-4a86-9fc5-6e75a3538d41",
      "metadata": {
        "id": "41c14e44-dc5d-4a86-9fc5-6e75a3538d41",
        "outputId": "6a95f64a-f28c-40c6-a314-c043427f3a2f"
      },
      "outputs": [],
      "source": [
        "mseNames = [\"mean_squared_error\",\n",
        "            'val_mean_squared_error'\n",
        "            ]\n",
        "colorList = [ 'k', 'r']\n",
        "\n",
        "plotTrainAndTestLoss(historyDict = HF_NN_history,\n",
        "                     mseNames = mseNames,\n",
        "                     colorList = colorList,\n",
        "                     fidelityLevel = 'High Fidelity')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6feb729f-dbbe-46e1-943f-2895935d31d2",
      "metadata": {
        "id": "6feb729f-dbbe-46e1-943f-2895935d31d2"
      },
      "source": [
        "## Generate and Inverse Transform Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48c7e85",
      "metadata": {},
      "outputs": [],
      "source": [
        "generateInverseTransformedPredictions(\n",
        "    X_train = X_train,\n",
        "    X_test = X_test,\n",
        "    y_train = y_train,\n",
        "    y_test = y_test,\n",
        "    method = 'NN',\n",
        "    fidelityLevel = 'HF',\n",
        "    verbose = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "192c69dd-acf2-40d4-aedf-c1288a12f0e8",
      "metadata": {
        "id": "192c69dd-acf2-40d4-aedf-c1288a12f0e8"
      },
      "source": [
        "## Analyze Predictions\n",
        "For 20 cases, we have plotted the predicted value vs. the actual value. A perfect prediciton would be a straight line with a slope of 1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96709d61-3f5e-4d3d-bc97-71eb87cb1327",
      "metadata": {
        "id": "96709d61-3f5e-4d3d-bc97-71eb87cb1327",
        "outputId": "9cc5a8c4-2c96-4c5d-f2af-f46d92ac3ba0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "oneToOnePlotTool(method='Neural Network', \n",
        "                 desiredNumCasesForPlot=12, \n",
        "                 X_test=X_test, \n",
        "                 qw_prediction = qw_HF_NN_test_predict, \n",
        "                 qw_truth = qw_HF_test_truth, \n",
        "                 p_prediction = p_HF_NN_test_predict, \n",
        "                 p_truth = p_HF_test_truth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae0a8717",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "oneToOneVisualizationPlotAllData(\n",
        "    case = 12, \n",
        "    qw_test_predict = qw_HF_NN_test_predict,\n",
        "    p_test_predict = p_HF_NN_test_predict,\n",
        "    qw_test_truth = qw_HF_test_truth, \n",
        "    p_test_truth = p_HF_test_truth, \n",
        "    M_inf_test = M_inf_test,\n",
        "    method = 'HF Neural Network')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f29b10eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plotPressureHeatTransferSideBySide(\n",
        "    case = 11,\n",
        "    qw_test_predict = qw_HF_NN_test_predict,\n",
        "    p_test_predict = p_HF_NN_test_predict,\n",
        "    qw_test_truth = qw_HF_test_truth,\n",
        "    p_test_truth = p_HF_test_truth,\n",
        "    method = 'NN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39433c1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "errorList = []\n",
        "totalTestCases = X_test.shape[0]\n",
        "\n",
        "# rmse = mean_squared_error(truth, prediction, squared=False)\n",
        "\n",
        "for case in np.arange(totalTestCases):\n",
        "    p_nrmse = normalizedRootMeanSquaredError(p_HF_test_truth[case], p_HF_NN_test_predict[case])\n",
        "    qw_nrmse = normalizedRootMeanSquaredError(qw_HF_test_truth[case], qw_HF_NN_test_predict[case])\n",
        "    # p_score = r2_score(p_HF_test_truth[case], p_HF_krig_test_predict[case])\n",
        "    # qw_score = r2_score(qw_HF_test_truth[case], qw_HF_krig_test_predict[case])\n",
        "    score = np.mean((p_nrmse, qw_nrmse))\n",
        "    errorList.append(score)\n",
        "\n",
        "#     caseList = [testIdx, trainIdx]\n",
        "\n",
        "plotInputSpaceErrorColorMap(\n",
        "    testIdxArray = testIdx,\n",
        "    trainIdxArray = trainIdx,\n",
        "    inputVarNameList=inputVarNameList,\n",
        "    errorList = errorList,\n",
        "    logPlot = False,\n",
        "    topErrorValuesToPlot= 10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ad6ac2b-56c4-47f1-9b6d-55a86c9ea858",
      "metadata": {
        "id": "8ad6ac2b-56c4-47f1-9b6d-55a86c9ea858"
      },
      "source": [
        "## Mean Predicition and Truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8306a538-347c-43af-a856-57d6c962933b",
      "metadata": {
        "id": "8306a538-347c-43af-a856-57d6c962933b",
        "outputId": "e25434f8-cd15-46f2-ddf1-4e4f3ef7731d"
      },
      "outputs": [],
      "source": [
        "plotAverageDistributions(\n",
        "    qw_test_predict = qw_HF_NN_test_predict,\n",
        "    p_test_predict = p_HF_NN_test_predict,\n",
        "    qw_test_truth = qw_HF_test_truth,\n",
        "    p_test_truth = p_HF_test_truth,\n",
        "    method = 'NN',\n",
        "    fidelityLevel='HF')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbd07e77-136e-493b-9ebc-c8407cc84059",
      "metadata": {
        "id": "bbd07e77-136e-493b-9ebc-c8407cc84059",
        "tags": [],
        "toc-hr-collapsed": true
      },
      "source": [
        "# High Fidelity Error Metrics Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f81b7cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"High Fidelity Error Metrics\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfd22e18-375c-41c0-aac4-1871158ff8ec",
      "metadata": {
        "id": "dfd22e18-375c-41c0-aac4-1871158ff8ec",
        "outputId": "558f01c2-4539-405e-fb4a-60f82a36b392"
      },
      "outputs": [],
      "source": [
        "[HF_krig_NRMSE_pressure, HF_krig_R2_pressure] = errorMetrics(\n",
        "    truth = p_HF_test_truth,\n",
        "    prediction = p_HF_krig_test_predict,\n",
        "    fidelity = 'HF',\n",
        "    model = 'Kriging',\n",
        "    variable = 'Pressure',\n",
        "    verbose = True)\n",
        "\n",
        "[HF_krig_NRMSE_heatTransfer, HF_krig_R2_heatTransfer] = errorMetrics(\n",
        "    truth = qw_HF_test_truth,\n",
        "    prediction = qw_HF_krig_test_predict,\n",
        "    fidelity = 'HF',\n",
        "    model = 'Kriging',\n",
        "    variable = 'Heat Transfer',\n",
        "    verbose = True)\n",
        "\n",
        "[HF_NN_NRMSE_pressure, HF_NN_R2_pressure] = errorMetrics(\n",
        "    truth = p_HF_test_truth,\n",
        "    prediction = p_HF_NN_test_predict,\n",
        "    fidelity = 'HF',\n",
        "    model = 'NN',\n",
        "    variable = 'Pressure',\n",
        "    verbose = True)\n",
        "\n",
        "[HF_NN_NRMSE_heatTransfer, HF_NN_R2_heatTransfer] = errorMetrics(\n",
        "    truth = qw_HF_test_truth,\n",
        "    prediction = qw_HF_NN_test_predict,\n",
        "    fidelity = 'HF',\n",
        "    model = 'NN',\n",
        "    variable = 'Heat Transfer',\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "698f6f47-209a-4caf-b07b-34fc0953d075",
      "metadata": {
        "id": "698f6f47-209a-4caf-b07b-34fc0953d075"
      },
      "source": [
        "# Multi-Fidelity Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb598c3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"Multi Fidelity Kriging\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03c6dec2-c587-4da9-886b-cf5041fb122c",
      "metadata": {
        "id": "03c6dec2-c587-4da9-886b-cf5041fb122c"
      },
      "source": [
        "## MF Kriging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61244c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "highFidelityDataGenAndProcess(verbose=True)\n",
        "downsample = False\n",
        "if downsample:\n",
        "    print(\"Truncated data set in MF data concat AKA downsampled\") \n",
        "    lowFidelityKriging_input = LF_krig.predict(X)\n",
        "    numOutputVars = len(LFoutputVarNames)\n",
        "\n",
        "    #first step, split the generated output into separate fluid scalar variables. \n",
        "    for i, name in enumerate(LFoutputVarNames):\n",
        "        tempVarName = name + '_krigPredicted'\n",
        "        globals()[tempVarName] = np.hsplit(lowFidelityKriging_input, numOutputVars)[i]\n",
        "        print(tempVarName, 'created.')\n",
        "\n",
        "    #Data will be downsampled to two points. One point on the cone and one point on the flare. These values will need to be chosen by the engineer using this code--they won't generalize \n",
        "\n",
        "    ##################################################\n",
        "    ####### Heat Flux and Pressure Downsample ########\n",
        "    ################################################## \n",
        "    conePoint = 2.0\n",
        "    flarePoint = 2.49\n",
        "    xLocationPressureValue1 = (np.abs(x_cc_windowed[0,:] - conePoint)).argmin()\n",
        "    xLocationPressureValue2 = (np.abs(x_cc_windowed[0,:] - flarePoint)).argmin()\n",
        "\n",
        "    indices = [xLocationPressureValue1, xLocationPressureValue2]\n",
        "    downsampledPressure = np.take(p_LF_krigPredicted, indices, axis=1)\n",
        "    downsampledHeatFlux = np.take(qw_LF_krigPredicted, indices, axis=1)\n",
        "    x_downsampledPressure = np.take(x_cc_windowed, indices, axis=1)\n",
        "    print('Low fidelity pressure data compression: ', p_LF.shape[1], ' to --> ', downsampledPressure.shape[1])\n",
        "    print('Low fidelity heat flux data compression: ', qw_LF.shape[1], ' to --> ', downsampledHeatFlux.shape[1])\n",
        "\n",
        "    lowFidelityKriging_input = np.concatenate((downsampledHeatFlux, downsampledPressure), axis=1)\n",
        "    multiFidelityKrig_input = np.concatenate((X,lowFidelityKriging_input),\n",
        "                                    axis = 1)\n",
        "    print('Shape of multiFidelityKrig_input: ' , multiFidelityKrig_input.shape)\n",
        "    \n",
        "    ################################################################\n",
        "    ####### Verification of accurate binary data assumption ########\n",
        "    ################################################################\n",
        "\n",
        "    leftsideIndex = xSpotLeft - 2\n",
        "    rightsideIndex = xSpotLeft + 2\n",
        "\n",
        "    leftMean = np.mean(qw_LF_krigPredicted[:,:leftsideIndex],axis=1).reshape(-1,1)\n",
        "    rightMean = np.mean(qw_LF_krigPredicted[:,rightsideIndex:],axis=1).reshape(-1,1)\n",
        "    leftData = qw_LF_krigPredicted[:,:leftsideIndex]\n",
        "    rightData = qw_LF_krigPredicted[:,rightsideIndex:]\n",
        "\n",
        "    leftMeanSubtracted = leftData - leftMean\n",
        "    rightMeanSubtracted = rightData - rightMean\n",
        "\n",
        "    print(\"Number of data points with great than 1e-10 difference from mean, left side: \", leftMeanSubtracted[leftMeanSubtracted>1e-10].shape)\n",
        "    print(\"Number of data points with great than 1e-10 difference from mean, right side: \", rightMeanSubtracted[rightMeanSubtracted>1e-10].shape)\n",
        "\n",
        "    print(\"Number of data points with great than 1e-11 difference from mean, left side: \", leftMeanSubtracted[leftMeanSubtracted>1e-11].shape)\n",
        "    print(\"Number of data points with great than 1e-11 difference from mean, right side: \", rightMeanSubtracted[rightMeanSubtracted>1e-11].shape)\n",
        "\n",
        "else:\n",
        "    print(\"Either full data set used, or LF Krig is already implicitly \\\"downsampled.\\\" AKA the output of the LF Krig model is truncated already\") \n",
        "    lowFidelityKriging_input = LF_krig.predict(X)\n",
        "    multiFidelityKrig_input = np.concatenate((X,lowFidelityKriging_input),\n",
        "                                    axis = 1)\n",
        "    multiFidelityKrig_input.shape\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41599bac",
      "metadata": {},
      "source": [
        "### Downsample Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb41511",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# caseWePick = 23\n",
        "# numLFcases = qw_LF.shape[0]\n",
        "# caseWePick = random.randint(0,numLFcases)\n",
        "# maxqw = qw_LF[caseWePick,:].max()\n",
        "# maxp = p_LF[caseWePick,:].max()\n",
        "# plt.plot(x_cc_windowed[0,:],qw_LF_krigPredicted[caseWePick,:],label = 'Scaled Low Fidelity Heat Transfer', c='firebrick')\n",
        "# # plt.semilogy(x_cc_windowed[0,:],qw[caseWePick,:], label = 'Truth (RANS) Heat Transfer')\n",
        "# plt.scatter(x_downsampledPressure[0,:],tinydownsampledHeatFlux[caseWePick,:], label = 'Downsampled Low Fidelity Heat Transfer', s= 20, marker = \"v\", c='k', zorder=3 )\n",
        "# # plt.vlines(x_cc_windowed[0,xSpotLeft], ymin=-4,ymax=4)\n",
        "# plt.grid()\n",
        "# plt.xlabel('Location Along Double Cone Wall, $x$ (meters)')\n",
        "# plt.ylabel('Scaled Heat Transfer Rate ($q_{w, scaled}$)')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(x_cc_windowed[0,:],p_LF_krigPredicted[caseWePick,:],label = 'Scaled Low Fidelity Pressure')\n",
        "# # plt.semilogy(x_cc_windowed[0,:],p[caseWePick,:], label = 'Truth (RANS) Pressure')\n",
        "# plt.scatter(x_downsampledPressure[0,:],downsampledPressure[caseWePick,:], label = 'Downsampled Low Fidelity Pressure', s= 20, marker = \"v\", c='k', zorder=3 )\n",
        "# plt.grid()\n",
        "# plt.xlabel('Location Along Double Cone Wall, $x$ (meters)')\n",
        "# plt.ylabel('Scaled Wall Pressure ($P_{scaled}$)')\n",
        "# plt.legend()\n",
        "# caseWePick = random.randint(0,397)\n",
        "# mean_qw_LF = np.mean(qw_LF, axis=0)\n",
        "# std_qw_LF = np.std(qw_LF,axis=0)\n",
        "\n",
        "# mean_qw_LF = np.take(mean_qw_LF, indices, axis=0)\n",
        "# std_qw_LF = np.take(std_qw_LF, indices, axis=0)\n",
        "# qw_plot2 = x_downsampledHeatFlux * std_qw_LF\n",
        "# qw_plot3 = qw_plot2 + std_qw_LF\n",
        "\n",
        "# plt.plot(x_cc_windowed[caseWePick,:],qw_LF_krigPredicted[caseWePick,:], color = 'mediumseagreen')\n",
        "# plt.ylabel('Scaled Heat Flux $(mean = 0, std = 1)$')\n",
        "# plt.xlabel('Location Along Double Cone Wall, $x$ (meters)')\n",
        "# plt.figure()\n",
        "\n",
        "\n",
        "# # plt.ylabel('Mean Centered Heat Flux $(mean = 0)$')\n",
        "# # plt.xlabel('Location Along Double Cone Wall, $x$ (meters)')\n",
        "\n",
        "# # plt.figure()\n",
        "# plt.plot(x_downsampledHeatFlux[caseWePick,:],qw_plot3[caseWePick,:],color = 'firebrick', label = 'Original Heat Flux')\n",
        "# plt.plot(x_downsampledHeatFlux[caseWePick,:],qw_plot2[caseWePick,:], color = 'steelblue', label = 'Mean Centered Heat Flux')\n",
        "# plt.xlabel('Location Along Double Cone Wall, $x$ (meters)')\n",
        "# plt.ylabel('Heat Flux ($W/m^2$)')\n",
        "# plt.legend()\n",
        "# caseWePick = random.randint(0,397)\n",
        "# mean_qw_LF = np.mean(qw_LF, axis=0)\n",
        "# std_qw_LF = np.std(qw_LF,axis=0)\n",
        "# qw_plot2 = qw_LF - mean_qw_LF\n",
        "# qw_plot3 = qw_plot2 / std_qw_LF\n",
        "\n",
        "# plt.plot(x_cc_windowed[caseWePick,:],qw_LF[caseWePick,:])\n",
        "# plt.figure()\n",
        "# plt.plot(x_cc_windowed[caseWePick,:],qw_plot2[caseWePick,:])\n",
        "# plt.figure()\n",
        "# plt.plot(x_cc_windowed[caseWePick,:],qw_plot3[caseWePick,:])\n",
        "# # plt.plot(x_cc_windowed[caseWePick,:],qw_LF_Scaled[caseWePick,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f269c7ce",
      "metadata": {},
      "source": [
        "## Model Convergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87a2d2d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "highFidelityDataGenAndProcess(verbose=True)\n",
        "lowFidelityNN_input = LF_NN.predict(X)\n",
        "multiFidelityNN_input = np.concatenate((X,lowFidelityNN_input),\n",
        "                                axis = 1)\n",
        "print(multiFidelityNN_input.shape)\n",
        "\n",
        "multiFidelityNN_output = outputTrainingData\n",
        "multiFidelityNN_outputFlat = np.hstack(multiFidelityNN_output)\n",
        "print(multiFidelityNN_outputFlat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6070c54b",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n_modelChoices = [ \n",
        "        [56, 72],\n",
        "        [80, 80],\n",
        "        [40, 56, 64]\n",
        "        ] \n",
        "start = 0.20 ; stop = 0.80 ; step = 0.03\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "hyperparamDict = {\n",
        "    \"learningRate\" : 1.0e-3,\n",
        "    \"regType\" : keras.regularizers.L2,\n",
        "    \"regValue\" : 1.0e-6,\n",
        "    \"hiddenLayerActivation\" : tf.nn.tanh,\n",
        "    \"outputLayerActivation\" : tf.nn.leaky_relu,\n",
        "    \"kernelInitializer\" : tf.keras.initializers.GlorotUniform(),\n",
        "    \"optimizer\" : tf.keras.optimizers.Adamax,\n",
        "    \"numEpochs\" : 7000,\n",
        "    \"myBatchSize\" : 224,\n",
        "    \"loss\" : 'mse'\n",
        "}\n",
        "\n",
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor = \"val_mean_squared_error\",mode=\"min\",\n",
        "        patience=200, verbose=0,\n",
        "        restore_best_weights=False \n",
        "        )\n",
        "    ]\n",
        "\n",
        "MF_NN_modelConvergenceDict = modelConvergenceStudy(\n",
        "    fidelityLevel= 'MF', \n",
        "    modelType= 'NN',\n",
        "    M_inf=M_inf,\n",
        "    inputTrainingData=multiFidelityNN_input,\n",
        "    outputTrainingData=outputTrainingData,\n",
        "    inputTrainingNames=inputTrainingNames,\n",
        "    outputTrainingNames=outputTrainingNames,\n",
        "    top_n_modelChoices=top_n_modelChoices,\n",
        "    splitList=splitList,\n",
        "    frequencyData = False,\n",
        "    truncate=False,\n",
        "    verbose=False,\n",
        "    hyperparamDict=hyperparamDict,\n",
        "    callbacks_list=callbacks_list,\n",
        "    n_restarts=None\n",
        "    )\n",
        "\n",
        "# twoLevelDictStructurePrint(HF_NN_modelConvergenceDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48cf4d53",
      "metadata": {},
      "outputs": [],
      "source": [
        "plotModelConvergenceStudy(\n",
        "    top_n_modelChoices,\n",
        "    splitList,\n",
        "    convDict= MF_NN_modelConvergenceDict,\n",
        "    fidelityLevel='MF',\n",
        "    modelChoice='NN',\n",
        "    peakMiss = 'median')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730bab9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "MFoptimizedKernel1 = 1.94**2 * Matern(length_scale=8.75, nu=2.5) + WhiteKernel(noise_level=0.000757)\n",
        "MFoptimizedKernel2 = 1.77**2 * RBF(length_scale=4.71) + WhiteKernel(noise_level=0.00136)\n",
        "MFoptimizedKernel3 = 3.42**2 * RationalQuadratic(alpha=0.00625, length_scale=17)\n",
        "\n",
        "top_n_modelChoices = [ \n",
        "        MFoptimizedKernel1,\n",
        "        MFoptimizedKernel2,\n",
        "        MFoptimizedKernel3\n",
        "        ] \n",
        "\n",
        "start = 0.20 ; stop = 0.80 ; step = 0.03\n",
        "splitList = np.arange(start=start,stop=stop+step,step=step)\n",
        "splitList = splitList[splitList<=0.8]\n",
        "\n",
        "MF_krig_modelConvergenceDict = modelConvergenceStudy(\n",
        "    fidelityLevel= 'MF', \n",
        "    modelType= 'krig',\n",
        "    M_inf=M_inf,\n",
        "    inputTrainingData=multiFidelityKrig_input,\n",
        "    outputTrainingData=outputTrainingData,\n",
        "    inputTrainingNames=inputTrainingNames,\n",
        "    outputTrainingNames=outputTrainingNames,\n",
        "    top_n_modelChoices=top_n_modelChoices,\n",
        "    frequencyData = False,\n",
        "    splitList=splitList,\n",
        "    verbose=False,\n",
        "    truncate=False,\n",
        "    hyperparamDict=None,\n",
        "    callbacks_list=None,\n",
        "    n_restarts=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75273775",
      "metadata": {},
      "outputs": [],
      "source": [
        "plotModelConvergenceStudy(\n",
        "    top_n_modelChoices,\n",
        "    splitList,\n",
        "    convDict= MF_krig_modelConvergenceDict,\n",
        "    fidelityLevel='MF',\n",
        "    modelChoice='krig',\n",
        "    peakMiss = 'median')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7efbe76-1fe2-406b-b6c3-3e07d3593937",
      "metadata": {
        "id": "d7efbe76-1fe2-406b-b6c3-3e07d3593937",
        "outputId": "fa9a410b-0e73-4fb3-de5f-2fce550463fd"
      },
      "outputs": [],
      "source": [
        "##### SKLEARN DATA SPLIT \n",
        "\n",
        "X_mf = multiFidelityKrig_input\n",
        "y_mf = np.hstack(outputTrainingData)\n",
        "Y_mf_names = np.hstack(outputVarNames)\n",
        "X_names = np.hstack(inputTrainingNames)\n",
        "\n",
        "X_mf_train, X_mf_test, y_mf_train, y_mf_test, M_inf_train, M_inf_test = train_test_split(\n",
        "    X_mf, y_mf, M_inf, test_size=0.20, random_state=random_state)\n",
        "\n",
        "X_mf_test, X_mf_val, y_mf_test, y_mf_val, M_inf_test, M_inf_val = train_test_split(\n",
        "    X_mf_test, y_mf_test, M_inf_test, test_size=0.50, random_state=random_state)\n",
        "\n",
        "# M_inf_train, M_inf_test = train_test_split(M_inf,test_size=0.20,random_state=random_state) # used in plotting\n",
        "# M_inf_test, M_inf_val = train_test_split(M_inf_test,test_size=0.50,random_state=random_state) # used in plotting\n",
        "\n",
        "print(\"Multi-fidelity X_train shape: {}\".format(X_mf_train.shape))\n",
        "print(\"Multi-fidelity X_test shape: {}\".format(X_mf_test.shape))\n",
        "print(\"Multi-fidelity X_val shape: {}\".format(X_mf_val.shape))\n",
        "print(\"Multi-fidelity y_lf_train shape: {}\".format(y_mf_train.shape))\n",
        "print(\"Multi-fidelity y_lf_test shape: {}\".format(y_mf_test.shape))\n",
        "print(\"Multi-fidelity y_lf_val shape: {}\".format(y_mf_val.shape))\n",
        "print(f\"concatenation order: {X_names}\")\n",
        "print(f\"concatenation order: {Y_mf_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78674e3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "if MFKrigOptimize:\n",
        "    longKernel = 34.4**2 * RBF(length_scale=41.8) \\\n",
        "    + 3.27**2 * RBF(length_scale=180) \\\n",
        "        * ExpSineSquared(length_scale=1.44, periodicity=1) \\\n",
        "        + 0.446**2 * RationalQuadratic(alpha=17.7, length_scale=0.957) \\\n",
        "            + 0.197**2 * RBF(length_scale=0.138) + WhiteKernel(noise_level=0.0336)\n",
        "    ### MF Kernels\n",
        "    MFoptimizedKernel =  1.02**2 * RBF(length_scale=9.74)\n",
        "    ### LF Kernels\n",
        "    LFoptimizedKernel1 = 0.0873**2 + Matern(length_scale=7.53, nu=1.5) + WhiteKernel(noise_level=0.00121)\n",
        "    LFoptimizedKernel2 = 5.31**2 * RBF(length_scale=5.08) + WhiteKernel(noise_level=0.00179)\n",
        "    LFoptimizedKernel3 = 4.33**2 * RationalQuadratic(alpha=0.00285, length_scale=12.1)\n",
        "    ### HF Kernels \n",
        "    HFoptimizedKernel1 = 2.28**2 * RBF(length_scale=3.09) + WhiteKernel(noise_level=0.002)\n",
        "    HFoptimizedKernel2 = 1.54**2 * Matern(length_scale=3.7, nu=2.5) + WhiteKernel(noise_level=0.00121)\n",
        "    HFoptimizedKernel3 = 2.75**2 * RBF(length_scale=3.48) + WhiteKernel(noise_level=0.00161)\n",
        "\n",
        "    kernels = [\n",
        "        LFoptimizedKernel1,\n",
        "        LFoptimizedKernel2,\n",
        "        LFoptimizedKernel3,\n",
        "        HFoptimizedKernel1,\n",
        "        HFoptimizedKernel2,\n",
        "        HFoptimizedKernel3,\n",
        "        MFoptimizedKernel,\n",
        "    ConstantKernel(1.0) + Matern(length_scale=0.1, nu=3/2) + WhiteKernel(noise_level=1),\n",
        "    longKernel\n",
        "    #]\n",
        "    ]\n",
        "\n",
        "    MFerrorCompDataFrame, MFerrorDict, MFmodelDict = optimizeKrig(\n",
        "        kernelList = kernels,\n",
        "        X_train=X_mf_train,\n",
        "        y_train=y_mf_train, \n",
        "        X_test = X_mf_test,\n",
        "        y_test = y_mf_test,\n",
        "        fidelityLevel = \"MF\",\n",
        "        method = \"krig\",\n",
        "        n_restarts = 1,\n",
        "        verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a6bde1",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(path)\n",
        "os.chdir(modelDir + '/' + krigDir)\n",
        "filename = 'optimizerPickle_MF_2022-07-06.pkl'\n",
        "\n",
        "optPickle = pickle.load(open(filename, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cce3c878",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = optPickle\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "newdf = df.sort_values(by=['NRMSE (Pressure)', 'NRMSE (Heat Transfer)'])\n",
        "newdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b718c0-fecc-4342-874f-b44e679c280c",
      "metadata": {
        "id": "10b718c0-fecc-4342-874f-b44e679c280c"
      },
      "outputs": [],
      "source": [
        "if MFKrigTrain:\n",
        "    \n",
        "    # MFoptimizedKernel =  1.02**2 * RBF(length_scale=9.74)\n",
        "    MFoptimizedKernel1 = 1.94**2 * Matern(length_scale=8.75, nu=2.5) + WhiteKernel(noise_level=0.000757)\n",
        "    MFoptimizedKernel2 = 1.77**2 * RBF(length_scale=4.71) + WhiteKernel(noise_level=0.00136)\n",
        "    MFoptimizedKernel3 = 3.42**2 * RationalQuadratic(alpha=0.00625, length_scale=17)\n",
        "    \n",
        "    krigTrain(\n",
        "        X_train=X_mf_train,\n",
        "        y_train=y_mf_train, \n",
        "        fidelityLevel='MF',\n",
        "        kernel=MFoptimizedKernel1, \n",
        "        n_restarts = 1,\n",
        "        verbose=True\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16052e91",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = MFerrorCompDataFrame\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "newdf = df.sort_values(by=['NRMSE (Pressure)', 'R^2 (Pressure)'])\n",
        "newdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8775d6ac-e2ae-4101-8c98-bed59be765b9",
      "metadata": {
        "id": "8775d6ac-e2ae-4101-8c98-bed59be765b9"
      },
      "outputs": [],
      "source": [
        "if MFKrigSave:\n",
        "    saveKrig(fidelityLevel='MF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e05252a0-98fb-423a-b5af-0a397726cb92",
      "metadata": {
        "id": "e05252a0-98fb-423a-b5af-0a397726cb92"
      },
      "outputs": [],
      "source": [
        "if MFKrigLoad:\n",
        "\n",
        "    filename = 'MF_krig_2022-03-21.sav'\n",
        "    desiredLoadedModelName = 'MF_krig_loaded'\n",
        "\n",
        "    locals()[desiredLoadedModelName] = pickle.load(open(filename, 'rb'))\n",
        "#########################\n",
        "    MF_krig = None\n",
        "    MF_krig = MF_krig_loaded"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe9e080-5385-4576-aeac-569ac21e58c7",
      "metadata": {
        "id": "3fe9e080-5385-4576-aeac-569ac21e58c7"
      },
      "source": [
        "### Split and Scale Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "669cc6f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "generateInverseTransformedPredictions(\n",
        "    X_train = X_mf_train,\n",
        "    X_test = X_mf_test,\n",
        "    y_train = y_mf_train,\n",
        "    y_test = y_mf_test,\n",
        "    method = 'kriging',\n",
        "    fidelityLevel = 'MF',\n",
        "    verbose = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c82ed801-2eac-4547-aceb-39706de24088",
      "metadata": {
        "id": "c82ed801-2eac-4547-aceb-39706de24088",
        "outputId": "46aff4b5-642d-44da-fd1a-2a8ca053d82f"
      },
      "outputs": [],
      "source": [
        "oneToOnePlotTool(method='Kriging', \n",
        "                 desiredNumCasesForPlot=10, \n",
        "                 X_test=X_mf_test, \n",
        "                 qw_prediction = qw_MF_krig_test_predict, \n",
        "                 qw_truth = qw_MF_test_truth, \n",
        "                 p_prediction = p_MF_krig_test_predict, \n",
        "                 p_truth = p_MF_test_truth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c43bc01e",
      "metadata": {},
      "outputs": [],
      "source": [
        "oneToOneVisualizationPlotAllData(\n",
        "    case = 33, \n",
        "    qw_test_predict = qw_MF_krig_test_predict,\n",
        "    p_test_predict = p_MF_krig_test_predict,\n",
        "    qw_test_truth = qw_MF_test_truth, \n",
        "    p_test_truth = p_MF_test_truth, \n",
        "    M_inf_test = M_inf_test,\n",
        "    method = 'Kriging')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e024990-b133-4bcb-82e8-3339bad9a181",
      "metadata": {
        "id": "1e024990-b133-4bcb-82e8-3339bad9a181"
      },
      "source": [
        "## MF Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cbebba4",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"Multi Fidelity Neural Network\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e85823-db42-42b4-984b-8e56331d7a5e",
      "metadata": {
        "id": "39e85823-db42-42b4-984b-8e56331d7a5e"
      },
      "source": [
        "### Assemble Data, Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66702aa1",
      "metadata": {},
      "outputs": [],
      "source": [
        "highFidelityDataGenAndProcess()\n",
        "\n",
        "if downsample:\n",
        "    print(\"Truncated data set in MF data concat AKA downsampled\") \n",
        "    lowFidelityNN_input = LF_NN.predict(X)\n",
        "    numOutputVars = len(LFoutputVarNames)\n",
        "\n",
        "    #first step, split the generated output into separate fluid scalar variables. \n",
        "    for i, name in enumerate(LFoutputVarNames):\n",
        "        tempVarName = name + '_NNPredicted'\n",
        "        globals()[tempVarName] = np.hsplit(lowFidelityNN_input, numOutputVars)[i]\n",
        "        print(tempVarName, 'created.')\n",
        "\n",
        "    #Data will be downsampled to two points. One point on the cone and one point on the flare. These values will need to be chosen by the engineer using this code--they won't generalize \n",
        "\n",
        "\n",
        "    ##################################################\n",
        "    ####### Heat Flux and Pressure Downsample ########\n",
        "    ################################################## \n",
        "    conePoint = 2.0\n",
        "    flarePoint = 2.49\n",
        "    xLocationPressureValue1 = (np.abs(x_cc_windowed[0,:] - conePoint)).argmin()\n",
        "    xLocationPressureValue2 = (np.abs(x_cc_windowed[0,:] - flarePoint)).argmin()\n",
        "\n",
        "    indices = [xLocationPressureValue1, xLocationPressureValue2]\n",
        "    downsampledPressure = np.take(p_LF_NNPredicted, indices, axis=1)\n",
        "    downsampledHeatFlux = np.take(qw_LF_NNPredicted, indices, axis=1)\n",
        "    x_downsampledPressure = np.take(x_cc_windowed, indices, axis=1)\n",
        "    print('Low fidelity pressure data compression: ', p_LF.shape[1], ' to --> ', downsampledPressure.shape[1])\n",
        "    print('Low fidelity heat flux data compression: ', qw_LF.shape[1], ' to --> ', downsampledHeatFlux.shape[1])\n",
        "\n",
        "    lowFidelityNN_input = np.concatenate((downsampledHeatFlux, downsampledPressure), axis=1)\n",
        "    multiFidelityNN_input = np.concatenate((X,lowFidelityNN_input),\n",
        "                                    axis = 1)\n",
        "    print('Shape of multiFidelityNN_input: ' , multiFidelityNN_input.shape)\n",
        "    \n",
        "\n",
        "    ################################################################\n",
        "    ####### Verification of accurate binary data assumption ########\n",
        "    ################################################################\n",
        "\n",
        "    # leftsideIndex = xSpotLeft - 2\n",
        "    # rightsideIndex = xSpotLeft + 2\n",
        "\n",
        "    # leftMean = np.mean(qw_LF_NNPredicted[:,:leftsideIndex],axis=1).reshape(-1,1)\n",
        "    # rightMean = np.mean(qw_LF_NNPredicted[:,rightsideIndex:],axis=1).reshape(-1,1)\n",
        "    # leftData = qw_LF_NNPredicted[:,:leftsideIndex]\n",
        "    # rightData = qw_LF_NNPredicted[:,rightsideIndex:]\n",
        "\n",
        "    # leftMeanSubtracted = leftData - leftMean\n",
        "    # rightMeanSubtracted = rightData - rightMean\n",
        "\n",
        "    # print(\"Number of data points with great than 1e-10 difference from mean, left side: \", leftMeanSubtracted[leftMeanSubtracted>1e-10].shape)\n",
        "    # print(\"Number of data points with great than 1e-10 difference from mean, right side: \", rightMeanSubtracted[rightMeanSubtracted>1e-10].shape)\n",
        "\n",
        "    # print(\"Number of data points with great than 1e-11 difference from mean, left side: \", leftMeanSubtracted[leftMeanSubtracted>1e-11].shape)\n",
        "    # print(\"Number of data points with great than 1e-11 difference from mean, right side: \", rightMeanSubtracted[rightMeanSubtracted>1e-11].shape)\n",
        "\n",
        "else:\n",
        "    print(\"Full data set in MF data concat AKA not downsampled\") \n",
        "    lowFidelityNN_input = LF_NN.predict(X)\n",
        "    multiFidelityNN_input = np.concatenate((X,lowFidelityNN_input),\n",
        "                                    axis = 1)\n",
        "    multiFidelityNN_input.shape\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57df5c5b",
      "metadata": {},
      "source": [
        "# MF NN Testing Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "061f34d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# leftsideIndex = xSpotLeft - 2\n",
        "# rightsideIndex = xSpotLeft + 2\n",
        "\n",
        "# leftMean = np.mean(qw_LF_NNPredicted[caseWePick,:leftsideIndex]).reshape(-1,1)\n",
        "# rightMean = np.mean(qw_LF_NNPredicted[caseWePick,rightsideIndex:]).reshape(-1,1)\n",
        "# leftData = qw_LF_NNPredicted[caseWePick,:leftsideIndex]\n",
        "# rightData = qw_LF_NNPredicted[caseWePick,rightsideIndex:]\n",
        "\n",
        "# leftMeanSubtracted = leftData - leftMean\n",
        "# rightMeanSubtracted = rightData - rightMean\n",
        "\n",
        "# leftMeanSubtracted.max()\n",
        "\n",
        "# qwCase17Left = np.tile(leftMean[0][0], qw_LF[0,:xSpotLeft].shape[0])\n",
        "# qwCase17Right = np.tile(rightMean[0][0], qw_LF[0,xSpotLeft:].shape[0])\n",
        "# print(qwCase17Left.shape, qwCase17Right.shape)\n",
        "\n",
        "# qwCase17MeanedUp = np.concatenate((qwCase17Left,qwCase17Right))\n",
        "# qwCase17MeanedUp.shape\n",
        "# singleQwTest = qw_LF_OutputScaler.inverse_transform(qw_LF_NNPredicted[caseWePick,:])\n",
        "# qwCase17MeanedUpTransformed = qw_LF_OutputScaler.inverse_transform(qwCase17MeanedUp)\n",
        "# plt.plot(x_cc_windowed[0,:],qw_LF[caseWePick,:],label = 'Low Fidelity Heat Transfer', c='firebrick')\n",
        "# # plt.scatter(x_cc_windowed[0,::5],singleQwTest[::5],label = 'Low Fidelity Heat Flux Prediction', c='white',zorder=3,edgecolors='black', marker='D', s=70)\n",
        "\n",
        "# plt.plot(x_cc_windowed[0,:],qwCase17MeanedUpTransformed, label = 'Recreated From mean', color = 'b', linestyle='-.')\n",
        "# mean_qw = np.mean(qw_LF, axis=0)\n",
        "# std_qw = np.std(qw_LF,axis=0)\n",
        "\n",
        "# plt.plot(x_cc_windowed[0,:], mean_qw)\n",
        "\n",
        "# plt.fill_between(\n",
        "# x_cc_windowed[0,:],\n",
        "# mean_qw + std_qw, \n",
        "# mean_qw - std_qw,\n",
        "# facecolor = 'yellow',\n",
        "# alpha=0.7\n",
        "# )\n",
        "\n",
        "# # caseWePick = 23\n",
        "# numLFcases = qw_LF.shape[0]\n",
        "# caseWePick = random.randint(0,398)\n",
        "# caseWePick = 17\n",
        "# maxqw = qw_LF[caseWePick,:].max()\n",
        "# maxp = p_LF[caseWePick,:].max()\n",
        "# plt.plot(x_cc_windowed[0,:],qw_LF_NNPredicted[caseWePick,:],label = 'Scaled Low Fidelity Heat Transfer', c='firebrick')\n",
        "# # plt.semilogy(x_cc_windowed[0,:],qw[caseWePick,:], label = 'Truth (RANS) Heat Transfer')\n",
        "# # plt.scatter(x_downsampledPressure[0,:],tinydownsampledHeatFlux[caseWePick,:], label = 'Downsampled Low Fidelity Heat Transfer', s= 20, marker = \"v\", c='k', zorder=3 )\n",
        "# # plt.vlines(x_cc_windowed[0,xSpotLeft], ymin=-4,ymax=4)\n",
        "# plt.grid()\n",
        "# plt.xlabel('Location Along Double Cone Wall, $x$ (meters)')\n",
        "# plt.ylabel('Scaled Heat Transfer Rate ($q_{w, scaled}$)')\n",
        "# plt.legend()\n",
        "\n",
        "# for i in np.arange(0,30):\n",
        "#     caseWePick = i*2\n",
        "#     plt.plot(x_cc_windowed[0,:],qw_LF[caseWePick,:],label = 'Low Fidelity Heat Transfer', c='firebrick')\n",
        "## What does the untransformed high fidelity heat transfer signal look like? \n",
        "# highFidelityDataGenAndProcess()\n",
        "\n",
        "\n",
        "# highFidelityNN_output = HF_NN.predict(X)\n",
        "# numOutputVars = len(outputVarNames)\n",
        "\n",
        "#first step, split the generated output into separate fluid scalar variables. \n",
        "# for i, name in enumerate(outputVarNames):\n",
        "#     tempVarName = name + '_NNPredicted'\n",
        "#     globals()[tempVarName] = np.hsplit(highFidelityNN_output, numOutputVars)[i]\n",
        "#     print(tempVarName, 'created.')\n",
        "\n",
        "# numLFcases = qw.shape[0]\n",
        "# caseWePick = random.randint(0,398)\n",
        "# caseWePick = 17\n",
        "# plt.plot(x_cc_windowed[0,:],qw_NNPredicted[caseWePick,:],label = 'Scaled High Fidelity Heat Transfer', c='firebrick')\n",
        "# plt.semilogy(x_cc_windowed[0,:],qw[caseWePick,:], label = 'Truth (RANS) Heat Transfer')\n",
        "# plt.scatter(x_downsampledPressure[0,:],tinydownsampledHeatFlux[caseWePick,:], label = 'Downsampled Low Fidelity Heat Transfer', s= 20, marker = \"v\", c='k', zorder=3 )\n",
        "# plt.vlines(x_cc_windowed[0,xSpotLeft], ymin=-4,ymax=4)\n",
        "# plt.grid()\n",
        "# plt.xlabel('Location Along Double Cone Wall, $x$ (meters)')\n",
        "# plt.ylabel('Scaled Heat Transfer Rate ($q_{w, scaled}$)')\n",
        "# plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc3e7d05-de2e-4ef4-9638-126537c580a4",
      "metadata": {
        "id": "dc3e7d05-de2e-4ef4-9638-126537c580a4",
        "outputId": "b8b8cc16-6b64-4e2b-fe8e-c007ce0ff842"
      },
      "outputs": [],
      "source": [
        "outputTrainingData = []\n",
        "outputTrainingNames = []\n",
        "\n",
        "print('\\nOutput Data (stored in list outputTrainingData):\\n')\n",
        "for i, name in enumerate(outputVarNames):\n",
        "    ScalerName = name + '_OutputScaler'\n",
        "    ScaledName = name + '_Scaled'\n",
        "    OutputDataName = name\n",
        "    locals()[ScalerName] = None\n",
        "    locals()[ScalerName] = preprocessing.StandardScaler()\n",
        "    locals()[ScaledName] = locals()[ScalerName].fit_transform(globals()[OutputDataName])\n",
        "    outputTrainingData.append(locals()[ScaledName])\n",
        "    outputTrainingNames.append(ScaledName)\n",
        "    max_element = str(round(np.max(locals()[ScaledName]),2))\n",
        "    min_element = str(round(np.min(locals()[ScaledName]),2))\n",
        "    print(name + ' has been scaled! It is called ' +\n",
        "          ScaledName + '. Min:' + min_element + '. Max:' + max_element)\n",
        "\n",
        "multiFidelityNN_output = outputTrainingData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87322e35-5177-4bc9-a51b-f1df889c1e6f",
      "metadata": {
        "id": "87322e35-5177-4bc9-a51b-f1df889c1e6f",
        "outputId": "81a7f7e6-ed13-43bc-be56-d9cec15417ac"
      },
      "outputs": [],
      "source": [
        "multiFidelityNN_outputFlat = np.hstack(multiFidelityNN_output)\n",
        "multiFidelityNN_outputFlat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21726b4-7192-4cc8-bbfc-51dbba323253",
      "metadata": {
        "id": "c21726b4-7192-4cc8-bbfc-51dbba323253",
        "outputId": "0b438a90-75a7-4538-8450-3c9489bd3906"
      },
      "outputs": [],
      "source": [
        "##### SKLEARN DATA SPLIT \n",
        "\n",
        "X_mf = multiFidelityNN_input\n",
        "y_mf = multiFidelityNN_outputFlat\n",
        "Y_mf_names = np.hstack(outputVarNames)\n",
        "X_names = np.hstack(inputTrainingNames)\n",
        "\n",
        "X_mf_train, X_mf_test, y_mf_train, y_mf_test, M_inf_train, M_inf_test = train_test_split(\n",
        "    X_mf, y_mf, M_inf, test_size=0.20, random_state=random_state)\n",
        "\n",
        "X_mf_test, X_mf_val, y_mf_test, y_mf_val, M_inf_test, M_inf_val = train_test_split(\n",
        "    X_mf_test, y_mf_test, M_inf_test, test_size=0.50, random_state=random_state)\n",
        "\n",
        "# M_inf_train, M_inf_test = train_test_split(M_inf,test_size=0.20,random_state=random_state) # used in plotting\n",
        "# M_inf_test, M_inf_val = train_test_split(M_inf_test,test_size=0.50,random_state=random_state) # used in plotting\n",
        "\n",
        "print(\"Multi-fidelity X_train shape: {}\".format(X_mf_train.shape))\n",
        "print(\"Multi-fidelity X_test shape: {}\".format(X_mf_test.shape))\n",
        "print(\"Multi-fidelity X_val shape: {}\".format(X_mf_val.shape))\n",
        "print(\"Multi-fidelity y_lf_train shape: {}\".format(y_mf_train.shape))\n",
        "print(\"Multi-fidelity y_lf_test shape: {}\".format(y_mf_test.shape))\n",
        "print(\"Multi-fidelity y_lf_val shape: {}\".format(y_mf_val.shape))\n",
        "print(f\"concatenation order: {X_names}\")\n",
        "print(f\"concatenation order: {Y_mf_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966c7239",
      "metadata": {},
      "source": [
        "### Optimize Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035d69a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "validData = (X_mf_test, y_mf_test)\n",
        "\n",
        "batchTest(\n",
        "    model=MF_NN,\n",
        "    fidelityLevel = 'MF',\n",
        "    batchSizeMultiples=15,\n",
        "    input_data=X_mf_train,\n",
        "    output_data=y_mf_train,\n",
        "    validData=validData,\n",
        "    numEpochs=40\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ef67721-d092-4cef-80d0-7be97d545e52",
      "metadata": {
        "id": "0ef67721-d092-4cef-80d0-7be97d545e52"
      },
      "source": [
        "### Optimize Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f76c9555",
      "metadata": {},
      "outputs": [],
      "source": [
        "if MFNNConvergence: \n",
        "    callbacks_list = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor = \"val_mean_squared_error\",mode=\"min\",\n",
        "            patience=75, verbose=0,\n",
        "            restore_best_weights=False \n",
        "            )\n",
        "        ]\n",
        "\n",
        "    convStudyLayerList = [ \n",
        "        [64],\n",
        "        [72],\n",
        "        [80],\n",
        "        [40, 32],\n",
        "        [32, 64],\n",
        "        [56, 72],\n",
        "        [56, 80],\n",
        "        [80, 80],\n",
        "        [64, 80, 80],\n",
        "        [48, 56, 40],\n",
        "        [64, 80, 32],\n",
        "        [40, 56, 64],\n",
        "        [80, 80, 80],\n",
        "        [32, 64, 128],\n",
        "        [64, 128, 160],\n",
        "        [32, 64, 96, 128],\n",
        "        [64, 80 ,80, 32],\n",
        "        [64, 80 , 80, 80, 32],\n",
        "        [32, 64, 32, 128]\n",
        "        ] \n",
        "\n",
        "    # convStudyLayerList = [ \n",
        "\n",
        "    #     # [80],\n",
        "    #     [32, 64],\n",
        "    #     # [56, 80],\n",
        "    #     # [64, 80, 32],\n",
        "    #     # [40, 56, 64],\n",
        "    #     [80, 80, 80],\n",
        "    #     [32, 64, 128],\n",
        "    #     [64, 128, 128+32],\n",
        "    #     [32, 64, 96, 128],\n",
        "    #     # [64, 80 ,80, 32],\n",
        "    #     # [64, 80 , 80, 80, 32],\n",
        "    #     # [32, 64, 32, 128]\n",
        "    #     ]   \n",
        "\n",
        "    hyperparamDict = {\n",
        "        \"learningRate\" : 1.0e-3,\n",
        "        \"regType\" : keras.regularizers.L2,\n",
        "        \"regValue\" : 1.0e-6,\n",
        "        \"hiddenLayerActivation\" : tf.nn.tanh,\n",
        "        \"outputLayerActivation\" : tf.nn.leaky_relu,\n",
        "        \"kernelInitializer\" : tf.keras.initializers.GlorotUniform(),\n",
        "        \"optimizer\" : tf.keras.optimizers.Adamax,\n",
        "        \"numEpochs\" : 7000,\n",
        "        \"myBatchSize\" : 224,\n",
        "        \"loss\" : 'mse'\n",
        "    }\n",
        "    validData = (X_mf_test, y_mf_test)\n",
        "\n",
        "    neuralNetworkConvergence(\n",
        "        fidelityLevel='MF',\n",
        "        convStudyLayerList = convStudyLayerList,\n",
        "        hyperparamDict = hyperparamDict,\n",
        "        X_train = X_mf_train,\n",
        "        y_train = y_mf_train,\n",
        "        validData = validData,\n",
        "        callbacks_list = callbacks_list,\n",
        "        verbose = True,\n",
        "        showConvPlot = True,\n",
        "        saveConvPlot = True,\n",
        "        showMSEplot = True,\n",
        "        saveMSEplot = True,\n",
        "        showSpeedPlot = True,\n",
        "        saveSpeedPlot =True\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f86f068-2d1c-4639-bd54-84d61d90e5d5",
      "metadata": {
        "id": "2f86f068-2d1c-4639-bd54-84d61d90e5d5",
        "outputId": "a28aaec6-91ee-4dc2-9d47-afd3772cd61e"
      },
      "outputs": [],
      "source": [
        "if MFNNTrain: \n",
        "\n",
        "    multiFidelityLayerSizeList = [1000, 504, 504] #input the number of neurons per layer. Length of this list indicates number of hidden layers\n",
        "    multiFidelityLayerSizeList = [56, 80] \n",
        "    learningRate = 1.0e-3 #From Deep Learning w/ Python (Chollet)\n",
        "    regType = keras.regularizers.L2\n",
        "    regValue = 1.0e-6\n",
        "    hiddenLayerActivation = tf.nn.tanh\n",
        "    outputLayerActivation = tf.nn.leaky_relu\n",
        "    kernelInitializer = tf.keras.initializers.GlorotUniform()\n",
        "    optimizer = tf.keras.optimizers.Adamax\n",
        "    numEpochs = 5000\n",
        "    if quickTestRun:\n",
        "        numEpochs = 10\n",
        "    myBatchSize = None\n",
        "    validSplit = None\n",
        "    loss = 'mse'\n",
        "    validData = (X_mf_test, y_mf_test)\n",
        "\n",
        "    callbacks_list = None\n",
        "\n",
        "    MF_NN = None #sometimes remnants of previously trained models can hang around, it's best \n",
        "                #to clear the variable first \n",
        "\n",
        "    MF_NN = build_model_parameterized(\n",
        "        input_data = X_mf_train, \n",
        "        output_data = y_mf_train,\n",
        "        layerSizeList = multiFidelityLayerSizeList, \n",
        "        rate = learningRate, \n",
        "        regType = regType, \n",
        "        regValue = regValue,\n",
        "        hiddenLayerActivation = hiddenLayerActivation,\n",
        "        outputLayerActivation = outputLayerActivation,\n",
        "        kernelInitializer = kernelInitializer,\n",
        "        outputLayerDataType='float32',\n",
        "        optimizer = optimizer,\n",
        "        loss = loss)\n",
        "kerasPlotModel(model=MF_NN,fidelityLevel='MF')\n",
        "MF_NN.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ef67721-d092-4cef-80d0-7be97d545e52",
      "metadata": {
        "id": "0ef67721-d092-4cef-80d0-7be97d545e52"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e49b6b15-7808-469c-8e67-a819f4e26231",
      "metadata": {
        "id": "e49b6b15-7808-469c-8e67-a819f4e26231",
        "outputId": "fb1636db-3ebe-431f-a59c-540f792f8fb3"
      },
      "outputs": [],
      "source": [
        "#Initialize hyperparamters for Single Fidelity Model\n",
        "if MFNNTrain: \n",
        "\n",
        "    MF_NN_epochs = None\n",
        "    MF_NN_history = None\n",
        "    print('MF NN training start')\n",
        "    start = time.time()\n",
        "    MF_NN_epochs, MF_NN_history = train_model_all_fidelity(\n",
        "        model = MF_NN, \n",
        "        input_data = X_mf_train, \n",
        "        output_data = y_mf_train,\n",
        "        numEpochs = numEpochs, \n",
        "        myBatchSize = myBatchSize,\n",
        "        validData = validData,\n",
        "        callbacks_list= callbacks_list)\n",
        "    end = time.time()\n",
        "    print('MF NN training complete. Time to train:')\n",
        "    print(round((end-start),4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "731609d4-a719-4ed0-a114-f0b82bb36b36",
      "metadata": {
        "id": "731609d4-a719-4ed0-a114-f0b82bb36b36"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ae2445-6a34-47a3-99f3-f59b2c9af3d6",
      "metadata": {
        "id": "66ae2445-6a34-47a3-99f3-f59b2c9af3d6"
      },
      "outputs": [],
      "source": [
        "if MFNNSave:\n",
        "    saveNN(fidelityLevel='MF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5777938d-b260-4842-8979-ad04a6e6320e",
      "metadata": {
        "id": "5777938d-b260-4842-8979-ad04a6e6320e"
      },
      "outputs": [],
      "source": [
        "# build this one so you just type the date and it populates all the strings/pkls/paths, etc. \n",
        "\n",
        "if MFNNLoad: \n",
        "    loadNN(\n",
        "        neuralNetFolderName = 'MF_NN_2022-XX-XX'\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30242911",
      "metadata": {},
      "outputs": [],
      "source": [
        "loadConvStudyNN(\n",
        "    convStudyFolderName='MF20220707-195106', \n",
        "    fidelityLevel='MF', \n",
        "    layerConfiguration=[80,80]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b29dd11-5297-416d-8172-60c687c34a30",
      "metadata": {
        "id": "8b29dd11-5297-416d-8172-60c687c34a30"
      },
      "source": [
        "### Generate Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21b81fcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "MF_NN_history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a116d2ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "mseNames = [\"mean_squared_error\",\n",
        "            'val_mean_squared_error'\n",
        "            ]\n",
        "colorList = [ 'k', 'r']\n",
        "\n",
        "plotTrainAndTestLoss(historyDict = MF_NN_history,\n",
        "                     mseNames = mseNames,\n",
        "                     colorList = colorList,\n",
        "                     fidelityLevel = 'Multi Fidelity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab64bb79-104f-4c61-8883-c1e9a5571853",
      "metadata": {
        "id": "ab64bb79-104f-4c61-8883-c1e9a5571853",
        "outputId": "9496855a-61ff-4a59-d303-537d5a80c1a5"
      },
      "outputs": [],
      "source": [
        "generateInverseTransformedPredictions(\n",
        "    X_train = X_mf_train,\n",
        "    X_test = X_mf_test,\n",
        "    y_train = y_mf_train,\n",
        "    y_test = y_mf_test,\n",
        "    method = 'NN',\n",
        "    fidelityLevel = 'MF',\n",
        "    verbose = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d61afdec-8502-4cc5-950c-3c61c416cc29",
      "metadata": {
        "id": "d61afdec-8502-4cc5-950c-3c61c416cc29"
      },
      "source": [
        "### Analyze Predictions (One to One Comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "101dcfd9-83d3-486a-bf4b-110e3a1cb3ee",
      "metadata": {
        "id": "101dcfd9-83d3-486a-bf4b-110e3a1cb3ee",
        "outputId": "55e94f76-e24e-49e9-8ef1-f0c9c4f4a00a"
      },
      "outputs": [],
      "source": [
        "oneToOnePlotTool(\n",
        "    method='Neural Network', \n",
        "    desiredNumCasesForPlot=10, \n",
        "    X_test=X_test, \n",
        "    qw_prediction = qw_MF_NN_test_predict, \n",
        "    qw_truth = qw_MF_test_truth, \n",
        "    p_prediction = p_MF_NN_test_predict, \n",
        "    p_truth = p_MF_test_truth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c573577",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "qr2 = percentdifferencecalc(4532, 3649)\n",
        "pr2 = percentdifferencecalc(4129,2769)\n",
        "np.mean((qr2,pr2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fea4eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "oneToOneVisualizationPlotAllData(\n",
        "    case = 12, \n",
        "    qw_test_predict = qw_MF_NN_test_predict,\n",
        "    p_test_predict = p_MF_NN_test_predict,\n",
        "    qw_test_truth = qw_MF_test_truth, \n",
        "    p_test_truth = p_MF_test_truth, \n",
        "    M_inf_test = M_inf_test,\n",
        "    method = 'MF Neural Network')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76163365",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*40, \"Multi Fidelity Error Metrics\", \"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc226aa7-de28-4936-b5e7-5395da8d6e45",
      "metadata": {
        "id": "bc226aa7-de28-4936-b5e7-5395da8d6e45",
        "outputId": "0d47ceb7-6f77-4fd6-e7e8-c2c9d93b18db"
      },
      "outputs": [],
      "source": [
        "[MF_krig_NRMSE_pressure, MF_krig_R2_pressure] = errorMetrics(\n",
        "    truth = p_MF_test_truth,\n",
        "    prediction = p_MF_krig_test_predict,\n",
        "    fidelity = 'MF',\n",
        "    model = 'Kriging',\n",
        "    variable = 'Pressure',\n",
        "    verbose = True)\n",
        "\n",
        "[MF_krig_NRMSE_heatTransfer, MF_krig_R2_heatTransfer] = errorMetrics(\n",
        "    truth = qw_MF_test_truth,\n",
        "    prediction = qw_MF_krig_test_predict,\n",
        "    fidelity = 'MF',\n",
        "    model = 'Kriging',\n",
        "    variable = 'Heat Transfer',\n",
        "    verbose = True)\n",
        "\n",
        "[MF_NN_NRMSE_pressure, MF_NN_R2_pressure] = errorMetrics(\n",
        "    truth = p_MF_test_truth,\n",
        "    prediction = p_MF_NN_test_predict,\n",
        "    fidelity = 'MF',\n",
        "    model = 'NN',\n",
        "    variable = 'Pressure',\n",
        "    verbose = True)\n",
        "\n",
        "[MF_NN_NRMSE_heatTransfer, MF_NN_R2_heatTransfer] = errorMetrics(\n",
        "    truth = qw_MF_test_truth,\n",
        "    prediction = qw_MF_NN_test_predict,\n",
        "    fidelity = 'MF',\n",
        "    model = 'NN',\n",
        "    variable = 'Heat Transfer',\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c59eed56",
      "metadata": {},
      "outputs": [],
      "source": [
        "programEnd = time.time()\n",
        "programTotal = round(((programEnd - programStart)/60),4)\n",
        "print('Entire program took ' + str(programTotal) + ' minutes')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "f5b051b6-de85-46d1-a987-46d3d480204d",
        "80080302-eb61-4838-be1f-9eb26a61d9d0",
        "0386b527-836f-49c1-8304-3e33ee21eb1a",
        "9bdd64f8-61a8-449e-bda8-eef10e4db4ab",
        "56f18009-4d57-4c22-8b7f-7a29bb29234f",
        "79e301b5-8f62-4f14-a57f-c0a97b68bbbd",
        "1416c194-d937-40e8-acff-bcdb2263af37",
        "168986b7-24a1-44bb-9daf-5b1f7c9bc477",
        "56a09f43-5702-468b-b35d-e6afe87e1fcb",
        "a7417314-33ed-4d82-8ea4-3837387dffd8",
        "4f3ef323-1f56-440e-b19c-aa22f8ede4f2",
        "a1dc91b2-fdd5-4bcb-9394-19beb4127a04",
        "ffdac9a4-23e5-4f25-b539-f7ea49ccfcb8",
        "c070cfcb-82ea-4092-b0ed-3f4dd499bf11",
        "ce595305-5bf2-4324-abe9-2ca59928d8c5",
        "517401b7-79eb-4976-b094-790d686c7af7",
        "3c54dd8f-04e4-4500-90c9-1371d5226185",
        "db860f01-a7b2-4f0c-a923-ebca861af621",
        "3170d7bf-d445-4f80-8758-94ed41a4c8fc",
        "a63f67e0-6e3b-4d4a-88ed-71ca155467d1",
        "c07afb82-5143-4209-a4d3-6c5da1370d9e",
        "9d0ad813-3f39-4c11-9945-05c38c0e385b",
        "9d623bfc-a106-4bcd-bf3b-524af5f8e68a",
        "99620439-bd71-4aaf-bffa-9c1e536ca870",
        "41fb8fac-65fc-42d1-9a61-4d52ce364f42",
        "3e1dd7d9-5f82-462a-973c-32d0e893d4d4",
        "44e20e6e-fc9d-4cc0-8081-fc2b18a2e668",
        "bf9e78fb-192d-4566-87ff-bb01b6c0629b",
        "ab638b4b-7599-45fd-a1d3-49e3a6da48be",
        "f5825af9-1083-4621-8487-6a2a2617d080",
        "05b48b81-3907-4df6-8f0f-f2d2a59b5604",
        "c63207a5-74f7-4638-a36f-eef627c9fecd",
        "6feb729f-dbbe-46e1-943f-2895935d31d2",
        "192c69dd-acf2-40d4-aedf-c1288a12f0e8",
        "8ad6ac2b-56c4-47f1-9b6d-55a86c9ea858",
        "bbd07e77-136e-493b-9ebc-c8407cc84059",
        "698f6f47-209a-4caf-b07b-34fc0953d075",
        "03c6dec2-c587-4da9-886b-cf5041fb122c",
        "cb66ffce-a66d-46b4-a7c8-88fb5ca6aba1",
        "3fe9e080-5385-4576-aeac-569ac21e58c7",
        "1e024990-b133-4bcb-82e8-3339bad9a181",
        "fd337125-abbb-4a0a-be1b-a911a7294fbb",
        "39e85823-db42-42b4-984b-8e56331d7a5e",
        "c7bdb64c-ade0-46c2-9b6f-4c12c2a423ea",
        "0ef67721-d092-4cef-80d0-7be97d545e52",
        "731609d4-a719-4ed0-a114-f0b82bb36b36",
        "8b29dd11-5297-416d-8172-60c687c34a30",
        "7bc04db8-703b-4ac0-8500-f05b99cc6a86",
        "634b5f53-0ee1-40c8-b180-4276bb2c19e1",
        "d61afdec-8502-4cc5-950c-3c61c416cc29",
        "57bc5be5-c563-4387-85e4-450e80cadab0"
      ],
      "name": "MF_SurrogateModel_20220516.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "081af3024f16a256c5b6c8c49e7d6c68935d0cb335782e21a8d7e5584a02a432"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": false
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
